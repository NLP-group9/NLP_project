{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_GNN_comments_generation (2).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "XQh-352-Vy4w",
        "pIUYYeaJEJRN",
        "0eGeCOK8EKfX",
        "8j6XLsKOxudP",
        "QLu5qU6_xyG-"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load file"
      ],
      "metadata": {
        "id": "XQh-352-Vy4w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "h4B7dYGPORcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "021a346a-8513-4866-9832-218699c8b207"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "dir = '/content/gdrive/MyDrive/archive'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dirname, _, filenames in os.walk('/content/gdrive/MyDrive/archive'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "qkEJ-iiDrN6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a627811c-e263-497f-fa00-1c0fa429e9f6"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/archive/nyt-articles-2020.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-2020.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part0.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part1.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part2.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part3.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part4.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part5.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part6.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part7.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part8.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part9.csv\n",
            "/content/gdrive/MyDrive/archive/test.csv\n",
            "/content/gdrive/MyDrive/archive/train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "article"
      ],
      "metadata": {
        "id": "NGYRTZhCrxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-articles-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df1 = pd.read_csv('/content/gdrive/MyDrive/archive/nyt-articles-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df1.dataframeName = 'nyt-articles-2020.csv'\n",
        "nRow, nCol = df1.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "metadata": {
        "id": "I1G8ci8frTne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eecf95e8-b65c-48d0-c47f-8758e3c2e627"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 16787 rows and 11 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "metadata": {
        "id": "0ZBxuoC1rfdk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "d2a934c9-349a-4eff-e326-f8b0ecb40fbe"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    newsdesk             section subsection             material  \\\n",
              "0  Editorial             Opinion        NaN            Editorial   \n",
              "1      Games  Crosswords & Games        NaN                 News   \n",
              "2    Science             Science        NaN                 News   \n",
              "3    Science             Science        NaN  Interactive Feature   \n",
              "4    Science             Science        NaN                 News   \n",
              "\n",
              "                                            headline  \\\n",
              "0                        Protect Veterans From Fraud   \n",
              "1                             ‘It’s Green and Slimy’   \n",
              "2  Meteor Showers in 2020 That Will Light Up Nigh...   \n",
              "3           Sync your calendar with the solar system   \n",
              "4  Rocket Launches, Trips to Mars and More 2020 S...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  Congress could do much more to protect America...   \n",
              "1  Christina Iverson and Jeff Chen ring in the Ne...   \n",
              "2  All year long, Earth passes through streams of...   \n",
              "3  Never miss an eclipse, a meteor shower, a rock...   \n",
              "4  A year full of highs and lows in space just en...   \n",
              "\n",
              "                                            keywords  word_count  \\\n",
              "0  ['Veterans', 'For-Profit Schools', 'Financial ...         680   \n",
              "1                              ['Crossword Puzzles']         931   \n",
              "2  ['Meteors and Meteorites', 'Space and Astronom...        1057   \n",
              "3  ['Space and Astronomy', 'Moon', 'Eclipses', 'S...           0   \n",
              "4  ['Space and Astronomy', 'Private Spaceflight',...        1156   \n",
              "\n",
              "                    pub_date  n_comments  \\\n",
              "0  2020-01-01 00:18:54+00:00         186   \n",
              "1  2020-01-01 03:00:10+00:00         257   \n",
              "2  2020-01-01 05:00:08+00:00           6   \n",
              "3  2020-01-01 05:00:12+00:00           2   \n",
              "4  2020-01-01 05:02:38+00:00          25   \n",
              "\n",
              "                                            uniqueID  \n",
              "0  nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "1  nyt://article/9edddb54-0aa3-5835-a833-d311a76f...  \n",
              "2  nyt://article/04bc90f0-b20b-511c-b5bb-3ce13194...  \n",
              "3  nyt://interactive/5b58d876-9351-50af-9b41-a312...  \n",
              "4  nyt://article/bd8647b3-8ec6-50aa-95cf-2b81ed12...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-300fb233-60ac-4449-8cad-844ea6a34d82\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>newsdesk</th>\n",
              "      <th>section</th>\n",
              "      <th>subsection</th>\n",
              "      <th>material</th>\n",
              "      <th>headline</th>\n",
              "      <th>abstract</th>\n",
              "      <th>keywords</th>\n",
              "      <th>word_count</th>\n",
              "      <th>pub_date</th>\n",
              "      <th>n_comments</th>\n",
              "      <th>uniqueID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Editorial</td>\n",
              "      <td>Opinion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Editorial</td>\n",
              "      <td>Protect Veterans From Fraud</td>\n",
              "      <td>Congress could do much more to protect America...</td>\n",
              "      <td>['Veterans', 'For-Profit Schools', 'Financial ...</td>\n",
              "      <td>680</td>\n",
              "      <td>2020-01-01 00:18:54+00:00</td>\n",
              "      <td>186</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Games</td>\n",
              "      <td>Crosswords &amp; Games</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "      <td>‘It’s Green and Slimy’</td>\n",
              "      <td>Christina Iverson and Jeff Chen ring in the Ne...</td>\n",
              "      <td>['Crossword Puzzles']</td>\n",
              "      <td>931</td>\n",
              "      <td>2020-01-01 03:00:10+00:00</td>\n",
              "      <td>257</td>\n",
              "      <td>nyt://article/9edddb54-0aa3-5835-a833-d311a76f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Science</td>\n",
              "      <td>Science</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "      <td>Meteor Showers in 2020 That Will Light Up Nigh...</td>\n",
              "      <td>All year long, Earth passes through streams of...</td>\n",
              "      <td>['Meteors and Meteorites', 'Space and Astronom...</td>\n",
              "      <td>1057</td>\n",
              "      <td>2020-01-01 05:00:08+00:00</td>\n",
              "      <td>6</td>\n",
              "      <td>nyt://article/04bc90f0-b20b-511c-b5bb-3ce13194...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Science</td>\n",
              "      <td>Science</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Interactive Feature</td>\n",
              "      <td>Sync your calendar with the solar system</td>\n",
              "      <td>Never miss an eclipse, a meteor shower, a rock...</td>\n",
              "      <td>['Space and Astronomy', 'Moon', 'Eclipses', 'S...</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-01-01 05:00:12+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>nyt://interactive/5b58d876-9351-50af-9b41-a312...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Science</td>\n",
              "      <td>Science</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "      <td>Rocket Launches, Trips to Mars and More 2020 S...</td>\n",
              "      <td>A year full of highs and lows in space just en...</td>\n",
              "      <td>['Space and Astronomy', 'Private Spaceflight',...</td>\n",
              "      <td>1156</td>\n",
              "      <td>2020-01-01 05:02:38+00:00</td>\n",
              "      <td>25</td>\n",
              "      <td>nyt://article/bd8647b3-8ec6-50aa-95cf-2b81ed12...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-300fb233-60ac-4449-8cad-844ea6a34d82')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-300fb233-60ac-4449-8cad-844ea6a34d82 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-300fb233-60ac-4449-8cad-844ea6a34d82');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comment"
      ],
      "metadata": {
        "id": "4Ul50KM2rzeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-comments-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df2 = pd.read_csv( dir+'/nyt-comments-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df2.dataframeName = 'nyt-comments-2020.csv'\n",
        "nRow, nCol = df2.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "metadata": {
        "id": "lARaxsdtrmiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28072df-a439-4882-b8f6-25bda7501495"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4986461 rows and 23 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "tMxISPwSr3Tt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "outputId": "4214d274-fa4a-4b23-cf30-199411f4dd88"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   commentID    status  commentSequence    userID userDisplayName  \\\n",
              "0  104387472  approved        104387472  60215558  magicisnotreal   \n",
              "1  104387873  approved        104387873  65691034              JD   \n",
              "2  104387976  approved        104387976  65110053           ebmem   \n",
              "3  104390628  approved        104390628  60215558  magicisnotreal   \n",
              "4  104391463  approved        104391463  65691034              JD   \n",
              "\n",
              "  userLocation userTitle                                        commentBody  \\\n",
              "0        earth       NaN  Here is something I think is fraudulent that v...   \n",
              "1         Elko       NaN  @magicisnotreal  I have used my VA loan option...   \n",
              "2  Memphis, TN       NaN  @magi\\n\\nWhy would someone take out a VA loan ...   \n",
              "3        earth       NaN  @JD\\nOut here in the Alabama of the PNW they w...   \n",
              "4         Elko       NaN  @magicisnotreal  just a guess but I doubt that...   \n",
              "\n",
              "            createDate           updateDate  ... editorsSelection  \\\n",
              "0  2020-01-01 01:05:46  2020-01-01 08:13:39  ...            False   \n",
              "1  2020-01-01 01:52:25  2020-01-01 20:55:19  ...            False   \n",
              "2  2020-01-01 02:06:05  2020-01-01 20:55:35  ...            False   \n",
              "3  2020-01-01 14:38:50  2020-01-01 20:56:46  ...            False   \n",
              "4  2020-01-01 16:23:14  2020-01-01 16:25:57  ...            False   \n",
              "\n",
              "      parentID  parentUserDisplayName  depth  commentType trusted  \\\n",
              "0          NaN                    NaN      1      comment       0   \n",
              "1  104387472.0         magicisnotreal      2    userReply       0   \n",
              "2  104387472.0         magicisnotreal      2    userReply       0   \n",
              "3  104387873.0         magicisnotreal      2    userReply       0   \n",
              "4  104390628.0         magicisnotreal      2    userReply       0   \n",
              "\n",
              "   recommendedFlag     permID  isAnonymous  \\\n",
              "0                0  104387472        False   \n",
              "1                0  104387873        False   \n",
              "2                0  104387976        False   \n",
              "3                0  104390628        False   \n",
              "4                0  104391463        False   \n",
              "\n",
              "                                           articleID  \n",
              "0  nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "1  nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "2  nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "3  nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "4  nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb38321c-884a-4c2a-9082-2d62fa16cbf4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentID</th>\n",
              "      <th>status</th>\n",
              "      <th>commentSequence</th>\n",
              "      <th>userID</th>\n",
              "      <th>userDisplayName</th>\n",
              "      <th>userLocation</th>\n",
              "      <th>userTitle</th>\n",
              "      <th>commentBody</th>\n",
              "      <th>createDate</th>\n",
              "      <th>updateDate</th>\n",
              "      <th>...</th>\n",
              "      <th>editorsSelection</th>\n",
              "      <th>parentID</th>\n",
              "      <th>parentUserDisplayName</th>\n",
              "      <th>depth</th>\n",
              "      <th>commentType</th>\n",
              "      <th>trusted</th>\n",
              "      <th>recommendedFlag</th>\n",
              "      <th>permID</th>\n",
              "      <th>isAnonymous</th>\n",
              "      <th>articleID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>104387472</td>\n",
              "      <td>approved</td>\n",
              "      <td>104387472</td>\n",
              "      <td>60215558</td>\n",
              "      <td>magicisnotreal</td>\n",
              "      <td>earth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Here is something I think is fraudulent that v...</td>\n",
              "      <td>2020-01-01 01:05:46</td>\n",
              "      <td>2020-01-01 08:13:39</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>comment</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104387472</td>\n",
              "      <td>False</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>104387873</td>\n",
              "      <td>approved</td>\n",
              "      <td>104387873</td>\n",
              "      <td>65691034</td>\n",
              "      <td>JD</td>\n",
              "      <td>Elko</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@magicisnotreal  I have used my VA loan option...</td>\n",
              "      <td>2020-01-01 01:52:25</td>\n",
              "      <td>2020-01-01 20:55:19</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>104387472.0</td>\n",
              "      <td>magicisnotreal</td>\n",
              "      <td>2</td>\n",
              "      <td>userReply</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104387873</td>\n",
              "      <td>False</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>104387976</td>\n",
              "      <td>approved</td>\n",
              "      <td>104387976</td>\n",
              "      <td>65110053</td>\n",
              "      <td>ebmem</td>\n",
              "      <td>Memphis, TN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@magi\\n\\nWhy would someone take out a VA loan ...</td>\n",
              "      <td>2020-01-01 02:06:05</td>\n",
              "      <td>2020-01-01 20:55:35</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>104387472.0</td>\n",
              "      <td>magicisnotreal</td>\n",
              "      <td>2</td>\n",
              "      <td>userReply</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104387976</td>\n",
              "      <td>False</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>104390628</td>\n",
              "      <td>approved</td>\n",
              "      <td>104390628</td>\n",
              "      <td>60215558</td>\n",
              "      <td>magicisnotreal</td>\n",
              "      <td>earth</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@JD\\nOut here in the Alabama of the PNW they w...</td>\n",
              "      <td>2020-01-01 14:38:50</td>\n",
              "      <td>2020-01-01 20:56:46</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>104387873.0</td>\n",
              "      <td>magicisnotreal</td>\n",
              "      <td>2</td>\n",
              "      <td>userReply</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104390628</td>\n",
              "      <td>False</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>104391463</td>\n",
              "      <td>approved</td>\n",
              "      <td>104391463</td>\n",
              "      <td>65691034</td>\n",
              "      <td>JD</td>\n",
              "      <td>Elko</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@magicisnotreal  just a guess but I doubt that...</td>\n",
              "      <td>2020-01-01 16:23:14</td>\n",
              "      <td>2020-01-01 16:25:57</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>104390628.0</td>\n",
              "      <td>magicisnotreal</td>\n",
              "      <td>2</td>\n",
              "      <td>userReply</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>104391463</td>\n",
              "      <td>False</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb38321c-884a-4c2a-9082-2d62fa16cbf4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb38321c-884a-4c2a-9082-2d62fa16cbf4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb38321c-884a-4c2a-9082-2d62fa16cbf4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "article = np.array(df1)"
      ],
      "metadata": {
        "id": "N0S__w1jr4rf"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comments = np.array(df2)"
      ],
      "metadata": {
        "id": "BSIxXpKVtuUN"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "r4sjXW5pyxFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Article cleaning \\\\\n",
        "列数从0开始 \\\\\n",
        "第1列 第2列不出现 politics \\\\\n",
        "第6列不出现 [] \\\\\n",
        "第7列筛选文章词数大于50 \\\\\n",
        "第9列筛选comments个数大于50 \\\\\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "akvF2EghyytA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#只保留sports和movies\n",
        "df1_1 = df1.drop(df1[df1['section'] != 'Sports'].index)\n",
        "df1_2 = df1.drop(df1[df1['section'] != 'Movies'].index)\n",
        "cleaned_arti = pd.concat([df1_1, df1_2])\n",
        "#第六列不出现空\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['keywords'] == '[]'].index)\n",
        "#第七列筛选次数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['word_count'] < 50].index)\n",
        "#第九列comments个数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['n_comments'] < 50].index)"
      ],
      "metadata": {
        "id": "KY9i-F7t1F51"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#取出对应的article id\n",
        "uni_id = cleaned_arti['uniqueID'].to_numpy()"
      ],
      "metadata": {
        "id": "Wj2NhbCZ6D7p"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#article只保留四列\n",
        "cleaned_arti = cleaned_arti[['headline','abstract','keywords', 'uniqueID']]"
      ],
      "metadata": {
        "id": "YvukWqHq8HLE"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_arti.head()"
      ],
      "metadata": {
        "id": "1kHADShR8XRq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f87dc853-e98d-4b53-ca56-c2008a83b288"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              headline  \\\n",
              "162    What We Learned in the N.F.L.’s Wild-Card Round   \n",
              "382             Pete Carroll Wants to Change Your Life   \n",
              "434  N.F.L. Playoff Predictions: Our Picks for the ...   \n",
              "443  How Dabo Swinney Turned Clemson Into a Footbal...   \n",
              "554  Technology, Once the Astros’ Ally, Helps Do Th...   \n",
              "\n",
              "                                              abstract  \\\n",
              "162  The Titans, the Vikings and the Seahawks all w...   \n",
              "382  The Seattle Seahawks’ coach is shaping his loc...   \n",
              "434  Lamar Jackson is back, the 49ers are healthy, ...   \n",
              "443  Clemson can win a third national title in four...   \n",
              "554  Jeff Luhnow built a powerhouse in Houston by t...   \n",
              "\n",
              "                                              keywords  \\\n",
              "162  ['Football', 'Playoff Games', 'Tennessee Titan...   \n",
              "382  ['Football', 'Carroll, Pete', 'Seattle Seahawk...   \n",
              "434  ['Football', 'Playoff Games', 'Baltimore Raven...   \n",
              "443  ['Football (College)', 'Clemson University', '...   \n",
              "554  ['Baseball', 'Coaches and Managers', 'Cheating...   \n",
              "\n",
              "                                              uniqueID  \n",
              "162  nyt://article/d2f604e1-55b0-596b-9098-c80e3d98...  \n",
              "382  nyt://article/4a353cc1-cd8e-59f8-9eb0-bfb071b6...  \n",
              "434  nyt://article/2a58bdd3-95df-5ed2-b220-90b2333c...  \n",
              "443  nyt://article/90868d45-4d64-530a-a275-ff0003be...  \n",
              "554  nyt://article/0cae0dbb-cbd7-59eb-a03f-5a9f2395...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce519bbf-e54e-4b01-8d30-ee7f0b05c6f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>abstract</th>\n",
              "      <th>keywords</th>\n",
              "      <th>uniqueID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>What We Learned in the N.F.L.’s Wild-Card Round</td>\n",
              "      <td>The Titans, the Vikings and the Seahawks all w...</td>\n",
              "      <td>['Football', 'Playoff Games', 'Tennessee Titan...</td>\n",
              "      <td>nyt://article/d2f604e1-55b0-596b-9098-c80e3d98...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>Pete Carroll Wants to Change Your Life</td>\n",
              "      <td>The Seattle Seahawks’ coach is shaping his loc...</td>\n",
              "      <td>['Football', 'Carroll, Pete', 'Seattle Seahawk...</td>\n",
              "      <td>nyt://article/4a353cc1-cd8e-59f8-9eb0-bfb071b6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>N.F.L. Playoff Predictions: Our Picks for the ...</td>\n",
              "      <td>Lamar Jackson is back, the 49ers are healthy, ...</td>\n",
              "      <td>['Football', 'Playoff Games', 'Baltimore Raven...</td>\n",
              "      <td>nyt://article/2a58bdd3-95df-5ed2-b220-90b2333c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>How Dabo Swinney Turned Clemson Into a Footbal...</td>\n",
              "      <td>Clemson can win a third national title in four...</td>\n",
              "      <td>['Football (College)', 'Clemson University', '...</td>\n",
              "      <td>nyt://article/90868d45-4d64-530a-a275-ff0003be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>Technology, Once the Astros’ Ally, Helps Do Th...</td>\n",
              "      <td>Jeff Luhnow built a powerhouse in Houston by t...</td>\n",
              "      <td>['Baseball', 'Coaches and Managers', 'Cheating...</td>\n",
              "      <td>nyt://article/0cae0dbb-cbd7-59eb-a03f-5a9f2395...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce519bbf-e54e-4b01-8d30-ee7f0b05c6f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ce519bbf-e54e-4b01-8d30-ee7f0b05c6f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ce519bbf-e54e-4b01-8d30-ee7f0b05c6f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments cleaning \\\\\n",
        "根据cleaned article筛选comments \\\\\n"
      ],
      "metadata": {
        "id": "lG4K6bjD0BE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_comm = df2[df2['articleID'].isin(uni_id)]"
      ],
      "metadata": {
        "id": "CJfNgUgi65t3"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_comm = cleaned_comm[['commentBody','articleID']]"
      ],
      "metadata": {
        "id": "4TnepgQb8j_C"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_comm.shape"
      ],
      "metadata": {
        "id": "-p3i-r4q9Bgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3320ae36-cf4f-44b2-f904-fcb8e9bb88fe"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(38746, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_comm.head()"
      ],
      "metadata": {
        "id": "r3K1ziPk7WGH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "ff27f1a5-e165-44e3-c8c6-42cc92626bc6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            commentBody  \\\n",
              "8567  No mention of the excellent film \"The Age of I...   \n",
              "8568  @susan The Age of Innocence is one of Scorsese...   \n",
              "8569  @susan Nope. It doesn't support the narrative ...   \n",
              "8570  @susan \\n\\nIsn't it an Edith Wharton novel inv...   \n",
              "8571  @Big Frank The critics do their job. No need t...   \n",
              "\n",
              "                                              articleID  \n",
              "8567  nyt://article/8c52bb6b-fb80-5567-8164-f19de052...  \n",
              "8568  nyt://article/8c52bb6b-fb80-5567-8164-f19de052...  \n",
              "8569  nyt://article/8c52bb6b-fb80-5567-8164-f19de052...  \n",
              "8570  nyt://article/8c52bb6b-fb80-5567-8164-f19de052...  \n",
              "8571  nyt://article/8c52bb6b-fb80-5567-8164-f19de052...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e49373d2-4396-4929-bc53-a021c746a036\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>commentBody</th>\n",
              "      <th>articleID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8567</th>\n",
              "      <td>No mention of the excellent film \"The Age of I...</td>\n",
              "      <td>nyt://article/8c52bb6b-fb80-5567-8164-f19de052...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8568</th>\n",
              "      <td>@susan The Age of Innocence is one of Scorsese...</td>\n",
              "      <td>nyt://article/8c52bb6b-fb80-5567-8164-f19de052...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8569</th>\n",
              "      <td>@susan Nope. It doesn't support the narrative ...</td>\n",
              "      <td>nyt://article/8c52bb6b-fb80-5567-8164-f19de052...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8570</th>\n",
              "      <td>@susan \\n\\nIsn't it an Edith Wharton novel inv...</td>\n",
              "      <td>nyt://article/8c52bb6b-fb80-5567-8164-f19de052...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8571</th>\n",
              "      <td>@Big Frank The critics do their job. No need t...</td>\n",
              "      <td>nyt://article/8c52bb6b-fb80-5567-8164-f19de052...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e49373d2-4396-4929-bc53-a021c746a036')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e49373d2-4396-4929-bc53-a021c746a036 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e49373d2-4396-4929-bc53-a021c746a036');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node extraction"
      ],
      "metadata": {
        "id": "tjVo2aKAV5vx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reconstruct keywords"
      ],
      "metadata": {
        "id": "QPzAYx7UI3rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "\n",
        "# new version\n",
        "def extract_kw(cleaned_arti):\n",
        "    # stop words in English\n",
        "    stop = set(stopwords.words('english')) \n",
        "    #extract keywords from cleaned article\n",
        "    kw_set = np.array(cleaned_arti['keywords'])\n",
        "    for i, kw in enumerate(kw_set):\n",
        "        kw = kw.split(',')\n",
        "        for j in range(len(kw)):\n",
        "            kw[j] = re.sub(u\"([^\\u0041-\\u005a\\u0061-\\u007a\\u0020])\", \"\", kw[j])\n",
        "            kw[j] = kw[j].strip()\n",
        "        kw = np.array([i for i in kw if i != \"\" and i not in stop])\n",
        "        kw_set[i] = np.unique(kw)\n",
        "    return kw_set\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awoyXGsss6Vs",
        "outputId": "195b8894-a3c0-4dab-b08d-264ad6bd34ad"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "j4lgrRSagGis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kw = extract_kw(cleaned_arti)"
      ],
      "metadata": {
        "id": "TD-5-WXbHcku"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "\n",
        "def not_break(sen):\n",
        "    return (sen != '\\n' and sen != '\\u3000' and  sen != '' and not sen.isspace())\n",
        "def filter_data(ini_data):\n",
        "    new_data = list(filter(not_break, [data.strip() for data in ini_data]))\n",
        "    return new_data"
      ],
      "metadata": {
        "id": "8Qh1kaG0UaXS"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 略加修改\n",
        "import gc\n",
        "kw = extract_kw(cleaned_arti)\n",
        "for i in range(len(kw)):\n",
        "    kw[i] = kw[i].astype('<U5000')\n",
        "\n",
        "headline = np.array(cleaned_arti['headline'])\n",
        "def recon_kw(kw, headline, cleaned_arti, cleaned_comm):\n",
        "    data_list = []\n",
        "    sample_num = 5\n",
        "    sample_comment_set = []\n",
        "    sample_comment_set_atten_mask = []\n",
        "    edge_connection_box, edge_feat_box = [], []\n",
        "    #divider\n",
        "    english_punctuation = string.punctuation\n",
        "    eng_punc = '|'.join([c for c in english_punctuation])\n",
        "    eng_punc  = eng_punc[:-5] + eng_punc[-3:]\n",
        "\n",
        "    uni_id = np.array(cleaned_arti['uniqueID'])\n",
        "\n",
        "    #construct abstract set\n",
        "    abstract_set = np.array(cleaned_arti['abstract'])\n",
        "    #iterate through each article\n",
        "    for i, id in enumerate(tqdm(uni_id)):\n",
        "\n",
        "        #find corresponding comments set\n",
        "        idx = np.where(np.array(cleaned_comm['articleID']) == id)\n",
        "        comment_set = np.array(cleaned_comm['commentBody'])[idx]\n",
        "\n",
        "        #constract abstract in sentence for one id\n",
        "        abstract = abstract_set[i]\n",
        "        abstract_kw = filter_data(re.split(r''+(\"[\"+eng_punc+\"]\"), abstract))\n",
        "        abstract_kw = [abstract.strip('\\n') for abstract in abstract_kw]\n",
        "        \n",
        "        #iterate through each comment, construct comment set\n",
        "        comm_list = []\n",
        "        comm_kw = []\n",
        "        for comm in comment_set:\n",
        "            comm_k = re.sub(u\"([^\\u0061-\\u007a\\u0030-\\u0039\\u0020\\u0041-\\u005a])\", \"\", comm.strip('\\n'))\n",
        "            comm1 = comm_k.split(' ')\n",
        "            comm_list.extend(comm1)\n",
        "            comm_k = comm.strip('\\n')\n",
        "            comm_kw.append(comm_k)\n",
        "        \n",
        "        #construct dict\n",
        "        comm_dict = {}\n",
        "        for comm in comm_list:\n",
        "            if comm in comm_dict:\n",
        "                comm_dict[comm] += 1\n",
        "            else:\n",
        "                comm_dict[comm] = 1\n",
        "        \n",
        "        # take out the top10\n",
        "        top = 10\n",
        "        freq_threshold = 10\n",
        "        stop_words = 50\n",
        "\n",
        "        # rank comm_dict\n",
        "        comm_dict = np.array(sorted(comm_dict.items(), key=lambda item:item[1], reverse=True))[stop_words:]\n",
        "        comm_kw_list = np.array(comm_dict[:, 0])\n",
        "        freq_list = np.array(np.array(comm_dict[:, 1], dtype=np.int64))\n",
        "\n",
        "        # append keywords\n",
        "        #************************************************************************************\n",
        "        # delete stop words\n",
        "        idx = np.where(freq_list >= freq_threshold)[0]\n",
        "        kw[i] = np.concatenate((kw[i], comm_kw_list[idx])) if len(idx) <= top else np.concatenate((kw[i], comm_kw_list[:top]))\n",
        "        kw[i] = np.unique(kw[i])\n",
        "\n",
        "        # append headline at the end of each graph\n",
        "        headline[i] = headline[i].strip('\\n')\n",
        "        headline[i] =  np.delete(headline[i], np.where(headline[i] == ''))\n",
        "        kw[i] = np.concatenate((kw[i], headline[i]))\n",
        "\n",
        "\n",
        "        #add our keyword to tokenizer\n",
        "        for word in kw[i]:\n",
        "            tokenizer.add_tokens([word])\n",
        "\n",
        "        #resize BERTmodel\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "        # copy kw, without the first empty node\n",
        "        kw_copy = kw[i].copy()\n",
        "\n",
        "\n",
        "        #sample several comments as target\n",
        "        random_idx = np.arange(len(comm_kw))\n",
        "        np.random.shuffle(random_idx)\n",
        "        sample_idx = random_idx[:sample_num]\n",
        "        sample_comment = np.zeros((sample_num, 200))\n",
        "        sample_comment_mask = np.zeros((sample_num, 200))\n",
        "        for idx in range(len(sample_idx)):\n",
        "            selected_comm = comm_kw[idx]\n",
        "            sample_encoding = tokenizer.encode_plus(selected_comm, padding='max_length',add_special_tokens=True, max_length=200, truncation=True, return_attention_mask=True)\n",
        "            sample_comment[idx] = sample_encoding['input_ids']\n",
        "            sample_comment_mask[idx] = sample_encoding['attention_mask']\n",
        "            del comm_kw[idx]\n",
        "            gc.collect()\n",
        "        sample_comment_set.append(sample_comment)\n",
        "        sample_comment_set_atten_mask.append(sample_comment_mask)\n",
        "\n",
        "        # add comment and abstract to node\n",
        "        comm_kw.extend(abstract_kw)\n",
        "        docs = comm_kw\n",
        "\n",
        "        counter = np.zeros(len(docs))\n",
        "        counter_edge = np.zeros((len(kw_copy[:-1]), len(docs)))\n",
        "        \n",
        "        # add corresponding sentences to keywords\n",
        "        #************************************************************************************\n",
        "        for j, single_kw in enumerate(kw_copy[:-1]):\n",
        "            # convert to word\n",
        "            single_kw_set = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", single_kw.strip('\\n').lower()).split(' ')\n",
        "            for k, doc in enumerate(docs):  \n",
        "                doc_copy = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", doc.strip('\\n').lower())\n",
        "                exist = 0\n",
        "                for s_kw in single_kw_set:\n",
        "                    if s_kw in doc_copy.split(' ') and exist == 0:\n",
        "                        exist = 1\n",
        "                        kw[i][j] += ' '\n",
        "                        kw[i][j] = np.char.add(kw[i][j], doc)\n",
        "                        counter[k] += 1\n",
        "                        counter_edge[j, k] += 1\n",
        "                    else:\n",
        "                        pass\n",
        "        #************************************************************************************\n",
        "\n",
        "\n",
        "\n",
        "        # construct empty node \n",
        "        empty_node = np.array([''], dtype='<U10000')\n",
        "        kw[i] = np.concatenate((empty_node, kw[i]))\n",
        "        \n",
        "        # add doc to empty node\n",
        "        if len(np.where(counter == 0)[0]) != 0:\n",
        "            empty_doc = np.array(docs)[np.where(counter == 0)[0]]\n",
        "            kw[i][0] = np.char.add(kw[i][0], ' '.join(empty_doc))\n",
        "\n",
        "        #encode and generate graph.x data file\n",
        "        path = '/content/gdrive/MyDrive/graph/graph_{0:}'.format(i)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        for ith, row in enumerate(kw[i]):\n",
        "            input = tokenizer.encode_plus(row, padding='max_length',add_special_tokens=True, max_length=200, truncation=True, return_attention_mask=True, return_tensors = \"pt\")\n",
        "            torch.save(model(**input)[0][0][1], path + \"/node{0:}.pt\".format(ith))\n",
        "\n",
        "            \n",
        "\n",
        "        # calculate edge\n",
        "        store_edge = []\n",
        "        value_edge = []\n",
        "\n",
        "        for j in range(len(counter_edge)-1):\n",
        "            interaction = np.sum(counter_edge[j] * counter_edge[j+1:], axis=1)\n",
        "            if len(np.where(interaction != 0)[0]) != 0:\n",
        "                if len(value_edge) != 0:\n",
        "                    value_edge.append(np.hstack((value_edge[-1], interaction[np.nonzero(interaction)])))\n",
        "                else:\n",
        "                    value_edge.append(interaction[np.nonzero(interaction)])\n",
        "                \n",
        "                edge = np.vstack((np.array([j for _ in range(len(np.where(interaction != 0)[0]))]), np.where(interaction != 0)[0]+j+1))\n",
        "                \n",
        "                if len(store_edge) != 0:\n",
        "                    store_edge.append(np.hstack((store_edge[-1], edge))) \n",
        "                else:\n",
        "                    store_edge.append(edge)\n",
        "\n",
        "        # edge connection\n",
        "        if len(store_edge) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            edge_for_id = store_edge[-1]\n",
        "        \n",
        "            # copy edge connection\n",
        "            edge_for_id2 = np.zeros_like(edge_for_id)\n",
        "            edge_for_id2[0], edge_for_id2[1] = edge_for_id[1], edge_for_id[0]\n",
        "            edge_connection_box.append(np.hstack((edge_for_id, edge_for_id2)))\n",
        "\n",
        "            # edge feature\n",
        "            edge_feat_for_id = value_edge[-1]\n",
        "\n",
        "            # copy edge feature\n",
        "            edge_feat_box.append(np.hstack((edge_feat_for_id, edge_feat_for_id)))\n",
        "        \n",
        "    return sample_comment_set, sample_comment_set_atten_mask, edge_connection_box, edge_feat_box\n"
      ],
      "metadata": {
        "id": "XichWjhuszfJ"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_comment_set, sample_comment_set_atten_mask, edge_connection, edge_feat = recon_kw(kw, np.array(cleaned_arti['headline']), cleaned_arti, cleaned_comm)"
      ],
      "metadata": {
        "id": "6umU6S33tbN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf6fddd-42d9-437f-86c8-df918bb6a3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▊      | 85/220 [11:20<19:34,  8.70s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the other edge related data file \n",
        "import os\n",
        "\n",
        "path = '/content/gdrive/MyDrive/edge_connection'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/edge_feat'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/sample_comment'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/sample_comment_set_atten_mask'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "\n",
        "for i in range(len(uni_id)):\n",
        "    np.save('/content/gdrive/MyDrive/edge_connection/egde_connection{0:}.npy'.format(i), edge_connection[i])\n",
        "    np.save('/content/gdrive/MyDrive/edge_feat/edge_feat{0:}.npy'.format(i), edge_feat[i])\n",
        "    np.save('/content/gdrive/MyDrive/sample_comment/sample_comment{0:}.npy'.format(i), sample_comment_set[i])\n",
        "    np.save('/content/gdrive/MyDrive/sample_comment_set_atten_mask/sample_comment_set_atten_mask{0:}.npy'.format(i), sample_comment_set_atten_mask[i])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A-XvhsWrtSDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory_tokenizer = '/content/gdrive/MyDrive/tokenizer'\n",
        "tokenizer.save_pretrained(save_directory_tokenizer)\n",
        "\n",
        "save_directory_BERT = '/content/gdrive/MyDrive/BERT'\n",
        "model.save_pretrained(save_directory_BERT)"
      ],
      "metadata": {
        "id": "JxVBV_uQ9kTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph construction"
      ],
      "metadata": {
        "id": "tkuo2EXMyd9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export CPATH=/usr/local/cuda/include:$CPATH\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "save_directory_tokenizer='/content/gdrive/MyDrive/tokenizer'\n",
        "tokenizer = BertTokenizer.from_pretrained(save_directory_tokenizer)\n",
        "\n",
        "save_directory_BERT = '/content/gdrive/MyDrive/BERT'\n",
        "model = BertModel.from_pretrained(save_directory_BERT)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "TjbdRFmHDp7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Dataset, download_url\n",
        "\n",
        "\n",
        "class MyOwnDataset(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['/graph']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        path_graph = '/content/gdrive/MyDrive/graph'\n",
        "        num_file = len(os.listdir(path_graph))\n",
        "        return ['data_' + str(i) for i in range(num_file)]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        path_graph = '/content/gdrive/MyDrive/graph'\n",
        "        path_connect = '/content/gdrive/MyDrive/edge_connection'\n",
        "        path_feat = '/content/gdrive/MyDrive/edge_feat'\n",
        "        num_file = len(os.listdir(path_graph))\n",
        "\n",
        "        idx=0\n",
        "        for i in range(num_file):\n",
        "            path_graphi = path_graph+'/graph_'+str(i)\n",
        "            path_connecti = path_connect+'/egde_connection'+str(i)+'.npy'\n",
        "            path_feati = path_feat+'/edge_feat'+str(i)+'.npy'\n",
        "            num_node = len(os.listdir(path_graphi))\n",
        "            \n",
        "            #load\n",
        "            x = torch.zeros(num_node, 768)\n",
        "            for j in range(num_node):\n",
        "                x[j] = torch.load(path_graphi+'/node{0:}.pt'.format(j))\n",
        "            \n",
        "            edge_index = torch.tensor(np.load(path_connecti), dtype=torch.long)\n",
        "            edge_attr = torch.tensor(np.load(path_feati))\n",
        "\n",
        "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "            idx += 1\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        return data"
      ],
      "metadata": {
        "id": "MNlVxliwekt4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_x(num, path):\n",
        "#     #load graph data.x file\n",
        "#     path = '/content/gdrive/MyDrive/graph/graph_{0:}'.format(num)\n",
        "#     files = os.listdir(path)   \n",
        "#     num_file = len(files)     \n",
        "\n",
        "#     a = torch.zeros((num_file), 768)\n",
        "#     for i in range(num_file):\n",
        "#         a[i] = torch.load(path+'/node{0:}.pt'.format(i))\n",
        "#     return a\n"
      ],
      "metadata": {
        "id": "CA6GJaWBFEg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_y(sample_comment, sample_comment_atten_mask):\n",
        "    #generate y data file \n",
        "    sample_comment = np.array(sample_comment)\n",
        "    sample_comment_atten_mask = np.array(sample_comment_atten_mask)\n",
        "    num_label_set = sample_comment.shape[1]\n",
        "    for i in tqdm(range(num_label_set)):\n",
        "        label_set = sample_comment[:, i, :]\n",
        "        label_set_atten_mask = sample_comment_atten_mask[:, i, :]\n",
        "        num_label = label_set.shape[0]\n",
        "        \n",
        "        #vector y path\n",
        "        path = '/content/gdrive/MyDrive/label_set{0:}'.format(i)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        #scalar y path\n",
        "        path_scalar = '/content/gdrive/MyDrive/scalar_label_set{0:}'.format(i)\n",
        "        if not os.path.exists(path_scalar):\n",
        "            os.makedirs(path_scalar)\n",
        "\n",
        "        for j in range(num_label):\n",
        "            label_tensor = torch.tensor(label_set[j], dtype=torch.long).view(1,-1)\n",
        "            label_mask_tensor = torch.tensor(label_set_atten_mask[j], dtype=torch.long).view(1,-1)\n",
        "            torch.save(model(label_tensor, label_mask_tensor)[0][0], path + \"/label{0:}.pt\".format(j))\n",
        "            torch.save(label_tensor, path_scalar+\"/label{0:}.pt\".format(j))\n",
        "\n",
        "def gen_loader_Y(path, sample_num=5, bs=32):\n",
        "    #generate y dataloader\n",
        "    loader_list = []\n",
        "    for i in range(sample_num):\n",
        "        ydataset = YDataset(path, i)\n",
        "        yloader = torch.utils.data.DataLoader(ydataset, batch_size=bs, shuffle=False, num_workers=2)\n",
        "        loader_list.append(yloader)\n",
        "    return loader_list\n"
      ],
      "metadata": {
        "id": "BdqjMFzxeb6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, num_set):\n",
        "        super(YDataset, self).__init__()\n",
        "        self.path = path \n",
        "        self.num_set = num_set\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.path + str(self.num_set) + '/label' + str(index) + '.pt'\n",
        "        return torch.load(path).cpu().detach().numpy()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.path+str(self.num_set)))"
      ],
      "metadata": {
        "id": "2WZh6sAU-Ofn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate y data file\n",
        "path = '/content/gdrive/MyDrive/label_set0'\n",
        "if not os.path.exists(path):\n",
        "    path = '/content/gdrive/MyDrive/graph/' \n",
        "    files = os.listdir(path)   \n",
        "    num_file = len(files)       \n",
        "\n",
        "    #graph.x file has been generated by recon_kw\n",
        "    #generate sample\n",
        "    sample_comment = []\n",
        "    sample_comment_atten_mask = []\n",
        "\n",
        "    for i in tqdm(range(num_file)):\n",
        "        sample_comment.append(np.load('/content/gdrive/MyDrive/sample_comment/sample_comment{0:}.npy'.format(i)))\n",
        "        sample_comment_atten_mask.append(np.load('/content/gdrive/MyDrive/sample_comment_set_atten_mask/sample_comment_set_atten_mask{0:}.npy'.format(i)))\n",
        "    gen_y(sample_comment, sample_comment_atten_mask)"
      ],
      "metadata": {
        "id": "fxBD4qnTgDHv"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN with fixed pretrained embedding"
      ],
      "metadata": {
        "id": "ucPROchYOghj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GraphEncoder(torch.nn.Module):\n",
        "    def __init__(self, embedding_size):\n",
        "        super(GraphEncoder, self).__init__()\n",
        "        self.embedding_size = embedding_size        \n",
        "        self.hidden_size = 768\n",
        "        #GCN encoder\n",
        "        self.conv1 = GCNConv(self.embedding_size, 768)\n",
        "        self.conv2 = GCNConv(768, 768)\n",
        "        self.fc = nn.Linear(768, 768)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "    \n",
        "        ## 1. GCN\n",
        "        x_ = self.conv1(x, edge_index, edge_attr)\n",
        "        x_ = F.relu(x_)\n",
        "        ## residual connection\n",
        "        x_ += x\n",
        "        x_ = x_.to(torch.float32)\n",
        "        x_ = self.conv2(x_, edge_index, edge_attr)\n",
        "        x_ = x_.to(torch.float32)\n",
        "        x_ = torch.tanh(self.fc(x_)) #num_nodes, embedding_size --> num_nodes, encoder_hidden_size\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, units, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, units)\n",
        "        self.W2 = nn.Linear(hidden_size, units)\n",
        "        self.V = nn.Linear(units, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, batch_size, query, values):\n",
        "        #query: init_hidden_state: headline embedding: 1, embedding_size\n",
        "        #values: encoder_output_embeeding: 1, bs, embedding_size\n",
        "        query = query.view(batch_size, 1, -1) # bs, 1, embedding_size\n",
        "        score = self.V(self.tanh(self.W1(values) + self.W2(query))) #bs, num_nodes, attention_hidden_size -> bs, num_nodes, 1\n",
        "        attention_weights = self.softmax(score) #bs, num_nodes, 1\n",
        "        context_vector = torch.sum(attention_weights * values, 1) #bs, embedding_size == bs, encoder_hidden_size\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "class GRUDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, dec_units, encoder_hidden_size):\n",
        "        super(GRUDecoder, self).__init__()\n",
        "        #GRU Decoder\n",
        "        self.dec_units = dec_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.encoder_hidden_size = encoder_hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.encoder_hidden_size,\n",
        "            hidden_size=self.dec_units\n",
        "        )\n",
        "        self.fc_input = nn.Linear(768, self.embedding_size)\n",
        "        self.fc = nn.Linear(self.dec_units, self.vocab_size)\n",
        "        self.attention = BahdanauAttention(self.dec_units, self.encoder_hidden_size)\n",
        "        self.attn_combine = nn.Linear(self.embedding_size + self.encoder_hidden_size, self.dec_units)\n",
        "\n",
        "    def forward(self, batch_size, x, hidden, enc_output):\n",
        "        #x: bs, bs, encoder_hidden_size\n",
        "        #hidden: 1, bs, encoder_hidden_size\n",
        "        #enc_output: num_nodes, bs, encoder_hidden_size\n",
        "        #output -> embedding\n",
        "        x = self.fc_input(x).view(1, batch_size, -1) #1, bs, embedding_size\n",
        "\n",
        "        hidden = hidden.view(1, batch_size, -1) # 1, bs, encoder_hidden_size\n",
        "\n",
        "        context_vector, attention_weights = self.attention(batch_size, hidden, enc_output) #1, encoder_hidden_size\n",
        "\n",
        "        context_vector = context_vector.unsqueeze(0) # 1, 1, encoder_hidden_size\n",
        "\n",
        "        #concatenate x and context_vector\n",
        "        x = torch.cat((context_vector, x), -1) #1, 1, embedding_size + encoder_hidden_size\n",
        "\n",
        "        x = self.attn_combine(x) #1, 1, dec_units\n",
        "\n",
        "        #pass to GRU\n",
        "        output, hn = self.gru(x, hidden)\n",
        "\n",
        "        #classification\n",
        "        output = self.fc(output[0]) #1, vocab_size\n",
        "\n",
        "        output = F.log_softmax(output, dim=1) #1, vocab_size\n",
        "\n",
        "        return output, hn \n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "7qR_BIoyOi7E"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_num_nodes(path, num_file):\n",
        "    len_list = []\n",
        "    for i in range(num_file):\n",
        "        len_list.append(len(os.listdir(path+'/graph_'+str(i))))\n",
        "    return max(len_list)\n"
      ],
      "metadata": {
        "id": "JAba770dO4Lx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/graph/' \n",
        "files = os.listdir(path)   \n",
        "num_file = len(files)  \n",
        "\n",
        "max_num_nodes = get_max_num_nodes('/content/gdrive/MyDrive/graph', num_file)\n",
        "batchsize = 32\n",
        "\n",
        "#graph dataset\n",
        "graph_dataset = MyOwnDataset('/content/gdrive/MyDrive')\n",
        "graph_loader = DataLoader(graph_dataset, batchsize, shuffle=False)\n",
        "\n",
        "#vector y dataloader\n",
        "path = '/content/gdrive/MyDrive/label_set'\n",
        "Y_loader_list = gen_loader_Y(path, bs=batchsize)\n",
        "\n",
        "#scalar y dataloader\n",
        "path = '/content/gdrive/MyDrive/scalar_label_set'\n",
        "y_loader_list = gen_loader_Y(path, bs=batchsize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7zMccVZ0ybK",
        "outputId": "d0da0e8d-781f-4854-8572-c0287b255b7e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "#training\n",
        "embedding_size = 768\n",
        "dec_units = 768\n",
        "encoder_hidden_size = 768\n",
        "vocab_size = len(tokenizer)\n",
        "lr = 1e-3\n",
        "num_sample = 5\n",
        "epochs = 5\n",
        "\n",
        "\n",
        "#model\n",
        "graph_encoder = GraphEncoder(768).to(device)\n",
        "GRU_decoder = GRUDecoder(vocab_size, embedding_size, dec_units, encoder_hidden_size).to(device)\n",
        "\n",
        "#loss definition\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "#optimizer\n",
        "encoder_optimizer = optim.Adam(graph_encoder.parameters(), lr=lr)\n",
        "decoder_optimizer = optim.Adam(GRU_decoder.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "for i in range(num_sample):\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for data, y, scalar_y in zip(graph_loader, Y_loader_list[i], y_loader_list[i]):\n",
        "            batchsize = y.shape[0]\n",
        "            loss = 0\n",
        "            \n",
        "            data = data.to(device)\n",
        "            y = y.to(device).transpose(0, 1) #200, bs, 768\n",
        "            scalar_y = torch.squeeze(scalar_y.to(device)).transpose(0, 1)\n",
        "\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "            \n",
        "            #encoder\n",
        "            x_encode = graph_encoder(data) # bs*num_nodes, encoder_hidden_size\n",
        "\n",
        "            #grasp corresponding x and generate decoder hidden\n",
        "            encoder_outputs = torch.zeros(batchsize, max_num_nodes, graph_encoder.hidden_size).to(device)\n",
        "            decoder_hidden = torch.zeros(batchsize, 1, graph_encoder.hidden_size).to(device)\n",
        "            idx = data.batch.cpu().numpy()\n",
        "            start_idx = 0\n",
        "            for batch_num in range(batchsize):\n",
        "                idx_list = np.where(idx==batch_num)[0]\n",
        "                graph_data = x_encode[idx_list]\n",
        "                encoder_outputs[batch_num, :len(idx_list)] = graph_data\n",
        "                #find headline vertex \n",
        "                decoder_hidden[batch_num] = graph_data[-1].view(1, -1)\n",
        "            encoder_outputs.transpose(0, 1) #max_num_nodes, bs, encoder_hidden_size\n",
        "            decoder_hidden.transpose(0, 1) # 1, bs, encoder_hidden_size\n",
        "\n",
        "\n",
        "            #teacher forcing\n",
        "            for t in range(y.shape[0]-1):\n",
        "                dec_input = y[t] # \n",
        "                predictions, decoder_hidden = GRU_decoder(batchsize, dec_input, decoder_hidden, encoder_outputs)\n",
        "                loss += criterion(predictions, scalar_y[t+1])\n",
        "\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()/y.shape[0]\n",
        "\n",
        "        print('Epoch: {0:} \\t Loss: {1:3f}'.format(epoch, running_loss))\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "n_GSP8NQFvfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Top1"
      ],
      "metadata": {
        "id": "pIUYYeaJEJRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_encode = graph_encoder(data)\n",
        "dec_input = torch.tensor([101], device=device)\n",
        "dec_hidden = x_encode[-1]\n",
        "decode = []\n",
        "idx_list = []\n",
        "for _ in range(200):\n",
        "    predictions, dec_hidden = GRU_decoder(dec_input, dec_hidden, x_encode, weight)\n",
        "    idx = torch.argmax(predictions, 1)\n",
        "    idx_list.append(idx.data.cpu().numpy()[0])\n",
        "    dec_input = idx\n",
        "decode = tokenizer.decode(np.array(idx_list))\n"
      ],
      "metadata": {
        "id": "Akyl912Nn4Vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode"
      ],
      "metadata": {
        "id": "y2uSpC8Z-wRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TopK"
      ],
      "metadata": {
        "id": "0eGeCOK8EKfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_encode, weight = graph_encoder(data, mask)\n",
        "dec_input = torch.tensor([101], device=device)\n",
        "dec_hidden = x_encode[-1]\n",
        "decode = []\n",
        "idx_list = []\n",
        "for _ in range(200):\n",
        "    predictions, dec_hidden = GRU_decoder(dec_input, dec_hidden, x_encode, weight)\n",
        "    a, idx = predictions.topk(2)\n",
        "    idx_list.append(idx.cpu().numpy()[0,1])\n",
        "    dec_input = idx[0, 1]\n",
        "decode = tokenizer.decode(np.array(idx_list))\n"
      ],
      "metadata": {
        "id": "d982nISooC7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GbLhfHFz15VJ",
        "outputId": "29cb893d-a96d-44f2-9289-8c985fa0462c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"- said i was also a packers put fan - was root qb to the vikings their brett. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for num in sample:\n",
        "    res = tokenizer.decode(num)\n",
        "    print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-5ZQykO2UAc",
        "outputId": "54a059ac-d953-491f-f068-ada55b6987b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] i was shocked that the vikings held on. i was even more shocked that new england was not only a wild card contender but ac tua lly lost in the end. i guess the only that that could surprise me more would be if my beloved packers ac tua lly beat seattle and if minn esota made it to the super bowl. what a wild and crazy nfl season thus far. while the 49ers and seahawks are tough and consistent, i stopped assuming any one team will be in the super bowl this year. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ marge keller i thought seattle looked awful. it was a close game even with the eagle's 40 year old qb. i am surprised they play so well against sf. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ jsailor really? i thought their defense was pretty sharp. i was almost embarrassed by how the eagles played. funny how folks can have such differing recollections when viewing the same game. t hanks much for your comment. much appreciated. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ doon i really like your assessment! the biggest thrill for me will be if / when the vikings ac tua lly become the bride rather than bridesmaids. but they have to get to the super bowl first. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ doon - well said. i'm a packers fan and i was rooting for the vikings in this game. as i recall sean payton was also suspended for a year for allowing his players to put a \" bounty \" on the viking players when brett was their qb. i have no sympathy for sean payton. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM example"
      ],
      "metadata": {
        "id": "8j6XLsKOxudP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample LSTM text generator\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self, text_df\n",
        "    ):\n",
        "        self.text_df = text_df\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.sequence_length = 4\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    # here I load all the words in all nodes for one graph, it should be fixed...\n",
        "    def load_words(self):\n",
        "        text_arr = np.array(self.text_df)\n",
        "        text = \"\"\n",
        "        for i in range(len(text_arr)):\n",
        "            text += text_arr[i][0] + \" \"\n",
        "        return text.split(' ')\n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# LSTM\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
        "        \n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(dataset, model):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=256\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        state_h, state_c = model.init_state(4)\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "\n",
        "def predict(dataset, model, text, next_words=100):\n",
        "    words = text.split(' ')\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "dataset = Dataset(df)\n",
        "model = Model(dataset)\n",
        "\n",
        "train(dataset, model)"
      ],
      "metadata": {
        "id": "k23VjARD7GHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transformer encoder example"
      ],
      "metadata": {
        "id": "QLu5qU6_xyG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = transformer_encoder(src)"
      ],
      "metadata": {
        "id": "nqkdnu3aHgoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8OVWHGDiiPD",
        "outputId": "3bcba31f-921b-4543-abf0-7617733c9dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 32, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uE3IQXVujKZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uDF6rHXQ2YtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "text = \"The capital of France contains the Eiffel Tower.\"\n",
        "input = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
        "output = model(**input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dysWTlnqa1eB",
        "outputId": "61c4f7ff-9856-4bf1-c5a6-3bb99c46f854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59HGZyYYfDSm",
        "outputId": "3d640297-f016-4005-a1f0-42c99e502a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"The capital of France contains the Eiffel Tower.\"]\n",
        "input = tokenizer.encode_plus(text, return_tensors = \"pt\")"
      ],
      "metadata": {
        "id": "-xD9fnCidlaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode_plus(text, add_special_tokens = True,  truncation = True, padding = \"max_length\", return_attention_mask = True, return_tensors = \"pt\")"
      ],
      "metadata": {
        "id": "wmYENNtydo4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}