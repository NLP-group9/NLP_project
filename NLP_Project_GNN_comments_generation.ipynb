{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQh-352-Vy4w"
      },
      "source": [
        "# Load file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4B7dYGPORcr",
        "outputId": "e974df8e-2aad-469a-d883-60f0bca18f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "dir =  '/content/drive/My Drive/Colab Notebooks/UCL/comp0087nlp/archive'\n",
        "dir1 = '/content/drive/My Drive/Colab Notebooks/UCL/comp0087nlp/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkEJ-iiDrN6a",
        "outputId": "303c79eb-eaf6-4a63-c216-81941c525636"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/archive/nyt-articles-2020.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-2020.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part0.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part1.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part2.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part3.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part4.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part5.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part6.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part7.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part8.csv\n",
            "/content/gdrive/MyDrive/archive/nyt-comments-part9.csv\n",
            "/content/gdrive/MyDrive/archive/test.csv\n",
            "/content/gdrive/MyDrive/archive/train.csv\n"
          ]
        }
      ],
      "source": [
        "for dirname, _, filenames in os.walk(dir):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGYRTZhCrxL9"
      },
      "source": [
        "article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1G8ci8frTne",
        "outputId": "674011e1-b721-4f5e-f92f-9e89364f430b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 16787 rows and 11 columns\n"
          ]
        }
      ],
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-articles-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df1 = pd.read_csv(dir+'/nyt-articles-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df1.dataframeName = 'nyt-articles-2020.csv'\n",
        "nRow, nCol = df1.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZBxuoC1rfdk",
        "outputId": "01384bfa-6943-4f2b-ceda-14eb6d7c2951"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c6f10af-3313-41de-a8b5-4027fb38f3ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>newsdesk</th>\n",
              "      <th>section</th>\n",
              "      <th>subsection</th>\n",
              "      <th>material</th>\n",
              "      <th>headline</th>\n",
              "      <th>abstract</th>\n",
              "      <th>keywords</th>\n",
              "      <th>word_count</th>\n",
              "      <th>pub_date</th>\n",
              "      <th>n_comments</th>\n",
              "      <th>uniqueID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Editorial</td>\n",
              "      <td>Opinion</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Editorial</td>\n",
              "      <td>Protect Veterans From Fraud</td>\n",
              "      <td>Congress could do much more to protect America...</td>\n",
              "      <td>['Veterans', 'For-Profit Schools', 'Financial ...</td>\n",
              "      <td>680</td>\n",
              "      <td>2020-01-01 00:18:54+00:00</td>\n",
              "      <td>186</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Games</td>\n",
              "      <td>Crosswords &amp; Games</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "      <td>‘It’s Green and Slimy’</td>\n",
              "      <td>Christina Iverson and Jeff Chen ring in the Ne...</td>\n",
              "      <td>['Crossword Puzzles']</td>\n",
              "      <td>931</td>\n",
              "      <td>2020-01-01 03:00:10+00:00</td>\n",
              "      <td>257</td>\n",
              "      <td>nyt://article/9edddb54-0aa3-5835-a833-d311a76f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Science</td>\n",
              "      <td>Science</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "      <td>Meteor Showers in 2020 That Will Light Up Nigh...</td>\n",
              "      <td>All year long, Earth passes through streams of...</td>\n",
              "      <td>['Meteors and Meteorites', 'Space and Astronom...</td>\n",
              "      <td>1057</td>\n",
              "      <td>2020-01-01 05:00:08+00:00</td>\n",
              "      <td>6</td>\n",
              "      <td>nyt://article/04bc90f0-b20b-511c-b5bb-3ce13194...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Science</td>\n",
              "      <td>Science</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Interactive Feature</td>\n",
              "      <td>Sync your calendar with the solar system</td>\n",
              "      <td>Never miss an eclipse, a meteor shower, a rock...</td>\n",
              "      <td>['Space and Astronomy', 'Moon', 'Eclipses', 'S...</td>\n",
              "      <td>0</td>\n",
              "      <td>2020-01-01 05:00:12+00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>nyt://interactive/5b58d876-9351-50af-9b41-a312...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Science</td>\n",
              "      <td>Science</td>\n",
              "      <td>NaN</td>\n",
              "      <td>News</td>\n",
              "      <td>Rocket Launches, Trips to Mars and More 2020 S...</td>\n",
              "      <td>A year full of highs and lows in space just en...</td>\n",
              "      <td>['Space and Astronomy', 'Private Spaceflight',...</td>\n",
              "      <td>1156</td>\n",
              "      <td>2020-01-01 05:02:38+00:00</td>\n",
              "      <td>25</td>\n",
              "      <td>nyt://article/bd8647b3-8ec6-50aa-95cf-2b81ed12...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c6f10af-3313-41de-a8b5-4027fb38f3ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c6f10af-3313-41de-a8b5-4027fb38f3ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c6f10af-3313-41de-a8b5-4027fb38f3ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    newsdesk             section subsection             material  \\\n",
              "0  Editorial             Opinion        NaN            Editorial   \n",
              "1      Games  Crosswords & Games        NaN                 News   \n",
              "2    Science             Science        NaN                 News   \n",
              "3    Science             Science        NaN  Interactive Feature   \n",
              "4    Science             Science        NaN                 News   \n",
              "\n",
              "                                            headline  \\\n",
              "0                        Protect Veterans From Fraud   \n",
              "1                             ‘It’s Green and Slimy’   \n",
              "2  Meteor Showers in 2020 That Will Light Up Nigh...   \n",
              "3           Sync your calendar with the solar system   \n",
              "4  Rocket Launches, Trips to Mars and More 2020 S...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  Congress could do much more to protect America...   \n",
              "1  Christina Iverson and Jeff Chen ring in the Ne...   \n",
              "2  All year long, Earth passes through streams of...   \n",
              "3  Never miss an eclipse, a meteor shower, a rock...   \n",
              "4  A year full of highs and lows in space just en...   \n",
              "\n",
              "                                            keywords  word_count  \\\n",
              "0  ['Veterans', 'For-Profit Schools', 'Financial ...         680   \n",
              "1                              ['Crossword Puzzles']         931   \n",
              "2  ['Meteors and Meteorites', 'Space and Astronom...        1057   \n",
              "3  ['Space and Astronomy', 'Moon', 'Eclipses', 'S...           0   \n",
              "4  ['Space and Astronomy', 'Private Spaceflight',...        1156   \n",
              "\n",
              "                    pub_date  n_comments  \\\n",
              "0  2020-01-01 00:18:54+00:00         186   \n",
              "1  2020-01-01 03:00:10+00:00         257   \n",
              "2  2020-01-01 05:00:08+00:00           6   \n",
              "3  2020-01-01 05:00:12+00:00           2   \n",
              "4  2020-01-01 05:02:38+00:00          25   \n",
              "\n",
              "                                            uniqueID  \n",
              "0  nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "1  nyt://article/9edddb54-0aa3-5835-a833-d311a76f...  \n",
              "2  nyt://article/04bc90f0-b20b-511c-b5bb-3ce13194...  \n",
              "3  nyt://interactive/5b58d876-9351-50af-9b41-a312...  \n",
              "4  nyt://article/bd8647b3-8ec6-50aa-95cf-2b81ed12...  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ul50KM2rzeM"
      },
      "source": [
        "comment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lARaxsdtrmiG",
        "outputId": "1593b911-d738-4046-989b-6980996a3182"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 4986461 rows and 23 columns\n"
          ]
        }
      ],
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-comments-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df2 = pd.read_csv( dir+'/nyt-comments-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df2.dataframeName = 'nyt-comments-2020.csv'\n",
        "nRow, nCol = df2.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0S__w1jr4rf"
      },
      "outputs": [],
      "source": [
        "article = np.array(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSIxXpKVtuUN"
      },
      "outputs": [],
      "source": [
        "comments = np.array(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4sjXW5pyxFU"
      },
      "source": [
        "# Data cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akvF2EghyytA"
      },
      "source": [
        "Article cleaning \\\\\n",
        "列数从0开始 \\\\\n",
        "第1列 第2列不出现 politics \\\\\n",
        "第6列不出现 [] \\\\\n",
        "第7列筛选文章词数大于50 \\\\\n",
        "第9列筛选comments个数大于50 \\\\\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY9i-F7t1F51"
      },
      "outputs": [],
      "source": [
        "#只保留sports和movies\n",
        "df1_1 = df1.drop(df1[df1['section'] != 'Sports'].index)\n",
        "df1_2 = df1.drop(df1[df1['section'] != 'Movies'].index)\n",
        "cleaned_arti = pd.concat([df1_1, df1_2])\n",
        "#第六列不出现空\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['keywords'] == '[]'].index)\n",
        "#第七列筛选次数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['word_count'] < 50].index)\n",
        "#第九列comments个数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['n_comments'] < 50].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj2NhbCZ6D7p"
      },
      "outputs": [],
      "source": [
        "#取出对应的article id\n",
        "uni_id = cleaned_arti['uniqueID'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvukWqHq8HLE"
      },
      "outputs": [],
      "source": [
        "#article只保留四列\n",
        "cleaned_arti = cleaned_arti[['headline','abstract','keywords', 'uniqueID']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lG4K6bjD0BE9"
      },
      "source": [
        "Comments cleaning \\\\\n",
        "根据cleaned article筛选comments \\\\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJfNgUgi65t3"
      },
      "outputs": [],
      "source": [
        "cleaned_comm = df2[df2['articleID'].isin(uni_id)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TnepgQb8j_C"
      },
      "outputs": [],
      "source": [
        "cleaned_comm = cleaned_comm[['commentBody','articleID']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjVo2aKAV5vx"
      },
      "source": [
        "# Node extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPzAYx7UI3rZ"
      },
      "source": [
        "reconstruct keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awoyXGsss6Vs",
        "outputId": "1c798322-e55a-4a27-d8f7-91649ddb2427"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "\n",
        "# new version\n",
        "def extract_kw(cleaned_arti):\n",
        "    # stop words in English\n",
        "    stop = set(stopwords.words('english')) \n",
        "    #extract keywords from cleaned article\n",
        "    kw_set = np.array(cleaned_arti['keywords'])\n",
        "    for i, kw in enumerate(kw_set):\n",
        "        kw = kw.split(',')\n",
        "        for j in range(len(kw)):\n",
        "            kw[j] = re.sub(u\"([^\\u0041-\\u005a\\u0061-\\u007a\\u0020])\", \"\", kw[j])\n",
        "            kw[j] = kw[j].strip()\n",
        "        kw = np.array([i for i in kw if i != \"\" and i not in stop])\n",
        "        kw_set[i] = np.unique(kw)\n",
        "    return kw_set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811,
          "referenced_widgets": [
            "bf6ce23fdd124f95a8ede96e95127447",
            "07e37d47ccd44d7b8309a51755037298",
            "51341fc3245945b7a50cd4b6a4dba09a",
            "521efa670ba74d4a80c9217b1acbf350",
            "510462e3f44f4c2984d272e1db94681e",
            "b95560abaafe4151bd8949da721655e3",
            "c4da20c2c6704c84845959bbd313deaf",
            "cfd9b6c71a7c44739428059442f4deb8",
            "efbfb597d6b84c428514219bfb00ecfd",
            "a0d2ac2361384ee1b6d544d1006ff767",
            "5525448f676543ea9f87e21251b03a60",
            "729591fe8e074ff19b5d424dff3e175d",
            "b250c03863564294b81d73b6e82f07a2",
            "7d23ffff25d446619b04a2c141a4530d",
            "11af1f31a11347da8f33e4a33efe197d",
            "f07dfb3862a145baa46af06275f0d687",
            "bc123d9650714a6e86be998d537ec47d",
            "7fbfbbd4f21f451ba1332b2a1c12c881",
            "19eb1916d00a431dad9276d42f7488c9",
            "6378c0dd00cc467dbcb4cdaa60e490d6",
            "b0cf05f4fa8d4d3a84b0ff761d72bbd2",
            "c32b161aacbe4f4289648b7f72356107",
            "04a1589a26cb4dbb9d36552bccfe4c10",
            "99c6a9ee1c2245dd885d7fbee44d5785",
            "d2e301a298ca4e49ac3d5b73ae513d9f",
            "cfd57b2075d2436dbe10d925f328cc89",
            "8be1a314117b4580aba77e700501200f",
            "462008e3083749389fc34efa0649cf83",
            "efbfb924b5a640f08bd9e8b5b3e3d4f6",
            "91ef0f2de27c4c6a8d620d943a85e379",
            "64201a5140aa4da8b3a670fbcd03c169",
            "a9954457edfa402592b7547dd1127ab0",
            "8db5a6700b534942ad6aa6bb179b4f97"
          ]
        },
        "id": "j4lgrRSagGis",
        "outputId": "62289265-95b2-467a-9d4e-ba8dae4ff57a"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD-5-WXbHcku"
      },
      "outputs": [],
      "source": [
        "kw = extract_kw(cleaned_arti)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Qh1kaG0UaXS"
      },
      "outputs": [],
      "source": [
        "import string \n",
        "\n",
        "def not_break(sen):\n",
        "    return (sen != '\\n' and sen != '\\u3000' and  sen != '' and not sen.isspace())\n",
        "def filter_data(ini_data):\n",
        "    new_data = list(filter(not_break, [data.strip() for data in ini_data]))\n",
        "    return new_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XichWjhuszfJ"
      },
      "outputs": [],
      "source": [
        "# 略加修改\n",
        "kw = extract_kw(cleaned_arti)\n",
        "for i in range(len(kw)):\n",
        "    kw[i] = kw[i].astype('<U5000')\n",
        "\n",
        "\n",
        "def recon_kw(kw, headline, cleaned_arti, cleaned_comm):\n",
        "    sample_num = 5\n",
        "    sample_comment_set = []\n",
        "    edge_connection_box, edge_feat_box = [], []\n",
        "    #divider\n",
        "    english_punctuation = string.punctuation\n",
        "    eng_punc = '|'.join([c for c in english_punctuation])\n",
        "    eng_punc  = eng_punc[:-5] + eng_punc[-3:]\n",
        "\n",
        "    uni_id = np.array(cleaned_arti['uniqueID'])\n",
        "\n",
        "    #construct abstract set\n",
        "    abstract_set = np.array(cleaned_arti['abstract'])\n",
        "\n",
        "    new_kw = [[] for i in range(len(kw))]\n",
        "    new_kw_mask = [[] for i in range(len(kw))]\n",
        "    #iterate through each article\n",
        "    for i, id in enumerate(tqdm(uni_id)):\n",
        "\n",
        "        #find corresponding comments set\n",
        "        idx = np.where(np.array(cleaned_comm['articleID']) == id)\n",
        "        comment_set = np.array(cleaned_comm['commentBody'])[idx]\n",
        "\n",
        "        #constract abstract in sentence for one id\n",
        "        abstract = abstract_set[i]\n",
        "        abstract_kw = filter_data(re.split(r''+(\"[\"+eng_punc+\"]\"), abstract))\n",
        "        # abstract_kw = [re.sub(u\"([^\\u0061-\\u007a\\u0030-\\u0039\\u0020\\u0041-\\u005a])\", \"\", abstract.strip('\\n')) for abstract in abstract_kw]\n",
        "        abstract_kw = [abstract.strip('\\n') for abstract in abstract_kw]\n",
        "        \n",
        "        #iterate through each comment, construct comment set\n",
        "        comm_list = []\n",
        "        comm_kw = []\n",
        "        for comm in comment_set:\n",
        "            comm_k = re.sub(u\"([^\\u0061-\\u007a\\u0030-\\u0039\\u0020\\u0041-\\u005a])\", \"\", comm.strip('\\n'))\n",
        "            comm1 = comm_k.split(' ')\n",
        "            comm_list.extend(comm1)\n",
        "            comm_k = comm.strip('\\n')\n",
        "            comm_kw.append(comm_k)\n",
        "        \n",
        "        #construct dict\n",
        "        comm_dict = {}\n",
        "        for comm in comm_list:\n",
        "            if comm in comm_dict:\n",
        "                comm_dict[comm] += 1\n",
        "            else:\n",
        "                comm_dict[comm] = 1\n",
        "        \n",
        "        # take out the top10\n",
        "        top = 10\n",
        "        freq_threshold = 10\n",
        "        stop_words = 50\n",
        "\n",
        "        # rank comm_dict\n",
        "        comm_dict = np.array(sorted(comm_dict.items(), key=lambda item:item[1], reverse=True))[stop_words:]\n",
        "        comm_kw_list = np.array(comm_dict[:, 0])\n",
        "        freq_list = np.array(np.array(comm_dict[:, 1], dtype=np.int64))\n",
        "\n",
        "        # append keywords\n",
        "        #************************************************************************************\n",
        "        # delete stop words\n",
        "        idx = np.where(freq_list >= freq_threshold)[0]\n",
        "        kw[i] = np.concatenate((kw[i], comm_kw_list[idx])) if len(idx) <= top else np.concatenate((kw[i], comm_kw_list[:top]))\n",
        "        kw[i] = np.unique(kw[i])\n",
        "\n",
        "        # append headline at the end of each graph\n",
        "        # headline[i] = re.sub(u\"([^\\u0061-\\u007a\\u0030-\\u0039\\u0020\\u0041-\\u005a])\", \"\", headline[i].strip('\\n'))\n",
        "        headline[i] = headline[i].strip('\\n')\n",
        "        headline[i] =  np.delete(headline[i], np.where(headline[i] == ''))\n",
        "        kw[i] = np.concatenate((kw[i], headline[i]))\n",
        "\n",
        "\n",
        "        #add our keyword to tokenizer\n",
        "        for word in kw[i]:\n",
        "            tokenizer.add_tokens([word])\n",
        "\n",
        "\n",
        "        # copy kw, without the first empty node\n",
        "        kw_copy = kw[i].copy()\n",
        "\n",
        "\n",
        "        #sample several comments as target\n",
        "        random_idx = np.arange(len(comm_kw))\n",
        "        np.random.shuffle(random_idx)\n",
        "        sample_idx = random_idx[:sample_num]\n",
        "        sample_comment = np.zeros((sample_num, 200))\n",
        "        for idx in range(len(sample_idx)):\n",
        "            selected_comm = comm_kw[idx]\n",
        "            sample_comment[idx] = tokenizer.encode(selected_comm, padding='max_length',add_special_tokens=True, max_length=200, truncation=True)\n",
        "            del comm_kw[idx]\n",
        "        sample_comment_set.append(sample_comment)\n",
        "\n",
        "        # add comment and abstract to node\n",
        "        comm_kw.extend(abstract_kw)\n",
        "        docs = comm_kw\n",
        "\n",
        "        counter = np.zeros(len(docs))\n",
        "        counter_edge = np.zeros((len(kw_copy[:-1]), len(docs)))\n",
        "        \n",
        "        # add corresponding sentences to keywords\n",
        "        #************************************************************************************\n",
        "        # for j, single_kw in enumerate(kw_copy[:-1]):\n",
        "        #     for k, doc in enumerate(docs):\n",
        "        #         if single_kw in doc.split(' '):\n",
        "        #             kw[i][j] += ' '\n",
        "        #             kw[i][j] = np.char.add(kw[i][j], doc)\n",
        "        #             counter[k] += 1\n",
        "        #             counter_edge[j, k] += 1\n",
        "        for j, single_kw in enumerate(kw_copy[:-1]):\n",
        "            # convert to word\n",
        "            single_kw_set = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", single_kw.strip('\\n').lower()).split(' ')\n",
        "            for k, doc in enumerate(docs):  \n",
        "                doc_copy = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", doc.strip('\\n').lower())\n",
        "                exist = 0\n",
        "                for s_kw in single_kw_set:\n",
        "                    if s_kw in doc_copy.split(' ') and exist == 0:\n",
        "                        exist = 1\n",
        "                        kw[i][j] += ' '\n",
        "                        kw[i][j] = np.char.add(kw[i][j], doc)\n",
        "                        counter[k] += 1\n",
        "                        counter_edge[j, k] += 1\n",
        "                    else:\n",
        "                        pass\n",
        "        #************************************************************************************\n",
        "\n",
        "\n",
        "\n",
        "        # construct empty node \n",
        "        empty_node = np.array([''], dtype='<U10000')\n",
        "        kw[i] = np.concatenate((empty_node, kw[i]))\n",
        "        \n",
        "        # add doc to empty node\n",
        "        if len(np.where(counter == 0)[0]) != 0:\n",
        "            empty_doc = np.array(docs)[np.where(counter == 0)[0]]\n",
        "            kw[i][0] = np.char.add(kw[i][0], ' '.join(empty_doc))\n",
        "\n",
        "        #encode\n",
        "        for ith, row in enumerate(kw[i]):\n",
        "            token_ids = tokenizer(row, padding='max_length',add_special_tokens=True, max_length=200, truncation=True)\n",
        "            new_kw[i].append(token_ids['input_ids'])\n",
        "            new_kw_mask[i].append(token_ids['attention_mask'])\n",
        "            \n",
        "\n",
        "        # calculate edge\n",
        "        store_edge = []\n",
        "        value_edge = []\n",
        "\n",
        "        for j in range(len(counter_edge)-1):\n",
        "            interaction = np.sum(counter_edge[j] * counter_edge[j+1:], axis=1)\n",
        "            if len(np.where(interaction != 0)[0]) != 0:\n",
        "                if len(value_edge) != 0:\n",
        "                    value_edge.append(np.hstack((value_edge[-1], interaction[np.nonzero(interaction)])))\n",
        "                else:\n",
        "                    value_edge.append(interaction[np.nonzero(interaction)])\n",
        "                \n",
        "                edge = np.vstack((np.array([j for _ in range(len(np.where(interaction != 0)[0]))]), np.where(interaction != 0)[0]+j+1))\n",
        "                \n",
        "                if len(store_edge) != 0:\n",
        "                    store_edge.append(np.hstack((store_edge[-1], edge))) \n",
        "                else:\n",
        "                    store_edge.append(edge)\n",
        "\n",
        "        # edge connection\n",
        "        if len(store_edge) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            edge_for_id = store_edge[-1]\n",
        "        \n",
        "            # copy edge connection\n",
        "            edge_for_id2 = np.zeros_like(edge_for_id)\n",
        "            edge_for_id2[0], edge_for_id2[1] = edge_for_id[1], edge_for_id[0]\n",
        "            edge_connection_box.append(np.hstack((edge_for_id, edge_for_id2)))\n",
        "\n",
        "            # edge feature\n",
        "            edge_feat_for_id = value_edge[-1]\n",
        "\n",
        "            # copy edge feature\n",
        "            edge_feat_box.append(np.hstack((edge_feat_for_id, edge_feat_for_id)))\n",
        "            \n",
        "    return new_kw, new_kw_mask, sample_comment_set, edge_connection_box, edge_feat_box\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6umU6S33tbN_",
        "outputId": "abb8471e-abd8-46bd-b637-070ada4193b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 220/220 [05:21<00:00,  1.46s/it]\n"
          ]
        }
      ],
      "source": [
        "cleaned_kw, kw_mask, sample_comment_set, edge_connection, edge_feat = recon_kw(kw, np.array(cleaned_arti['headline']), cleaned_arti, cleaned_comm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-XvhsWrtSDB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path = '/content/gdrive/MyDrive/graph_node'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/edge_connection'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/edge_feat'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/sample_comment'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/kw_mask'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "for i in range(len(cleaned_kw)):\n",
        "    np.save(dir1+'/graph_node/node_{0:}.npy'.format(i), cleaned_kw[i])\n",
        "    np.save('/content/gdrive/MyDrive/kw_mask/kw_mask_{0:}.npy'.format(i), kw_mask[i])\n",
        "    np.save(dir1+'/edge_connection/egde_connection{0:}.npy'.format(i), edge_connection[i])\n",
        "    np.save(dir1+'/edge_feat/edge_feat{0:}.npy'.format(i), edge_feat[i])\n",
        "    np.save(dir1+'/sample_comment/sample_comment{0:}.npy'.format(i), sample_comment_set[i])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_directory = '/content/gdrive/MyDrive/tokenizer'\n",
        "tokenizer.save_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkuo2EXMyd9J"
      },
      "source": [
        "# Graph construction 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yATIsE59EwtK",
        "outputId": "e353f8be-837a-40f5-8256-737d578356ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.13)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 220/220 [00:02<00:00, 95.75it/s]\n"
          ]
        }
      ],
      "source": [
        "!export CPATH=/usr/local/cuda/include:$CPATH\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "\n",
        "path = dir1+'/graph_node' \n",
        "files = os.listdir(path)   \n",
        "num_file = len(files)       \n",
        "\n",
        "        \n",
        "def load_npy(path):\n",
        "    x = np.load(path)\n",
        "    return x\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data_list = []\n",
        "sample_comment = []\n",
        "kw_mask = []\n",
        "for i in tqdm(range(num_file)):\n",
        "    x = load_npy(dir1+'/graph_node/node_{0:}.npy'.format(i))\n",
        "    edge_connection = load_npy(dir1+'/edge_connection/egde_connection{0:}.npy'.format(i))\n",
        "    edge_feat = load_npy(dir1+'/edge_feat/edge_feat{0:}.npy'.format(i))\n",
        "    sample_comment.append(load_npy(dir1+'/sample_comment/sample_comment{0:}.npy'.format(i)))\n",
        "    kw_mask.append(load_npy(dir1+'/kw_mask/kw_mask{0:}.npy'.format(i)))\n",
        "    \n",
        "\n",
        "    x = torch.tensor(x).to(device)\n",
        "    edge_index = torch.tensor(edge_connection, dtype=torch.long).to(device)\n",
        "    edge_attr = torch.tensor(edge_feat).to(device)\n",
        "    data_list.append(Data(x=x, edge_index=edge_index, edge_attr=edge_attr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucPROchYOghj"
      },
      "source": [
        "# GCN with random embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fr6LfhROJvNz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qR_BIoyOi7E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class GraphEncoder(torch.nn.Module):\n",
        "    def __init__(self, x, vocab_size, embedding_size):\n",
        "        super(GraphEncoder, self).__init__()\n",
        "        \n",
        "        self.num_node = x.shape[0]\n",
        "        self.num_word = x.shape[1]\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        #Embedding\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        \n",
        "        #positional encoding\n",
        "        # self.positional_encoding_kw = nn.Parameter(torch.rand(1)) #copy to the dimension, i.e. 1 copy to num_nodes, 1, embedding_size\n",
        "        # self.positional_encoding_rest = nn.Parameter(torch.rand(199)) #199 copy to num_nodes, max_len-1, embedding_size\n",
        "\n",
        "        #multi-head attention\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=self.embedding_size, nhead=4)\n",
        "        self.multi_atten = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "\n",
        "        #GCN encoder\n",
        "        self.conv1 = GCNConv(self.embedding_size, 128)\n",
        "        self.conv2 = GCNConv(128, 128)\n",
        "        self.fc = nn.Linear(128, 128)\n",
        "\n",
        "\n",
        "    def forward(self, data, mask):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "        ## 1. embedding layer\n",
        "        x = self.embedding(x) #num_nodes, max_len, embedding_size\n",
        "        \n",
        "        ## 1.1 positional embedding\n",
        "        # positional_encoding_kw = torch.unsqueeze(self.positional_encoding_kw.repeat(self.num_node, self.embedding_size), 1) #num_nodes, 1, embedding_size\n",
        "        # positional_encoding_rest = self.positional_encoding_rest.repeat(self.num_node, self.embedding_size).reshape(self.num_node,-1,self.embedding_size) #num_nodes, max_len-1, embedding_size\n",
        "        # positional_embedding = torch.cat((positional_encoding_kw, positional_encoding_rest), 1) #num_nodes, max_len, embedding_size\n",
        "\n",
        "        # ## add to embedding\n",
        "        # x += positional_embedding #num_nodes, max_len, embedding_size\n",
        "\n",
        "        ## 1.2 multi-head attention\n",
        "        x = torch.transpose(x, 0, 1) # max_len, num_nodes, embedding_size\n",
        "        x = self.multi_atten(x, src_key_padding_mask=mask)\n",
        "        x = torch.transpose(x, 0, 1) #num_nodes, embedding_size \n",
        "        x = x[:, 0] #take out the keywords embedding\n",
        "        ## 2. GCN\n",
        "        \n",
        "        x_ = self.conv1(x, edge_index, edge_attr)\n",
        "        x_ = F.relu(x_)\n",
        "        # x_ = F.dropout(x_, training=self.training)\n",
        "        # ## residual connection\n",
        "        # x_ += x\n",
        "        x_ = x_.to(torch.float32)\n",
        "        x_ = self.conv2(x_, edge_index, edge_attr)\n",
        "        x_ = x_.to(torch.float32)\n",
        "        x_ = torch.tanh(self.fc(x_)) #num_nodes, embedding_size --> num_nodes, encoder_hidden_size\n",
        "\n",
        "        # x = self.conv1(x, edge_index, edge_attr)\n",
        "        # x = F.relu(x)\n",
        "        # x = x.to(torch.float32)\n",
        "        # x = self.fc(x)\n",
        "        # x = torch.tanh(x)\n",
        "\n",
        "        return x, self.embedding.weight\n",
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, units, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, units)\n",
        "        self.W2 = nn.Linear(hidden_size, units)\n",
        "        self.V = nn.Linear(units, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, query, values):\n",
        "        #query: init_hidden_state: headline embedding: 1, embedding_size\n",
        "        #values: encoder_output_embeeding: num_nodes, embedding_size\n",
        "        query = query.view(1, 1, -1) # 1, 1, embedding_size\n",
        "        values = torch.unsqueeze(values, 0) # 1, num_nodes, embedding_size\n",
        "        score = self.V(self.tanh(self.W1(values) + self.W2(query))) #1, num_nodes, attention_hidden_size -> 1, num_nodes, 1\n",
        "        attention_weights = self.softmax(score) #1, num_nodes, 1\n",
        "        context_vector = torch.sum(attention_weights * values, 1) #1, embedding_size == 1, encoder_hidden_size\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "class GRUDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, dec_units, encoder_hidden_size):\n",
        "        super(GRUDecoder, self).__init__()\n",
        "        #GRU Decoder\n",
        "        self.dec_units = dec_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.encoder_hidden_size = encoder_hidden_size\n",
        "    \n",
        "        self.embedding_size = embedding_size\n",
        "        # self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.encoder_hidden_size,\n",
        "            hidden_size=self.dec_units\n",
        "        )\n",
        "        self.fc = nn.Linear(self.dec_units, self.vocab_size)\n",
        "        self.attention = BahdanauAttention(self.dec_units, self.encoder_hidden_size)\n",
        "        self.attn_combine = nn.Linear(self.embedding_size + self.encoder_hidden_size, self.dec_units)\n",
        "\n",
        "    def forward(self, x, hidden, enc_output, weight):\n",
        "        #x: scalar,\n",
        "        #hidden: headline vertex  dec_units == encoder_hidden_size\n",
        "        #enc_output: num_nodes, encoder_hidden_size\n",
        "        #output -> embedding\n",
        "        self.embedding = nn.Embedding.from_pretrained(weight)\n",
        "        x = self.embedding(x).view(1, 1, -1) #1, 1, embedding_size\n",
        "\n",
        "        hidden = hidden.view(1, 1, -1) # 1, 1, encoder_hidden_size\n",
        "\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output) #1, encoder_hidden_size\n",
        "\n",
        "        context_vector = context_vector.unsqueeze(0) # 1, 1, encoder_hidden_size\n",
        "\n",
        "        #concatenate x and context_vector\n",
        "        x = torch.cat((context_vector, x), -1) #1, 1, embedding_size + encoder_hidden_size\n",
        "\n",
        "        x = self.attn_combine(x) #1, 1, dec_units\n",
        "\n",
        "        #pass to GRU\n",
        "        output, hn = self.gru(x, hidden)\n",
        "\n",
        "        #classification\n",
        "        output = self.fc(output[0]) #1, vocab_size\n",
        "\n",
        "        output = F.log_softmax(output, dim=1) #1, vocab_size\n",
        "\n",
        "        return output, hn \n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkBQDNSFflXF"
      },
      "outputs": [],
      "source": [
        "#training\n",
        "embedding_size = 128\n",
        "dec_units = 128\n",
        "encoder_hidden_size = 128\n",
        "vocab_size = 31510\n",
        "lr = 1e-3\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for data, sample in tqdm(zip(data_list, sample_comment)):\n",
        "    #every data corresponding to one model\n",
        "    graph_encoder = GraphEncoder(data.x, vocab_size, embedding_size).to(device)\n",
        "    GRU_decoder = GRUDecoder(vocab_size, embedding_size, dec_units, encoder_hidden_size).to(device)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "    encoder_optimizer = optim.Adam(graph_encoder.parameters(), lr=lr)\n",
        "    decoder_optimizer = optim.Adam(GRU_decoder.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    for target in sample:\n",
        "        for epoch in range(epochs):\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "\n",
        "            target = torch.tensor(target, dtype=torch.long).to(device).reshape(-1, 1)\n",
        "\n",
        "            loss = 0\n",
        "            #encoder\n",
        "            x_encode = graph_encoder(data) # num_nodes * encoder_hidden_size\n",
        "\n",
        "            #decoder initial hidden state: headline vertex\n",
        "            dec_hidden = x_encode[-1] # 1 * encoder_hidden_size\n",
        "\n",
        "\n",
        "            #teacher forcing\n",
        "            for t in range(target.shape[0]-1):\n",
        "                dec_input = target[t] # scalar\n",
        "                predictions, dec_hidden = GRU_decoder(dec_input, dec_hidden, x_encode)\n",
        "                loss += criterion(predictions, target[t+1])\n",
        "\n",
        "\n",
        "            \n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "\n",
        "            print('Epoch: {0:} \\t Loss: {1:3f}'.format(epoch, loss/target.shape[0]))\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biQqbYDgDRdW"
      },
      "source": [
        "## demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7QZjZioDSV8",
        "outputId": "a04ef252-70e7-4fb2-c9aa-ec1ee775b667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 \t Loss: 10.274195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \t Loss: 9.713702\n",
            "Epoch: 2 \t Loss: 9.213662\n",
            "Epoch: 3 \t Loss: 8.724784\n",
            "Epoch: 4 \t Loss: 8.242581\n",
            "Epoch: 5 \t Loss: 7.786588\n",
            "Epoch: 6 \t Loss: 7.371405\n",
            "Epoch: 7 \t Loss: 7.003638\n",
            "Epoch: 8 \t Loss: 6.677536\n",
            "Epoch: 9 \t Loss: 6.380567\n",
            "Epoch: 10 \t Loss: 6.105358\n",
            "Epoch: 11 \t Loss: 5.849152\n",
            "Epoch: 12 \t Loss: 5.606265\n",
            "Epoch: 13 \t Loss: 5.370931\n",
            "Epoch: 14 \t Loss: 5.141693\n",
            "Epoch: 15 \t Loss: 4.919228\n",
            "Epoch: 16 \t Loss: 4.704614\n",
            "Epoch: 17 \t Loss: 4.500005\n",
            "Epoch: 18 \t Loss: 4.307152\n",
            "Epoch: 19 \t Loss: 4.128072\n",
            "Epoch: 20 \t Loss: 3.963415\n",
            "Epoch: 21 \t Loss: 3.813506\n",
            "Epoch: 22 \t Loss: 3.679062\n",
            "Epoch: 23 \t Loss: 3.558863\n",
            "Epoch: 24 \t Loss: 3.449848\n",
            "Epoch: 25 \t Loss: 3.351460\n",
            "Epoch: 26 \t Loss: 3.262501\n",
            "Epoch: 27 \t Loss: 3.181594\n",
            "Epoch: 28 \t Loss: 3.107619\n",
            "Epoch: 29 \t Loss: 3.040084\n",
            "Epoch: 30 \t Loss: 2.978679\n",
            "Epoch: 31 \t Loss: 2.921503\n",
            "Epoch: 32 \t Loss: 2.869578\n",
            "Epoch: 33 \t Loss: 2.822795\n",
            "Epoch: 34 \t Loss: 2.780065\n",
            "Epoch: 35 \t Loss: 2.740038\n",
            "Epoch: 36 \t Loss: 2.702867\n",
            "Epoch: 37 \t Loss: 2.669054\n",
            "Epoch: 38 \t Loss: 2.637111\n",
            "Epoch: 39 \t Loss: 2.607632\n",
            "Epoch: 40 \t Loss: 2.580403\n",
            "Epoch: 41 \t Loss: 2.554894\n",
            "Epoch: 42 \t Loss: 2.530943\n",
            "Epoch: 43 \t Loss: 2.507997\n",
            "Epoch: 44 \t Loss: 2.485652\n",
            "Epoch: 45 \t Loss: 2.463870\n",
            "Epoch: 46 \t Loss: 2.443125\n",
            "Epoch: 47 \t Loss: 2.423950\n",
            "Epoch: 48 \t Loss: 2.406611\n",
            "Epoch: 49 \t Loss: 2.390481\n",
            "Epoch: 50 \t Loss: 2.374328\n",
            "Epoch: 51 \t Loss: 2.358266\n",
            "Epoch: 52 \t Loss: 2.342295\n",
            "Epoch: 53 \t Loss: 2.326521\n",
            "Epoch: 54 \t Loss: 2.310704\n",
            "Epoch: 55 \t Loss: 2.294930\n",
            "Epoch: 56 \t Loss: 2.279199\n",
            "Epoch: 57 \t Loss: 2.263123\n",
            "Epoch: 58 \t Loss: 2.246723\n",
            "Epoch: 59 \t Loss: 2.230184\n",
            "Epoch: 60 \t Loss: 2.213317\n",
            "Epoch: 61 \t Loss: 2.196470\n",
            "Epoch: 62 \t Loss: 2.179327\n",
            "Epoch: 63 \t Loss: 2.162325\n",
            "Epoch: 64 \t Loss: 2.145489\n",
            "Epoch: 65 \t Loss: 2.128569\n",
            "Epoch: 66 \t Loss: 2.112039\n",
            "Epoch: 67 \t Loss: 2.095273\n",
            "Epoch: 68 \t Loss: 2.078812\n",
            "Epoch: 69 \t Loss: 2.062526\n",
            "Epoch: 70 \t Loss: 2.045709\n",
            "Epoch: 71 \t Loss: 2.028766\n",
            "Epoch: 72 \t Loss: 2.011612\n",
            "Epoch: 73 \t Loss: 1.994253\n",
            "Epoch: 74 \t Loss: 1.976726\n",
            "Epoch: 75 \t Loss: 1.959240\n",
            "Epoch: 76 \t Loss: 1.941714\n",
            "Epoch: 77 \t Loss: 1.923974\n",
            "Epoch: 78 \t Loss: 1.906102\n",
            "Epoch: 79 \t Loss: 1.888146\n",
            "Epoch: 80 \t Loss: 1.870228\n",
            "Epoch: 81 \t Loss: 1.852266\n",
            "Epoch: 82 \t Loss: 1.834319\n",
            "Epoch: 83 \t Loss: 1.816249\n",
            "Epoch: 84 \t Loss: 1.798193\n",
            "Epoch: 85 \t Loss: 1.780149\n",
            "Epoch: 86 \t Loss: 1.761970\n",
            "Epoch: 87 \t Loss: 1.743445\n",
            "Epoch: 88 \t Loss: 1.724585\n",
            "Epoch: 89 \t Loss: 1.705308\n",
            "Epoch: 90 \t Loss: 1.685809\n",
            "Epoch: 91 \t Loss: 1.666137\n",
            "Epoch: 92 \t Loss: 1.646445\n",
            "Epoch: 93 \t Loss: 1.626783\n",
            "Epoch: 94 \t Loss: 1.607144\n",
            "Epoch: 95 \t Loss: 1.587269\n",
            "Epoch: 96 \t Loss: 1.567131\n",
            "Epoch: 97 \t Loss: 1.546738\n",
            "Epoch: 98 \t Loss: 1.526213\n",
            "Epoch: 99 \t Loss: 1.505634\n",
            "Epoch: 0 \t Loss: 1.898409\n",
            "Epoch: 1 \t Loss: 1.808099\n",
            "Epoch: 2 \t Loss: 1.730977\n",
            "Epoch: 3 \t Loss: 1.671104\n",
            "Epoch: 4 \t Loss: 1.647504\n",
            "Epoch: 5 \t Loss: 1.631716\n",
            "Epoch: 6 \t Loss: 1.576424\n",
            "Epoch: 7 \t Loss: 1.515309\n",
            "Epoch: 8 \t Loss: 1.463106\n",
            "Epoch: 9 \t Loss: 1.415303\n",
            "Epoch: 10 \t Loss: 1.369052\n",
            "Epoch: 11 \t Loss: 1.324251\n",
            "Epoch: 12 \t Loss: 1.280792\n",
            "Epoch: 13 \t Loss: 1.238254\n",
            "Epoch: 14 \t Loss: 1.196412\n",
            "Epoch: 15 \t Loss: 1.154914\n",
            "Epoch: 16 \t Loss: 1.113588\n",
            "Epoch: 17 \t Loss: 1.071728\n",
            "Epoch: 18 \t Loss: 1.029625\n",
            "Epoch: 19 \t Loss: 0.988344\n",
            "Epoch: 20 \t Loss: 0.949064\n",
            "Epoch: 21 \t Loss: 0.911967\n",
            "Epoch: 22 \t Loss: 0.876159\n",
            "Epoch: 23 \t Loss: 0.840951\n",
            "Epoch: 24 \t Loss: 0.806057\n",
            "Epoch: 25 \t Loss: 0.771548\n",
            "Epoch: 26 \t Loss: 0.737506\n",
            "Epoch: 27 \t Loss: 0.704027\n",
            "Epoch: 28 \t Loss: 0.671261\n",
            "Epoch: 29 \t Loss: 0.639435\n",
            "Epoch: 30 \t Loss: 0.608706\n",
            "Epoch: 31 \t Loss: 0.579254\n",
            "Epoch: 32 \t Loss: 0.551044\n",
            "Epoch: 33 \t Loss: 0.523956\n",
            "Epoch: 34 \t Loss: 0.498267\n",
            "Epoch: 35 \t Loss: 0.473873\n",
            "Epoch: 36 \t Loss: 0.450938\n",
            "Epoch: 37 \t Loss: 0.429434\n",
            "Epoch: 38 \t Loss: 0.409228\n",
            "Epoch: 39 \t Loss: 0.390283\n",
            "Epoch: 40 \t Loss: 0.372523\n",
            "Epoch: 41 \t Loss: 0.355995\n",
            "Epoch: 42 \t Loss: 0.340649\n",
            "Epoch: 43 \t Loss: 0.326439\n",
            "Epoch: 44 \t Loss: 0.313260\n",
            "Epoch: 45 \t Loss: 0.300977\n",
            "Epoch: 46 \t Loss: 0.289493\n",
            "Epoch: 47 \t Loss: 0.278804\n",
            "Epoch: 48 \t Loss: 0.268838\n",
            "Epoch: 49 \t Loss: 0.259576\n",
            "Epoch: 50 \t Loss: 0.250918\n",
            "Epoch: 51 \t Loss: 0.242802\n",
            "Epoch: 52 \t Loss: 0.235168\n",
            "Epoch: 53 \t Loss: 0.227925\n",
            "Epoch: 54 \t Loss: 0.221078\n",
            "Epoch: 55 \t Loss: 0.214561\n",
            "Epoch: 56 \t Loss: 0.208325\n",
            "Epoch: 57 \t Loss: 0.202331\n",
            "Epoch: 58 \t Loss: 0.196550\n",
            "Epoch: 59 \t Loss: 0.190969\n",
            "Epoch: 60 \t Loss: 0.185570\n",
            "Epoch: 61 \t Loss: 0.180365\n",
            "Epoch: 62 \t Loss: 0.175346\n",
            "Epoch: 63 \t Loss: 0.170526\n",
            "Epoch: 64 \t Loss: 0.165900\n",
            "Epoch: 65 \t Loss: 0.161471\n",
            "Epoch: 66 \t Loss: 0.157197\n",
            "Epoch: 67 \t Loss: 0.153049\n",
            "Epoch: 68 \t Loss: 0.149006\n",
            "Epoch: 69 \t Loss: 0.145062\n",
            "Epoch: 70 \t Loss: 0.141215\n",
            "Epoch: 71 \t Loss: 0.137491\n",
            "Epoch: 72 \t Loss: 0.133900\n",
            "Epoch: 73 \t Loss: 0.130442\n",
            "Epoch: 74 \t Loss: 0.127106\n",
            "Epoch: 75 \t Loss: 0.123879\n",
            "Epoch: 76 \t Loss: 0.120755\n",
            "Epoch: 77 \t Loss: 0.117736\n",
            "Epoch: 78 \t Loss: 0.114807\n",
            "Epoch: 79 \t Loss: 0.111981\n",
            "Epoch: 80 \t Loss: 0.109255\n",
            "Epoch: 81 \t Loss: 0.106618\n",
            "Epoch: 82 \t Loss: 0.104075\n",
            "Epoch: 83 \t Loss: 0.101607\n",
            "Epoch: 84 \t Loss: 0.099226\n",
            "Epoch: 85 \t Loss: 0.096932\n",
            "Epoch: 86 \t Loss: 0.094720\n",
            "Epoch: 87 \t Loss: 0.092586\n",
            "Epoch: 88 \t Loss: 0.090525\n",
            "Epoch: 89 \t Loss: 0.088538\n",
            "Epoch: 90 \t Loss: 0.086616\n",
            "Epoch: 91 \t Loss: 0.084762\n",
            "Epoch: 92 \t Loss: 0.082968\n",
            "Epoch: 93 \t Loss: 0.081224\n",
            "Epoch: 94 \t Loss: 0.079537\n",
            "Epoch: 95 \t Loss: 0.077905\n",
            "Epoch: 96 \t Loss: 0.076318\n",
            "Epoch: 97 \t Loss: 0.074784\n",
            "Epoch: 98 \t Loss: 0.073295\n",
            "Epoch: 99 \t Loss: 0.071855\n",
            "Epoch: 0 \t Loss: 2.751321\n",
            "Epoch: 1 \t Loss: 2.676838\n",
            "Epoch: 2 \t Loss: 2.572587\n",
            "Epoch: 3 \t Loss: 2.447866\n",
            "Epoch: 4 \t Loss: 2.303061\n",
            "Epoch: 5 \t Loss: 2.171682\n",
            "Epoch: 6 \t Loss: 2.062961\n",
            "Epoch: 7 \t Loss: 1.977401\n",
            "Epoch: 8 \t Loss: 1.909211\n",
            "Epoch: 9 \t Loss: 1.847422\n",
            "Epoch: 10 \t Loss: 1.787501\n",
            "Epoch: 11 \t Loss: 1.726176\n",
            "Epoch: 12 \t Loss: 1.659500\n",
            "Epoch: 13 \t Loss: 1.584889\n",
            "Epoch: 14 \t Loss: 1.505488\n",
            "Epoch: 15 \t Loss: 1.426703\n",
            "Epoch: 16 \t Loss: 1.352109\n",
            "Epoch: 17 \t Loss: 1.280984\n",
            "Epoch: 18 \t Loss: 1.209116\n",
            "Epoch: 19 \t Loss: 1.135735\n",
            "Epoch: 20 \t Loss: 1.064322\n",
            "Epoch: 21 \t Loss: 0.997501\n",
            "Epoch: 22 \t Loss: 0.935967\n",
            "Epoch: 23 \t Loss: 0.878601\n",
            "Epoch: 24 \t Loss: 0.824095\n",
            "Epoch: 25 \t Loss: 0.772199\n",
            "Epoch: 26 \t Loss: 0.723697\n",
            "Epoch: 27 \t Loss: 0.679326\n",
            "Epoch: 28 \t Loss: 0.639202\n",
            "Epoch: 29 \t Loss: 0.603056\n",
            "Epoch: 30 \t Loss: 0.570347\n",
            "Epoch: 31 \t Loss: 0.540647\n",
            "Epoch: 32 \t Loss: 0.513699\n",
            "Epoch: 33 \t Loss: 0.489306\n",
            "Epoch: 34 \t Loss: 0.467436\n",
            "Epoch: 35 \t Loss: 0.448118\n",
            "Epoch: 36 \t Loss: 0.431096\n",
            "Epoch: 37 \t Loss: 0.415675\n",
            "Epoch: 38 \t Loss: 0.401479\n",
            "Epoch: 39 \t Loss: 0.388140\n",
            "Epoch: 40 \t Loss: 0.375467\n",
            "Epoch: 41 \t Loss: 0.363425\n",
            "Epoch: 42 \t Loss: 0.352062\n",
            "Epoch: 43 \t Loss: 0.341359\n",
            "Epoch: 44 \t Loss: 0.331337\n",
            "Epoch: 45 \t Loss: 0.321813\n",
            "Epoch: 46 \t Loss: 0.312599\n",
            "Epoch: 47 \t Loss: 0.303658\n",
            "Epoch: 48 \t Loss: 0.294933\n",
            "Epoch: 49 \t Loss: 0.286404\n",
            "Epoch: 50 \t Loss: 0.278037\n",
            "Epoch: 51 \t Loss: 0.269869\n",
            "Epoch: 52 \t Loss: 0.261915\n",
            "Epoch: 53 \t Loss: 0.254199\n",
            "Epoch: 54 \t Loss: 0.246731\n",
            "Epoch: 55 \t Loss: 0.239518\n",
            "Epoch: 56 \t Loss: 0.232515\n",
            "Epoch: 57 \t Loss: 0.225711\n",
            "Epoch: 58 \t Loss: 0.219079\n",
            "Epoch: 59 \t Loss: 0.212641\n",
            "Epoch: 60 \t Loss: 0.206408\n",
            "Epoch: 61 \t Loss: 0.200402\n",
            "Epoch: 62 \t Loss: 0.194589\n",
            "Epoch: 63 \t Loss: 0.188993\n",
            "Epoch: 64 \t Loss: 0.183545\n",
            "Epoch: 65 \t Loss: 0.178289\n",
            "Epoch: 66 \t Loss: 0.173204\n",
            "Epoch: 67 \t Loss: 0.168295\n",
            "Epoch: 68 \t Loss: 0.163584\n",
            "Epoch: 69 \t Loss: 0.159054\n",
            "Epoch: 70 \t Loss: 0.154720\n",
            "Epoch: 71 \t Loss: 0.150578\n",
            "Epoch: 72 \t Loss: 0.146608\n",
            "Epoch: 73 \t Loss: 0.142796\n",
            "Epoch: 74 \t Loss: 0.139090\n",
            "Epoch: 75 \t Loss: 0.135501\n",
            "Epoch: 76 \t Loss: 0.132024\n",
            "Epoch: 77 \t Loss: 0.128664\n",
            "Epoch: 78 \t Loss: 0.125419\n",
            "Epoch: 79 \t Loss: 0.122292\n",
            "Epoch: 80 \t Loss: 0.119270\n",
            "Epoch: 81 \t Loss: 0.116356\n",
            "Epoch: 82 \t Loss: 0.113532\n",
            "Epoch: 83 \t Loss: 0.110810\n",
            "Epoch: 84 \t Loss: 0.108180\n",
            "Epoch: 85 \t Loss: 0.105618\n",
            "Epoch: 86 \t Loss: 0.103149\n",
            "Epoch: 87 \t Loss: 0.100759\n",
            "Epoch: 88 \t Loss: 0.098448\n",
            "Epoch: 89 \t Loss: 0.096218\n",
            "Epoch: 90 \t Loss: 0.094068\n",
            "Epoch: 91 \t Loss: 0.091999\n",
            "Epoch: 92 \t Loss: 0.090002\n",
            "Epoch: 93 \t Loss: 0.088077\n",
            "Epoch: 94 \t Loss: 0.086207\n",
            "Epoch: 95 \t Loss: 0.084407\n",
            "Epoch: 96 \t Loss: 0.082662\n",
            "Epoch: 97 \t Loss: 0.080969\n",
            "Epoch: 98 \t Loss: 0.079342\n",
            "Epoch: 99 \t Loss: 0.077768\n",
            "Epoch: 0 \t Loss: 2.043926\n",
            "Epoch: 1 \t Loss: 1.976363\n",
            "Epoch: 2 \t Loss: 1.875231\n",
            "Epoch: 3 \t Loss: 1.762272\n",
            "Epoch: 4 \t Loss: 1.652911\n",
            "Epoch: 5 \t Loss: 1.558169\n",
            "Epoch: 6 \t Loss: 1.472084\n",
            "Epoch: 7 \t Loss: 1.399839\n",
            "Epoch: 8 \t Loss: 1.336572\n",
            "Epoch: 9 \t Loss: 1.272058\n",
            "Epoch: 10 \t Loss: 1.208133\n",
            "Epoch: 11 \t Loss: 1.147069\n",
            "Epoch: 12 \t Loss: 1.088858\n",
            "Epoch: 13 \t Loss: 1.031915\n",
            "Epoch: 14 \t Loss: 0.974792\n",
            "Epoch: 15 \t Loss: 0.917652\n",
            "Epoch: 16 \t Loss: 0.861215\n",
            "Epoch: 17 \t Loss: 0.805878\n",
            "Epoch: 18 \t Loss: 0.752166\n",
            "Epoch: 19 \t Loss: 0.701028\n",
            "Epoch: 20 \t Loss: 0.652312\n",
            "Epoch: 21 \t Loss: 0.605324\n",
            "Epoch: 22 \t Loss: 0.560139\n",
            "Epoch: 23 \t Loss: 0.517513\n",
            "Epoch: 24 \t Loss: 0.477407\n",
            "Epoch: 25 \t Loss: 0.439947\n",
            "Epoch: 26 \t Loss: 0.404658\n",
            "Epoch: 27 \t Loss: 0.371447\n",
            "Epoch: 28 \t Loss: 0.340748\n",
            "Epoch: 29 \t Loss: 0.312668\n",
            "Epoch: 30 \t Loss: 0.287475\n",
            "Epoch: 31 \t Loss: 0.265190\n",
            "Epoch: 32 \t Loss: 0.245650\n",
            "Epoch: 33 \t Loss: 0.228532\n",
            "Epoch: 34 \t Loss: 0.213362\n",
            "Epoch: 35 \t Loss: 0.199975\n",
            "Epoch: 36 \t Loss: 0.188171\n",
            "Epoch: 37 \t Loss: 0.177608\n",
            "Epoch: 38 \t Loss: 0.167927\n",
            "Epoch: 39 \t Loss: 0.159042\n",
            "Epoch: 40 \t Loss: 0.150846\n",
            "Epoch: 41 \t Loss: 0.143319\n",
            "Epoch: 42 \t Loss: 0.136333\n",
            "Epoch: 43 \t Loss: 0.129871\n",
            "Epoch: 44 \t Loss: 0.123878\n",
            "Epoch: 45 \t Loss: 0.118278\n",
            "Epoch: 46 \t Loss: 0.113097\n",
            "Epoch: 47 \t Loss: 0.108311\n",
            "Epoch: 48 \t Loss: 0.103903\n",
            "Epoch: 49 \t Loss: 0.099800\n",
            "Epoch: 50 \t Loss: 0.095926\n",
            "Epoch: 51 \t Loss: 0.092272\n",
            "Epoch: 52 \t Loss: 0.088819\n",
            "Epoch: 53 \t Loss: 0.085517\n",
            "Epoch: 54 \t Loss: 0.082452\n",
            "Epoch: 55 \t Loss: 0.079588\n",
            "Epoch: 56 \t Loss: 0.076908\n",
            "Epoch: 57 \t Loss: 0.074399\n",
            "Epoch: 58 \t Loss: 0.072040\n",
            "Epoch: 59 \t Loss: 0.069805\n",
            "Epoch: 60 \t Loss: 0.067721\n",
            "Epoch: 61 \t Loss: 0.065758\n",
            "Epoch: 62 \t Loss: 0.063916\n",
            "Epoch: 63 \t Loss: 0.062151\n",
            "Epoch: 64 \t Loss: 0.060471\n",
            "Epoch: 65 \t Loss: 0.058866\n",
            "Epoch: 66 \t Loss: 0.057336\n",
            "Epoch: 67 \t Loss: 0.055892\n",
            "Epoch: 68 \t Loss: 0.054515\n",
            "Epoch: 69 \t Loss: 0.053199\n",
            "Epoch: 70 \t Loss: 0.051948\n",
            "Epoch: 71 \t Loss: 0.050734\n",
            "Epoch: 72 \t Loss: 0.049587\n",
            "Epoch: 73 \t Loss: 0.048490\n",
            "Epoch: 74 \t Loss: 0.047436\n",
            "Epoch: 75 \t Loss: 0.046425\n",
            "Epoch: 76 \t Loss: 0.045450\n",
            "Epoch: 77 \t Loss: 0.044505\n",
            "Epoch: 78 \t Loss: 0.043597\n",
            "Epoch: 79 \t Loss: 0.042717\n",
            "Epoch: 80 \t Loss: 0.041869\n",
            "Epoch: 81 \t Loss: 0.041053\n",
            "Epoch: 82 \t Loss: 0.040259\n",
            "Epoch: 83 \t Loss: 0.039492\n",
            "Epoch: 84 \t Loss: 0.038761\n",
            "Epoch: 85 \t Loss: 0.038057\n",
            "Epoch: 86 \t Loss: 0.037379\n",
            "Epoch: 87 \t Loss: 0.036734\n",
            "Epoch: 88 \t Loss: 0.036107\n",
            "Epoch: 89 \t Loss: 0.035493\n",
            "Epoch: 90 \t Loss: 0.034906\n",
            "Epoch: 91 \t Loss: 0.034337\n",
            "Epoch: 92 \t Loss: 0.033777\n",
            "Epoch: 93 \t Loss: 0.033244\n",
            "Epoch: 94 \t Loss: 0.032726\n",
            "Epoch: 95 \t Loss: 0.032227\n",
            "Epoch: 96 \t Loss: 0.031740\n",
            "Epoch: 97 \t Loss: 0.031270\n",
            "Epoch: 98 \t Loss: 0.030807\n",
            "Epoch: 99 \t Loss: 0.030363\n",
            "Epoch: 0 \t Loss: 3.047960\n",
            "Epoch: 1 \t Loss: 2.943709\n",
            "Epoch: 2 \t Loss: 2.793415\n",
            "Epoch: 3 \t Loss: 2.628175\n",
            "Epoch: 4 \t Loss: 2.469096\n",
            "Epoch: 5 \t Loss: 2.334480\n",
            "Epoch: 6 \t Loss: 2.210762\n",
            "Epoch: 7 \t Loss: 2.068642\n",
            "Epoch: 8 \t Loss: 1.939150\n",
            "Epoch: 9 \t Loss: 1.840781\n",
            "Epoch: 10 \t Loss: 1.747931\n",
            "Epoch: 11 \t Loss: 1.652468\n",
            "Epoch: 12 \t Loss: 1.556684\n",
            "Epoch: 13 \t Loss: 1.462361\n",
            "Epoch: 14 \t Loss: 1.367159\n",
            "Epoch: 15 \t Loss: 1.271822\n",
            "Epoch: 16 \t Loss: 1.181005\n",
            "Epoch: 17 \t Loss: 1.096908\n",
            "Epoch: 18 \t Loss: 1.017670\n",
            "Epoch: 19 \t Loss: 0.940450\n",
            "Epoch: 20 \t Loss: 0.865117\n",
            "Epoch: 21 \t Loss: 0.792933\n",
            "Epoch: 22 \t Loss: 0.724732\n",
            "Epoch: 23 \t Loss: 0.661381\n",
            "Epoch: 24 \t Loss: 0.603536\n",
            "Epoch: 25 \t Loss: 0.550716\n",
            "Epoch: 26 \t Loss: 0.503281\n",
            "Epoch: 27 \t Loss: 0.462068\n",
            "Epoch: 28 \t Loss: 0.426311\n",
            "Epoch: 29 \t Loss: 0.395411\n",
            "Epoch: 30 \t Loss: 0.368610\n",
            "Epoch: 31 \t Loss: 0.345135\n",
            "Epoch: 32 \t Loss: 0.324352\n",
            "Epoch: 33 \t Loss: 0.305873\n",
            "Epoch: 34 \t Loss: 0.289496\n",
            "Epoch: 35 \t Loss: 0.275081\n",
            "Epoch: 36 \t Loss: 0.262232\n",
            "Epoch: 37 \t Loss: 0.250497\n",
            "Epoch: 38 \t Loss: 0.239751\n",
            "Epoch: 39 \t Loss: 0.229812\n",
            "Epoch: 40 \t Loss: 0.220277\n",
            "Epoch: 41 \t Loss: 0.210995\n",
            "Epoch: 42 \t Loss: 0.202030\n",
            "Epoch: 43 \t Loss: 0.193472\n",
            "Epoch: 44 \t Loss: 0.185349\n",
            "Epoch: 45 \t Loss: 0.177621\n",
            "Epoch: 46 \t Loss: 0.170291\n",
            "Epoch: 47 \t Loss: 0.163436\n",
            "Epoch: 48 \t Loss: 0.157124\n",
            "Epoch: 49 \t Loss: 0.151307\n",
            "Epoch: 50 \t Loss: 0.145811\n",
            "Epoch: 51 \t Loss: 0.140391\n",
            "Epoch: 52 \t Loss: 0.135038\n",
            "Epoch: 53 \t Loss: 0.129910\n",
            "Epoch: 54 \t Loss: 0.125117\n",
            "Epoch: 55 \t Loss: 0.120639\n",
            "Epoch: 56 \t Loss: 0.116560\n",
            "Epoch: 57 \t Loss: 0.112895\n",
            "Epoch: 58 \t Loss: 0.109511\n",
            "Epoch: 59 \t Loss: 0.106295\n",
            "Epoch: 60 \t Loss: 0.103178\n",
            "Epoch: 61 \t Loss: 0.100120\n",
            "Epoch: 62 \t Loss: 0.097100\n",
            "Epoch: 63 \t Loss: 0.094145\n",
            "Epoch: 64 \t Loss: 0.091356\n",
            "Epoch: 65 \t Loss: 0.088734\n",
            "Epoch: 66 \t Loss: 0.086267\n",
            "Epoch: 67 \t Loss: 0.083907\n",
            "Epoch: 68 \t Loss: 0.081642\n",
            "Epoch: 69 \t Loss: 0.079459\n",
            "Epoch: 70 \t Loss: 0.077361\n",
            "Epoch: 71 \t Loss: 0.075371\n",
            "Epoch: 72 \t Loss: 0.073484\n",
            "Epoch: 73 \t Loss: 0.071682\n",
            "Epoch: 74 \t Loss: 0.069959\n",
            "Epoch: 75 \t Loss: 0.068310\n",
            "Epoch: 76 \t Loss: 0.066736\n",
            "Epoch: 77 \t Loss: 0.065228\n",
            "Epoch: 78 \t Loss: 0.063786\n",
            "Epoch: 79 \t Loss: 0.062406\n",
            "Epoch: 80 \t Loss: 0.061083\n",
            "Epoch: 81 \t Loss: 0.059818\n",
            "Epoch: 82 \t Loss: 0.058616\n",
            "Epoch: 83 \t Loss: 0.057461\n",
            "Epoch: 84 \t Loss: 0.056356\n",
            "Epoch: 85 \t Loss: 0.055286\n",
            "Epoch: 86 \t Loss: 0.054257\n",
            "Epoch: 87 \t Loss: 0.053260\n",
            "Epoch: 88 \t Loss: 0.052298\n",
            "Epoch: 89 \t Loss: 0.051366\n",
            "Epoch: 90 \t Loss: 0.050472\n",
            "Epoch: 91 \t Loss: 0.049607\n",
            "Epoch: 92 \t Loss: 0.048767\n",
            "Epoch: 93 \t Loss: 0.047956\n",
            "Epoch: 94 \t Loss: 0.047168\n",
            "Epoch: 95 \t Loss: 0.046405\n",
            "Epoch: 96 \t Loss: 0.045665\n",
            "Epoch: 97 \t Loss: 0.044951\n",
            "Epoch: 98 \t Loss: 0.044253\n",
            "Epoch: 99 \t Loss: 0.043577\n"
          ]
        }
      ],
      "source": [
        "#training\n",
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "embedding_size = 128\n",
        "dec_units = 128\n",
        "encoder_hidden_size = 128\n",
        "vocab_size = 31510\n",
        "lr = 1e-3\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "data = data_list[0]\n",
        "sample = sample_comment[0]\n",
        "\n",
        "#every data corresponding to one model\n",
        "graph_encoder = GraphEncoder(data.x, vocab_size, embedding_size).to(device)\n",
        "GRU_decoder = GRUDecoder(vocab_size, embedding_size, dec_units, encoder_hidden_size).to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "encoder_optimizer = optim.Adam(graph_encoder.parameters(), lr=lr)\n",
        "decoder_optimizer = optim.Adam(GRU_decoder.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "for target in sample:\n",
        "    for epoch in range(epochs):\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        target = torch.tensor(target, dtype=torch.long).to(device).reshape(-1, 1)\n",
        "\n",
        "        loss = 0\n",
        "        #encoder\n",
        "        x_encode, weight = graph_encoder(data) # num_nodes * encoder_hidden_size\n",
        "\n",
        "        #decoder initial hidden state: headline vertex\n",
        "        dec_hidden = torch.mean(x_encode, 0).view(1, -1) # 1 * encoder_hidden_size\n",
        "        # dec_hidden = x_encode[-1] # 1 * encoder_hidden_size\n",
        "\n",
        "\n",
        "        #teacher forcing\n",
        "        for t in range(target.shape[0]-1):\n",
        "            dec_input = target[t] # scalar\n",
        "            predictions, dec_hidden = GRU_decoder(dec_input, dec_hidden, x_encode, weight)\n",
        "            loss += criterion(predictions, target[t+1])\n",
        "\n",
        "\n",
        "        \n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        print('Epoch: {0:} \\t Loss: {1:3f}'.format(epoch, loss/target.shape[0]))\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvMONNmX1ESR"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained(save_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Akyl912Nn4Vm",
        "outputId": "5636fc26-a12d-4209-c3a9-8267b7d06006"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ]
        }
      ],
      "source": [
        "x_encode, weight = graph_encoder(data, mask)\n",
        "dec_input = torch.tensor([101], device=device)\n",
        "dec_hidden = x_encode[-1]\n",
        "decode = []\n",
        "idx_list = []\n",
        "for _ in range(200):\n",
        "    predictions, dec_hidden = GRU_decoder(dec_input, dec_hidden, x_encode, weight)\n",
        "    idx = torch.argmax(predictions, 1)\n",
        "    idx_list.append(idx.data.cpu().numpy()[0])\n",
        "    dec_input = idx\n",
        "decode = tokenizer.decode(np.array(idx_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "d982nISooC7c"
      },
      "outputs": [],
      "source": [
        "x_encode, weight = graph_encoder(data, mask)\n",
        "dec_input = torch.tensor([101], device=device)\n",
        "dec_hidden = x_encode[-1]\n",
        "decode = []\n",
        "idx_list = []\n",
        "for _ in range(200):\n",
        "    predictions, dec_hidden = GRU_decoder(dec_input, dec_hidden, x_encode, weight)\n",
        "    a, idx = predictions.topk(2)\n",
        "    idx_list.append(idx.cpu().numpy()[0,1])\n",
        "    dec_input = idx[0, 1]\n",
        "decode = tokenizer.decode(np.array(idx_list))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for num in sample:\n",
        "    res = tokenizer.decode(num)\n",
        "    print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j6XLsKOxudP"
      },
      "source": [
        "# LSTM example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k23VjARD7GHM"
      },
      "outputs": [],
      "source": [
        "# A sample LSTM text generator\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self, text_df\n",
        "    ):\n",
        "        self.text_df = text_df\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.sequence_length = 4\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    # here I load all the words in all nodes for one graph, it should be fixed...\n",
        "    def load_words(self):\n",
        "        text_arr = np.array(self.text_df)\n",
        "        text = \"\"\n",
        "        for i in range(len(text_arr)):\n",
        "            text += text_arr[i][0] + \" \"\n",
        "        return text.split(' ')\n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# LSTM\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
        "        \n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(dataset, model):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=256\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        state_h, state_c = model.init_state(4)\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "\n",
        "def predict(dataset, model, text, next_words=100):\n",
        "    words = text.split(' ')\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "dataset = Dataset(df)\n",
        "model = Model(dataset)\n",
        "\n",
        "train(dataset, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLu5qU6_xyG-"
      },
      "source": [
        "# transformer encoder example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqkdnu3aHgoI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = transformer_encoder(src)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uE3IQXVujKZT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "XQh-352-Vy4w",
        "umBg3Tme10QC",
        "8j6XLsKOxudP",
        "QLu5qU6_xyG-"
      ],
      "name": "NLP_Project_GNN_comments_generation (2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04a1589a26cb4dbb9d36552bccfe4c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99c6a9ee1c2245dd885d7fbee44d5785",
              "IPY_MODEL_d2e301a298ca4e49ac3d5b73ae513d9f",
              "IPY_MODEL_cfd57b2075d2436dbe10d925f328cc89"
            ],
            "layout": "IPY_MODEL_8be1a314117b4580aba77e700501200f"
          }
        },
        "07e37d47ccd44d7b8309a51755037298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95560abaafe4151bd8949da721655e3",
            "placeholder": "​",
            "style": "IPY_MODEL_c4da20c2c6704c84845959bbd313deaf",
            "value": "Downloading: 100%"
          }
        },
        "11af1f31a11347da8f33e4a33efe197d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0cf05f4fa8d4d3a84b0ff761d72bbd2",
            "placeholder": "​",
            "style": "IPY_MODEL_c32b161aacbe4f4289648b7f72356107",
            "value": " 28.0/28.0 [00:00&lt;00:00, 625B/s]"
          }
        },
        "19eb1916d00a431dad9276d42f7488c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "462008e3083749389fc34efa0649cf83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510462e3f44f4c2984d272e1db94681e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51341fc3245945b7a50cd4b6a4dba09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfd9b6c71a7c44739428059442f4deb8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efbfb597d6b84c428514219bfb00ecfd",
            "value": 231508
          }
        },
        "521efa670ba74d4a80c9217b1acbf350": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0d2ac2361384ee1b6d544d1006ff767",
            "placeholder": "​",
            "style": "IPY_MODEL_5525448f676543ea9f87e21251b03a60",
            "value": " 226k/226k [00:00&lt;00:00, 4.17MB/s]"
          }
        },
        "5525448f676543ea9f87e21251b03a60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6378c0dd00cc467dbcb4cdaa60e490d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64201a5140aa4da8b3a670fbcd03c169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "729591fe8e074ff19b5d424dff3e175d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b250c03863564294b81d73b6e82f07a2",
              "IPY_MODEL_7d23ffff25d446619b04a2c141a4530d",
              "IPY_MODEL_11af1f31a11347da8f33e4a33efe197d"
            ],
            "layout": "IPY_MODEL_f07dfb3862a145baa46af06275f0d687"
          }
        },
        "7d23ffff25d446619b04a2c141a4530d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19eb1916d00a431dad9276d42f7488c9",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6378c0dd00cc467dbcb4cdaa60e490d6",
            "value": 28
          }
        },
        "7fbfbbd4f21f451ba1332b2a1c12c881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8be1a314117b4580aba77e700501200f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8db5a6700b534942ad6aa6bb179b4f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91ef0f2de27c4c6a8d620d943a85e379": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99c6a9ee1c2245dd885d7fbee44d5785": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462008e3083749389fc34efa0649cf83",
            "placeholder": "​",
            "style": "IPY_MODEL_efbfb924b5a640f08bd9e8b5b3e3d4f6",
            "value": "Downloading: 100%"
          }
        },
        "a0d2ac2361384ee1b6d544d1006ff767": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9954457edfa402592b7547dd1127ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0cf05f4fa8d4d3a84b0ff761d72bbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b250c03863564294b81d73b6e82f07a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc123d9650714a6e86be998d537ec47d",
            "placeholder": "​",
            "style": "IPY_MODEL_7fbfbbd4f21f451ba1332b2a1c12c881",
            "value": "Downloading: 100%"
          }
        },
        "b95560abaafe4151bd8949da721655e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc123d9650714a6e86be998d537ec47d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf6ce23fdd124f95a8ede96e95127447": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07e37d47ccd44d7b8309a51755037298",
              "IPY_MODEL_51341fc3245945b7a50cd4b6a4dba09a",
              "IPY_MODEL_521efa670ba74d4a80c9217b1acbf350"
            ],
            "layout": "IPY_MODEL_510462e3f44f4c2984d272e1db94681e"
          }
        },
        "c32b161aacbe4f4289648b7f72356107": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4da20c2c6704c84845959bbd313deaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfd57b2075d2436dbe10d925f328cc89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9954457edfa402592b7547dd1127ab0",
            "placeholder": "​",
            "style": "IPY_MODEL_8db5a6700b534942ad6aa6bb179b4f97",
            "value": " 570/570 [00:00&lt;00:00, 9.61kB/s]"
          }
        },
        "cfd9b6c71a7c44739428059442f4deb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2e301a298ca4e49ac3d5b73ae513d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91ef0f2de27c4c6a8d620d943a85e379",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64201a5140aa4da8b3a670fbcd03c169",
            "value": 570
          }
        },
        "efbfb597d6b84c428514219bfb00ecfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efbfb924b5a640f08bd9e8b5b3e3d4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f07dfb3862a145baa46af06275f0d687": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
