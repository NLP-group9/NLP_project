{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project_GNN_comments_generation (2).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0eGeCOK8EKfX",
        "8j6XLsKOxudP",
        "QLu5qU6_xyG-"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a74f74583f2b401588efda3afe136fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_43aa8112cfbd4a0eb63fb00d58a37681",
              "IPY_MODEL_5021b7fd4b4a411695c1eca906580e11"
            ],
            "layout": "IPY_MODEL_60d7a01baabd4930bad5c3649f445bc7"
          }
        },
        "43aa8112cfbd4a0eb63fb00d58a37681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d209dd9084b4bf6a528dbfe185d46ca",
            "placeholder": "​",
            "style": "IPY_MODEL_b1ac1e8688af43d4986d412275070581",
            "value": "39.682 MB of 39.682 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5021b7fd4b4a411695c1eca906580e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_494729b01bd442d2b517b77bf986023e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5dc3c320636b48bbb6dbfb184a6263ce",
            "value": 1
          }
        },
        "60d7a01baabd4930bad5c3649f445bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d209dd9084b4bf6a528dbfe185d46ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ac1e8688af43d4986d412275070581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "494729b01bd442d2b517b77bf986023e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dc3c320636b48bbb6dbfb184a6263ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load file"
      ],
      "metadata": {
        "id": "XQh-352-Vy4w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h4B7dYGPORcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059baeb4-db5a-4d53-a215-fc0d7594da95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "dir = '/content/gdrive/MyDrive/archive'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "article"
      ],
      "metadata": {
        "id": "NGYRTZhCrxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-articles-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df1 = pd.read_csv('/content/gdrive/MyDrive/archive/nyt-articles-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df1.dataframeName = 'nyt-articles-2020.csv'\n",
        "nRow, nCol = df1.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "metadata": {
        "id": "I1G8ci8frTne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62103faf-85a2-47d0-de61-342881f1a7e8"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 16787 rows and 11 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comment"
      ],
      "metadata": {
        "id": "4Ul50KM2rzeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-comments-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df2 = pd.read_csv( dir+'/nyt-comments-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df2.dataframeName = 'nyt-comments-2020.csv'\n",
        "nRow, nCol = df2.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')\n",
        "article = np.array(df1)\n",
        "comments = np.array(df2)"
      ],
      "metadata": {
        "id": "lARaxsdtrmiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b05ee84e-f55e-4f40-c7fd-62af0b11fa53"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4986461 rows and 23 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "r4sjXW5pyxFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Article cleaning \\\\\n",
        "列数从0开始 \\\\\n",
        "第1列 第2列不出现 politics \\\\\n",
        "第6列不出现 [] \\\\\n",
        "第7列筛选文章词数大于50 \\\\\n",
        "第9列筛选comments个数大于50 \\\\\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "akvF2EghyytA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#只保留sports和movies\n",
        "# df1_1 = df1.drop(df1[df1['section'] != 'Sports'].index)\n",
        "# df1_2 = df1.drop(df1[df1['section'] != 'Movies'].index)\n",
        "# cleaned_arti = pd.concat([df1_1, df1_2])\n",
        "cleaned_arti = df1\n",
        "#第六列不出现空\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['keywords'] == '[]'].index)\n",
        "#第七列筛选次数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['word_count'] < 50].index)\n",
        "#第九列comments个数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['n_comments'] < 50].index)\n",
        "#取出对应的article id\n",
        "#article只保留四列\n",
        "cleaned_arti = cleaned_arti[['headline','abstract','keywords', 'uniqueID']]"
      ],
      "metadata": {
        "id": "KY9i-F7t1F51"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_arti.dropna(axis=0,how='any')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sGb_wf15eK--",
        "outputId": "fa17b8f8-fa54-4d54-8282-8f854338a7ac"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                headline  \\\n",
              "0                            Protect Veterans From Fraud   \n",
              "1                                 ‘It’s Green and Slimy’   \n",
              "5      Pro-Iranian Protesters End Siege of U.S. Embas...   \n",
              "7      She Felt Fine, but Her M.R.I. Showed Several S...   \n",
              "10     Eat Better, Feel Better? Food Advice From the ...   \n",
              "...                                                  ...   \n",
              "16781  Here’s Why Distribution of the Vaccine Is Taki...   \n",
              "16782                What It Takes to Heal From Covid-19   \n",
              "16784  Their Finances Ravaged, Customers Fear Banks W...   \n",
              "16785      Should Wine Be Among Your Health Resolutions?   \n",
              "16786  Microsoft Says Russian Hackers Viewed Some of ...   \n",
              "\n",
              "                                                abstract  \\\n",
              "0      Congress could do much more to protect America...   \n",
              "1      Christina Iverson and Jeff Chen ring in the Ne...   \n",
              "5      Iran’s ability to deploy militias to attack th...   \n",
              "7      After the 67-year-old woman fell at the airpor...   \n",
              "10     Intermittent fasting, drinking less alcohol an...   \n",
              "...                                                  ...   \n",
              "16781  Health officials and hospitals are struggling ...   \n",
              "16782      Survivors can get better, but they need help.   \n",
              "16784  Banks have the power to decide whether to let ...   \n",
              "16785  The new category of ‘clean wines’ is an effort...   \n",
              "16786  The hackers gained more access than the compan...   \n",
              "\n",
              "                                                keywords  \\\n",
              "0      ['Veterans', 'For-Profit Schools', 'Financial ...   \n",
              "1                                  ['Crossword Puzzles']   \n",
              "5      ['Iraq', 'Iran', 'United States', 'Demonstrati...   \n",
              "7      ['Stroke', 'Brain', 'Heart', 'Medicine and Hea...   \n",
              "10           ['Weight', 'Fasting', 'Diet and Nutrition']   \n",
              "...                                                  ...   \n",
              "16781  ['Vaccination and Immunization', 'Coronavirus ...   \n",
              "16782  ['Chronic Condition (Health)', 'Coronavirus (2...   \n",
              "16784  ['Banking and Financial Institutions', 'Corona...   \n",
              "16785  ['Wines', 'Grapes', 'Diet and Nutrition', 'Dia...   \n",
              "16786  ['Microsoft Corp', 'US Federal Government Data...   \n",
              "\n",
              "                                                uniqueID  \n",
              "0      nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "1      nyt://article/9edddb54-0aa3-5835-a833-d311a76f...  \n",
              "5      nyt://article/ac742403-9ccd-522f-9a1e-a90feb6c...  \n",
              "7      nyt://article/dfd5bb59-f330-5c01-ae02-221e6f9c...  \n",
              "10     nyt://article/da74e3b3-f027-5b03-9052-0bc2e69a...  \n",
              "...                                                  ...  \n",
              "16781  nyt://article/5320a2e9-d739-542a-a397-443c4323...  \n",
              "16782  nyt://article/e8adbb75-a8b3-5a8c-886b-b9c1195f...  \n",
              "16784  nyt://article/c4b9edab-bdde-5d81-b496-06fedb52...  \n",
              "16785  nyt://article/efcaf652-ffad-5b4e-9f17-4fd9aff5...  \n",
              "16786  nyt://article/12048b2b-62e3-5bed-8c77-483a4299...  \n",
              "\n",
              "[9403 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cc5407e6-fd69-451a-a2ac-c9086f43f586\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>abstract</th>\n",
              "      <th>keywords</th>\n",
              "      <th>uniqueID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Protect Veterans From Fraud</td>\n",
              "      <td>Congress could do much more to protect America...</td>\n",
              "      <td>['Veterans', 'For-Profit Schools', 'Financial ...</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‘It’s Green and Slimy’</td>\n",
              "      <td>Christina Iverson and Jeff Chen ring in the Ne...</td>\n",
              "      <td>['Crossword Puzzles']</td>\n",
              "      <td>nyt://article/9edddb54-0aa3-5835-a833-d311a76f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pro-Iranian Protesters End Siege of U.S. Embas...</td>\n",
              "      <td>Iran’s ability to deploy militias to attack th...</td>\n",
              "      <td>['Iraq', 'Iran', 'United States', 'Demonstrati...</td>\n",
              "      <td>nyt://article/ac742403-9ccd-522f-9a1e-a90feb6c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>She Felt Fine, but Her M.R.I. Showed Several S...</td>\n",
              "      <td>After the 67-year-old woman fell at the airpor...</td>\n",
              "      <td>['Stroke', 'Brain', 'Heart', 'Medicine and Hea...</td>\n",
              "      <td>nyt://article/dfd5bb59-f330-5c01-ae02-221e6f9c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Eat Better, Feel Better? Food Advice From the ...</td>\n",
              "      <td>Intermittent fasting, drinking less alcohol an...</td>\n",
              "      <td>['Weight', 'Fasting', 'Diet and Nutrition']</td>\n",
              "      <td>nyt://article/da74e3b3-f027-5b03-9052-0bc2e69a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16781</th>\n",
              "      <td>Here’s Why Distribution of the Vaccine Is Taki...</td>\n",
              "      <td>Health officials and hospitals are struggling ...</td>\n",
              "      <td>['Vaccination and Immunization', 'Coronavirus ...</td>\n",
              "      <td>nyt://article/5320a2e9-d739-542a-a397-443c4323...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16782</th>\n",
              "      <td>What It Takes to Heal From Covid-19</td>\n",
              "      <td>Survivors can get better, but they need help.</td>\n",
              "      <td>['Chronic Condition (Health)', 'Coronavirus (2...</td>\n",
              "      <td>nyt://article/e8adbb75-a8b3-5a8c-886b-b9c1195f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16784</th>\n",
              "      <td>Their Finances Ravaged, Customers Fear Banks W...</td>\n",
              "      <td>Banks have the power to decide whether to let ...</td>\n",
              "      <td>['Banking and Financial Institutions', 'Corona...</td>\n",
              "      <td>nyt://article/c4b9edab-bdde-5d81-b496-06fedb52...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16785</th>\n",
              "      <td>Should Wine Be Among Your Health Resolutions?</td>\n",
              "      <td>The new category of ‘clean wines’ is an effort...</td>\n",
              "      <td>['Wines', 'Grapes', 'Diet and Nutrition', 'Dia...</td>\n",
              "      <td>nyt://article/efcaf652-ffad-5b4e-9f17-4fd9aff5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16786</th>\n",
              "      <td>Microsoft Says Russian Hackers Viewed Some of ...</td>\n",
              "      <td>The hackers gained more access than the compan...</td>\n",
              "      <td>['Microsoft Corp', 'US Federal Government Data...</td>\n",
              "      <td>nyt://article/12048b2b-62e3-5bed-8c77-483a4299...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9403 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc5407e6-fd69-451a-a2ac-c9086f43f586')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc5407e6-fd69-451a-a2ac-c9086f43f586 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc5407e6-fd69-451a-a2ac-c9086f43f586');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kw_set = np.array(cleaned_arti['keywords'])"
      ],
      "metadata": {
        "id": "ttCY1njXczIQ"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_idx = []\n",
        "for i, kw in enumerate(kw_set):\n",
        "    if str(kw)=='nan' or ',' not in kw or len(kw.split(',')) < 25:\n",
        "        pass\n",
        "    else:\n",
        "        keep_idx.append(i)"
      ],
      "metadata": {
        "id": "fXUUVAOgc1T-"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_arti = cleaned_arti.iloc[keep_idx, :]"
      ],
      "metadata": {
        "id": "GJ2Qby02dmmk"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_arti)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpDWr5a8iyzr",
        "outputId": "8c7f0f96-6130-4105-f602-28f2c95cf428"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments cleaning \\\\\n",
        "根据cleaned article筛选comments \\\\\n"
      ],
      "metadata": {
        "id": "lG4K6bjD0BE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uni_id = cleaned_arti['uniqueID'].to_numpy()\n",
        "cleaned_comm = df2[df2['articleID'].isin(uni_id)]\n",
        "cleaned_comm = cleaned_comm[['commentBody','articleID']]"
      ],
      "metadata": {
        "id": "CJfNgUgi65t3"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_len_list = []\n",
        "a = np.array(cleaned_comm['commentBody'])\n",
        "for comm in tqdm(a):\n",
        "    comment_len_list.append(len(comm.split(' ')))\n",
        "comment_len_list = np.array(comment_len_list)"
      ],
      "metadata": {
        "id": "0zRoMUuLJzpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f279f60-83a2-4437-d26e-28b4280150a7"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 59296/59296 [00:00<00:00, 250005.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.sort(comment_len_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "8AFRZcQHZtpG",
        "outputId": "cc09fe0c-855d-47dd-d320-1425e06ffa81"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd56cbb40d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 192
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(comment_len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c2AJnK1aCJA",
        "outputId": "a75af15f-ba19-4b10-faa5-72eac3df3857"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60.84363194819212"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node extraction"
      ],
      "metadata": {
        "id": "tjVo2aKAV5vx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reconstruct keywords"
      ],
      "metadata": {
        "id": "QPzAYx7UI3rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "\n",
        "# new version\n",
        "def extract_kw(cleaned_arti):\n",
        "    # stop words in English\n",
        "    stop = set(stopwords.words('english')) \n",
        "    #extract keywords from cleaned article\n",
        "    kw_set = np.array(cleaned_arti['keywords'])\n",
        "    \n",
        "    for i, kw in enumerate(kw_set):\n",
        "        if ',' not in kw:\n",
        "            print(len(kw))\n",
        "        kw = kw.split(',') if ',' in kw else kw\n",
        "        for j in range(len(kw)):\n",
        "            kw[j] = re.sub(u\"([^\\u0041-\\u005a\\u0061-\\u007a\\u0020])\", \"\", kw[j])\n",
        "            kw[j] = kw[j].strip()\n",
        "        kw = np.array([i for i in kw if i != \"\" and i not in stop])\n",
        "        kw_set[i] = np.unique(kw)\n",
        "    return kw_set\n"
      ],
      "metadata": {
        "id": "awoyXGsss6Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb96a092-f519-413f-8f97-99a4b9cf301c"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)"
      ],
      "metadata": {
        "id": "j4lgrRSagGis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c62916-448d-4cd7-fc0b-e6faa3eb4dbf"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kw = extract_kw(cleaned_arti)"
      ],
      "metadata": {
        "id": "TD-5-WXbHcku"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "\n",
        "def not_break(sen):\n",
        "    return (sen != '\\n' and sen != '\\u3000' and  sen != '' and not sen.isspace())\n",
        "def filter_data(ini_data):\n",
        "    new_data = list(filter(not_break, [data.strip() for data in ini_data]))\n",
        "    return new_data"
      ],
      "metadata": {
        "id": "8Qh1kaG0UaXS"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 略加修改\n",
        "import gc\n",
        "kw = extract_kw(cleaned_arti)\n",
        "for i in range(len(kw)):\n",
        "    kw[i] = kw[i].astype('<U5000')\n",
        "\n",
        "headline = np.array(cleaned_arti['headline'])\n",
        "def recon_kw(kw, headline, cleaned_arti, cleaned_comm):\n",
        "    data_list = []\n",
        "    sample_num = 10\n",
        "    sample_comment_set = []\n",
        "    sample_comment_set_atten_mask = []\n",
        "    edge_connection_box, edge_feat_box = [], []\n",
        "\n",
        "    #divider\n",
        "    english_punctuation = string.punctuation\n",
        "    eng_punc = '|'.join([c for c in english_punctuation])\n",
        "    eng_punc  = eng_punc[:-5] + eng_punc[-3:]\n",
        "\n",
        "    uni_id = np.array(cleaned_arti['uniqueID'])\n",
        "\n",
        "    #construct abstract set\n",
        "    abstract_set = np.array(cleaned_arti['abstract'])\n",
        "\n",
        "    #iterate through each article\n",
        "    for i, id in enumerate(tqdm(uni_id)):\n",
        "\n",
        "        #find corresponding comments set\n",
        "        idx = np.where(np.array(cleaned_comm['articleID']) == id)\n",
        "        comment_set = np.array(cleaned_comm['commentBody'])[idx]\n",
        "\n",
        "        #constract abstract in sentence for one id\n",
        "        abstract = abstract_set[i]\n",
        "        abstract_kw = filter_data(re.split(r''+(\"[\"+eng_punc+\"]\"), abstract))\n",
        "        abstract_kw = [abstract.strip('\\n') for abstract in abstract_kw]\n",
        "        \n",
        "        #iterate through each comment, construct comment set\n",
        "        comm_list = []\n",
        "        comm_kw = []\n",
        "        for comm in comment_set:\n",
        "            comm_k = re.sub(u\"([^\\u0061-\\u007a\\u0030-\\u0039\\u0020\\u0041-\\u005a])\", \"\", comm.strip('\\n'))\n",
        "            comm1 = comm_k.split(' ')\n",
        "            comm_list.extend(comm1)\n",
        "            comm_k = comm.strip('\\n')\n",
        "            comm_kw.append(comm_k)\n",
        "        \n",
        "        #construct dict\n",
        "        comm_dict = {}\n",
        "        for comm in comm_list:\n",
        "            if comm in comm_dict:\n",
        "                comm_dict[comm] += 1\n",
        "            else:\n",
        "                comm_dict[comm] = 1\n",
        "        \n",
        "        # take out the top10\n",
        "        top = 10\n",
        "        freq_threshold = 10\n",
        "        stop_words = 50\n",
        "\n",
        "        # rank comm_dict\n",
        "        comm_dict = np.array(sorted(comm_dict.items(), key=lambda item:item[1], reverse=True))[stop_words:]\n",
        "        comm_kw_list = np.array(comm_dict[:, 0])\n",
        "        freq_list = np.array(np.array(comm_dict[:, 1], dtype=np.int64))\n",
        "\n",
        "        # append keywords\n",
        "        #************************************************************************************\n",
        "        # delete stop words\n",
        "        idx = np.where(freq_list >= freq_threshold)[0]\n",
        "        kw[i] = np.concatenate((kw[i], comm_kw_list[idx])) if len(idx) <= top else np.concatenate((kw[i], comm_kw_list[:top]))\n",
        "        kw[i] = np.unique(kw[i])\n",
        "\n",
        "        # append headline at the end of each graph\n",
        "        headline[i] = headline[i].strip('\\n')\n",
        "        headline[i] =  np.delete(headline[i], np.where(headline[i] == ''))\n",
        "        kw[i] = np.concatenate((kw[i], headline[i]))\n",
        "\n",
        "\n",
        "        #add our keyword to tokenizer\n",
        "        for word in kw[i]:\n",
        "            tokenizer.add_tokens([word])\n",
        "\n",
        "        #resize BERTmodel\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "        # copy kw, without the first empty node\n",
        "        kw_copy = kw[i].copy()\n",
        "\n",
        "\n",
        "        #sample several comments as target\n",
        "        random_idx = np.arange(len(comm_kw))\n",
        "        np.random.shuffle(random_idx)\n",
        "        sample_idx = random_idx[:sample_num]\n",
        "        sample_max_length = 50\n",
        "        sample_comment = np.zeros((sample_num, sample_max_length))\n",
        "        sample_comment_mask = np.zeros((sample_num, sample_max_length))\n",
        "        for idx in range(len(sample_idx)):\n",
        "            selected_comm = comm_kw[idx]\n",
        "            sample_encoding = tokenizer.encode_plus(selected_comm, padding='max_length',add_special_tokens=True, max_length=sample_max_length, truncation=True, return_attention_mask=True)\n",
        "            sample_comment[idx] = sample_encoding['input_ids']\n",
        "            sample_comment_mask[idx] = sample_encoding['attention_mask']\n",
        "            del comm_kw[idx]\n",
        "            gc.collect()\n",
        "        sample_comment_set.append(sample_comment)\n",
        "        sample_comment_set_atten_mask.append(sample_comment_mask)\n",
        "\n",
        "        # add comment and abstract to node\n",
        "        comm_kw.extend(abstract_kw)\n",
        "        docs = comm_kw\n",
        "\n",
        "        counter = np.zeros(len(docs))\n",
        "        counter_edge = np.zeros((len(kw_copy[:-1]), len(docs)))\n",
        "        \n",
        "        # add corresponding sentences to keywords\n",
        "        #************************************************************************************\n",
        "        for j, single_kw in enumerate(kw_copy[:-1]):\n",
        "            # convert to word\n",
        "            single_kw_set = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", single_kw.strip('\\n').lower()).split(' ')\n",
        "            for k, doc in enumerate(docs):  \n",
        "                doc_copy = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", doc.strip('\\n').lower())\n",
        "                exist = 0\n",
        "                for s_kw in single_kw_set:\n",
        "                    if s_kw in doc_copy.split(' ') and exist == 0:\n",
        "                        exist = 1\n",
        "                        kw[i][j] += ' '\n",
        "                        kw[i][j] = np.char.add(kw[i][j], doc)\n",
        "                        counter[k] += 1\n",
        "                        counter_edge[j, k] += 1\n",
        "                    else:\n",
        "                        pass\n",
        "        #************************************************************************************\n",
        "\n",
        "\n",
        "\n",
        "        # construct empty node \n",
        "        empty_node = np.array([''], dtype='<U10000')\n",
        "        kw[i] = np.concatenate((empty_node, kw[i]))\n",
        "        \n",
        "        # add doc to empty node\n",
        "        if len(np.where(counter == 0)[0]) != 0:\n",
        "            empty_doc = np.array(docs)[np.where(counter == 0)[0]]\n",
        "            kw[i][0] = np.char.add(kw[i][0], ' '.join(empty_doc))\n",
        "\n",
        "        #encode and generate graph.x data file\n",
        "        path = '/content/gdrive/MyDrive/graph/graph_{0:}'.format(i)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        # for ith, row in enumerate(kw[i]):\n",
        "        #     input = tokenizer.encode_plus(row, padding='max_length',add_special_tokens=True, max_length=200, truncation=True, return_attention_mask=True, return_tensors = \"pt\").to(device)\n",
        "        #     torch.save(model(**input)[0][0][1], path + \"/node{0:}.pt\".format(ith))\n",
        "\n",
        "        for ith, row in enumerate(kw[i]):\n",
        "            input = tokenizer.encode_plus(row, add_special_tokens=True, max_length=512, return_attention_mask=True, truncation=True, return_tensors = \"pt\").to(device)\n",
        "            with torch.no_grad():\n",
        "                output = model(**input)[0][0][1]\n",
        "                output = output.cpu()\n",
        "            torch.save(output, path + \"/node{0:}.pt\".format(ith))\n",
        "            \n",
        "\n",
        "        # calculate edge\n",
        "        store_edge = []\n",
        "        value_edge = []\n",
        "\n",
        "        for j in range(len(counter_edge)-1):\n",
        "            interaction = np.sum(counter_edge[j] * counter_edge[j+1:], axis=1)\n",
        "            if len(np.where(interaction != 0)[0]) != 0:\n",
        "                if len(value_edge) != 0:\n",
        "                    value_edge.append(np.hstack((value_edge[-1], interaction[np.nonzero(interaction)])))\n",
        "                else:\n",
        "                    value_edge.append(interaction[np.nonzero(interaction)])\n",
        "                \n",
        "                edge = np.vstack((np.array([j for _ in range(len(np.where(interaction != 0)[0]))]), np.where(interaction != 0)[0]+j+1))\n",
        "                \n",
        "                if len(store_edge) != 0:\n",
        "                    store_edge.append(np.hstack((store_edge[-1], edge))) \n",
        "                else:\n",
        "                    store_edge.append(edge)\n",
        "\n",
        "        # edge connection\n",
        "        if len(store_edge) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            edge_for_id = store_edge[-1]\n",
        "        \n",
        "            # copy edge connection\n",
        "            edge_for_id2 = np.zeros_like(edge_for_id)\n",
        "            edge_for_id2[0], edge_for_id2[1] = edge_for_id[1], edge_for_id[0]\n",
        "            edge_connection_box.append(np.hstack((edge_for_id, edge_for_id2)))\n",
        "\n",
        "            # edge feature\n",
        "            edge_feat_for_id = value_edge[-1]\n",
        "\n",
        "            # copy edge feature\n",
        "            edge_feat_box.append(np.hstack((edge_feat_for_id, edge_feat_for_id)))\n",
        "        \n",
        "    return sample_comment_set, sample_comment_set_atten_mask, edge_connection_box, edge_feat_box\n"
      ],
      "metadata": {
        "id": "XichWjhuszfJ"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_comment_set, sample_comment_set_atten_mask, edge_connection, edge_feat = recon_kw(kw, np.array(cleaned_arti['headline']), cleaned_arti, cleaned_comm)"
      ],
      "metadata": {
        "id": "6umU6S33tbN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3300749-3fe0-4ba1-8ac6-980565ba2b9a"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [09:52<00:00,  5.59s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the other edge related data file \n",
        "import os\n",
        "\n",
        "path = '/content/gdrive/MyDrive/edge_connection'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/edge_feat'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/sample_comment'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/sample_comment_set_atten_mask'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "\n",
        "for i in range(len(uni_id)):\n",
        "    np.save('/content/gdrive/MyDrive/edge_connection/egde_connection{0:}.npy'.format(i), edge_connection[i])\n",
        "    np.save('/content/gdrive/MyDrive/edge_feat/edge_feat{0:}.npy'.format(i), edge_feat[i])\n",
        "    np.save('/content/gdrive/MyDrive/sample_comment/sample_comment{0:}.npy'.format(i), sample_comment_set[i])\n",
        "    np.save('/content/gdrive/MyDrive/sample_comment_set_atten_mask/sample_comment_set_atten_mask{0:}.npy'.format(i), sample_comment_set_atten_mask[i])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A-XvhsWrtSDB"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory_tokenizer = '/content/gdrive/MyDrive/tokenizer'\n",
        "tokenizer.save_pretrained(save_directory_tokenizer)\n",
        "\n",
        "save_directory_BERT = '/content/gdrive/MyDrive/BERT'\n",
        "model.save_pretrained(save_directory_BERT)\n",
        "\n",
        "save_directory_BERT_weight = '/content/gdrive/MyDrive/BERT_weight'\n",
        "torch.save(model.embeddings.word_embeddings.weight.detach().cpu(), save_directory_BERT_weight+'.pt')"
      ],
      "metadata": {
        "id": "JxVBV_uQ9kTg"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph construction"
      ],
      "metadata": {
        "id": "tkuo2EXMyd9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export CPATH=/usr/local/cuda/include:$CPATH\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "save_directory_tokenizer='/content/gdrive/MyDrive/tokenizer'\n",
        "tokenizer = BertTokenizer.from_pretrained(save_directory_tokenizer)\n",
        "\n",
        "save_directory_BERT = '/content/gdrive/MyDrive/BERT'\n",
        "model = BertModel.from_pretrained(save_directory_BERT).to(device)\n",
        "\n",
        "save_directory_BERT_weight = '/content/gdrive/MyDrive/BERT_weight.pt'\n",
        "model_weight = torch.load(save_directory_BERT_weight)"
      ],
      "metadata": {
        "id": "TjbdRFmHDp7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "from torch_geometric.data import Dataset, download_url\n",
        "\n",
        "\n",
        "class MyOwnDataset(Dataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n",
        "        super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['/graph']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        path_graph = '/content/gdrive/MyDrive/graph'\n",
        "        num_file = len(os.listdir(path_graph))\n",
        "        return ['data_' + str(i) for i in range(num_file)]\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        path_graph = '/content/gdrive/MyDrive/graph'\n",
        "        path_connect = '/content/gdrive/MyDrive/edge_connection'\n",
        "        path_feat = '/content/gdrive/MyDrive/edge_feat'\n",
        "        num_file = len(os.listdir(path_graph))\n",
        "\n",
        "        idx=0\n",
        "        for i in tqdm(range(num_file)):\n",
        "            path_graphi = path_graph+'/graph_'+str(i)\n",
        "            path_connecti = path_connect+'/egde_connection'+str(i)+'.npy'\n",
        "            path_feati = path_feat+'/edge_feat'+str(i)+'.npy'\n",
        "            num_node = len(os.listdir(path_graphi))\n",
        "            \n",
        "            #load\n",
        "            x = torch.zeros(num_node, 768)\n",
        "            for j in range(num_node):\n",
        "                x[j] = torch.load(path_graphi+'/node{0:}.pt'.format(j))\n",
        "            \n",
        "            edge_index = torch.tensor(np.load(path_connecti), dtype=torch.long)\n",
        "            edge_attr = torch.tensor(np.load(path_feati))\n",
        "\n",
        "            data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
        "            torch.save(data, osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "            idx += 1\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.processed_file_names)\n",
        "\n",
        "    def get(self, idx):\n",
        "        data = torch.load(osp.join(self.processed_dir, f'data_{idx}.pt'))\n",
        "        return data"
      ],
      "metadata": {
        "id": "MNlVxliwekt4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_y(sample_comment, sample_comment_atten_mask):\n",
        "    #generate y data file \n",
        "    sample_comment = np.array(sample_comment)\n",
        "    sample_comment_atten_mask = np.array(sample_comment_atten_mask)\n",
        "    num_label_set = sample_comment.shape[1]\n",
        "    for i in tqdm(range(num_label_set)):\n",
        "        label_set = sample_comment[:, i, :]\n",
        "        label_set_atten_mask = sample_comment_atten_mask[:, i, :]\n",
        "        num_label = label_set.shape[0]\n",
        "        \n",
        "        #vector y path\n",
        "        path = '/content/gdrive/MyDrive/label_set{0:}'.format(i)\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        #scalar y path\n",
        "        path_scalar = '/content/gdrive/MyDrive/scalar_label_set{0:}'.format(i)\n",
        "        if not os.path.exists(path_scalar):\n",
        "            os.makedirs(path_scalar)\n",
        "\n",
        "        for j in range(num_label):\n",
        "            label_tensor = torch.tensor(label_set[j], dtype=torch.long).view(1,-1).to(device)\n",
        "            label_mask_tensor = torch.tensor(label_set_atten_mask[j], dtype=torch.long).view(1,-1).to(device)\n",
        "            with torch.no_grad():\n",
        "                label_tensor_vector = model(label_tensor, label_mask_tensor)[0][0]\n",
        "                label_tensor_vector = label_tensor_vector.cpu()\n",
        "            label_tensor = label_tensor.cpu()\n",
        "            torch.save(label_tensor_vector, path + \"/label{0:}.pt\".format(j))\n",
        "            torch.save(label_tensor, path_scalar+\"/label{0:}.pt\".format(j))\n"
      ],
      "metadata": {
        "id": "BdqjMFzxeb6X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, num_set):\n",
        "        super(YDataset, self).__init__()\n",
        "        self.path = path \n",
        "        self.num_set = num_set\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.path + str(self.num_set) + '/label' + str(index) + '.pt'\n",
        "        data = torch.load(path).cpu()\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.path+str(self.num_set)))"
      ],
      "metadata": {
        "id": "VnubtwZ10TdC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, datasetA, datasetB, datasetC):\n",
        "        self.datasetA = datasetA\n",
        "        self.datasetB = datasetB\n",
        "        self.datasetC = datasetC\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        xA = self.datasetA[index]\n",
        "        xB = self.datasetB[index]\n",
        "        xC = self.datasetC[index]\n",
        "        return xA, xB, xC\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.datasetA)\n",
        "    "
      ],
      "metadata": {
        "id": "OajK1OsE0xdy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate y data file\n",
        "path = '/content/gdrive/MyDrive/label_set0'\n",
        "if not os.path.exists(path):\n",
        "    path = '/content/gdrive/MyDrive/graph/' \n",
        "    files = os.listdir(path)   \n",
        "    num_file = len(files)       \n",
        "\n",
        "    #graph.x file has been generated by recon_kw\n",
        "    #generate sample\n",
        "    sample_comment = []\n",
        "    sample_comment_atten_mask = []\n",
        "\n",
        "    for i in tqdm(range(num_file)):\n",
        "        sample_comment.append(np.load('/content/gdrive/MyDrive/sample_comment/sample_comment{0:}.npy'.format(i)))\n",
        "        sample_comment_atten_mask.append(np.load('/content/gdrive/MyDrive/sample_comment_set_atten_mask/sample_comment_set_atten_mask{0:}.npy'.format(i)))\n",
        "    gen_y(sample_comment, sample_comment_atten_mask)"
      ],
      "metadata": {
        "id": "fxBD4qnTgDHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42453406-9772-432f-8845-d0e9882c77c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 106/106 [00:00<00:00, 605.75it/s]\n",
            "100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN with fixed pretrained embedding"
      ],
      "metadata": {
        "id": "ucPROchYOghj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. lower batchsize\n",
        "# 2. shuffle # 4. lower hidden size\n",
        "# 3. lr\n",
        "# 5. align two dataset\n",
        "# 6. stop when comments aren't continuing, [padding] 2\n",
        "# 7. better decoding\n",
        "# 8. take the avg length of comments 1"
      ],
      "metadata": {
        "id": "KP550idV6Yfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, GraphNorm\n",
        "\n",
        "class GraphEncoder(torch.nn.Module):\n",
        "    def __init__(self, embedding_size):\n",
        "        super(GraphEncoder, self).__init__()\n",
        "        self.embedding_size = embedding_size        \n",
        "        self.hidden_size = 128\n",
        "        #GCN encoder\n",
        "        self.conv1 = GATConv(self.embedding_size, self.hidden_size, edge_dim=1)\n",
        "        self.norm = GraphNorm(self.hidden_size)\n",
        "        self.conv2 = GATConv(self.hidden_size, self.hidden_size, edge_dim=1)\n",
        "        self.fc = nn.Linear(self.hidden_size, self.hidden_size) ########big fc!!\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
        "    \n",
        "        ## 1. GCN\n",
        "        x_ = self.conv1(x, edge_index, edge_attr.to(torch.float))\n",
        "        x_ = self.norm(x_)\n",
        "        x_ = F.relu(x_)\n",
        "        x_ = x_.to(torch.float32)\n",
        "        x_ = self.conv2(x_, edge_index, edge_attr.to(torch.float))\n",
        "        x_ = self.norm(x_)\n",
        "        x_ = x_.to(torch.float32)\n",
        "        x_ = torch.tanh(self.fc(x_)) #num_nodes, embedding_size --> num_nodes, encoder_hidden_size\n",
        "\n",
        "\n",
        "        return x_\n",
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, units, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, units)\n",
        "        self.W2 = nn.Linear(hidden_size, units)\n",
        "        self.V = nn.Linear(units, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, batch_size, query, values):\n",
        "        #query: init_hidden_state: headline embedding: 1, embedding_size\n",
        "        #values: encoder_output_embeeding: 1, bs, embedding_size\n",
        "        query = query.view(batch_size, 1, -1) # bs, 1, embedding_size\n",
        "        score = self.V(self.tanh(self.W1(values) + self.W2(query))) #bs, num_nodes, attention_hidden_size -> bs, num_nodes, 1\n",
        "        attention_weights = self.softmax(score) #bs, num_nodes, 1\n",
        "        context_vector = torch.sum(attention_weights * values, 1) #bs, embedding_size == bs, encoder_hidden_size\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "\n",
        "\n",
        "class GRUDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_size, embedding_weight, dec_units, encoder_hidden_size):\n",
        "        super(GRUDecoder, self).__init__()\n",
        "        #GRU Decoder\n",
        "        self.dec_units = dec_units\n",
        "        self.vocab_size = vocab_size\n",
        "        self.encoder_hidden_size = encoder_hidden_size\n",
        "        self.embedding_size = embedding_size\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.encoder_hidden_size,\n",
        "            hidden_size=self.dec_units\n",
        "        )\n",
        "        self.fc_input = nn.Linear(768, self.embedding_size)\n",
        "        self.fc = nn.Linear(self.dec_units, 768)\n",
        "        self.embedding = nn.Linear(768, vocab_size, bias=False)\n",
        "        with torch.no_grad():\n",
        "            self.embedding.weight.copy_(embedding_weight)\n",
        "        self.attention = BahdanauAttention(self.dec_units, self.encoder_hidden_size)\n",
        "        self.attn_combine = nn.Linear(self.embedding_size + self.encoder_hidden_size, self.dec_units)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, batch_size, x, hidden, enc_output):\n",
        "        #x: bs, bs, encoder_hidden_size\n",
        "        #hidden: 1, bs, encoder_hidden_size\n",
        "        #enc_output: num_nodes, bs, encoder_hidden_size\n",
        "        #output -> embedding\n",
        "        x = self.fc_input(x).view(1, batch_size, -1) #1, bs, embedding_size\n",
        "\n",
        "        hidden = hidden.view(1, batch_size, -1) # 1, bs, encoder_hidden_size\n",
        "\n",
        "        context_vector, attention_weights = self.attention(batch_size, hidden, enc_output) #1, encoder_hidden_size\n",
        "\n",
        "        context_vector = context_vector.unsqueeze(0) # 1, bs, encoder_hidden_size\n",
        "\n",
        "        #concatenate x and context_vector\n",
        "        x = torch.cat((context_vector, x), -1) #1, bs, embedding_size + encoder_hidden_size\n",
        "\n",
        "        x = self.relu(self.attn_combine(x)) #1, bs, dec_units\n",
        "\n",
        "        #pass to GRU\n",
        "        output, hn = self.gru(x, hidden)\n",
        "\n",
        "        #classification\n",
        "        output = self.fc(output[0]) #bs, vocab_size\n",
        "\n",
        "        output = self.embedding(output)\n",
        "\n",
        "        output = F.log_softmax(output, dim=1) #1, vocab_size\n",
        "\n",
        "        return output, hn \n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "7qR_BIoyOi7E"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_num_nodes(path, num_file):\n",
        "    len_list = []\n",
        "    for i in range(num_file):\n",
        "        len_list.append(len(os.listdir(path+'/graph_'+str(i))))\n",
        "    return max(len_list)\n"
      ],
      "metadata": {
        "id": "JAba770dO4Lx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/gdrive/MyDrive/graph/' \n",
        "files = os.listdir(path)   \n",
        "num_file = len(files)  \n",
        "\n",
        "num_sample = 10\n",
        "\n",
        "max_num_nodes = get_max_num_nodes('/content/gdrive/MyDrive/graph', num_file)\n",
        "batchsize = 8\n",
        "\n",
        "#graph dataset\n",
        "graph_dataset = MyOwnDataset('/content/gdrive/MyDrive')\n",
        "# graph_loader = DataLoader(graph_dataset, batchsize, shuffle=False)\n",
        "\n",
        "#vector y dataloader\n",
        "path_y_vector = '/content/gdrive/MyDrive/label_set'\n",
        "\n",
        "#scalar y dataloader\n",
        "path_y_scalar = '/content/gdrive/MyDrive/scalar_label_set'\n",
        "\n",
        "datasetA = graph_dataset\n",
        "datasetB_list = [YDataset(path_y_vector, i) for i in range(num_sample)]\n",
        "datasetC_list = [YDataset(path_y_scalar, i) for i in range(num_sample)]\n",
        "dataset_list = [MyDataset(datasetA, datasetB_list[i], datasetC_list[i]) for i in range(num_sample)]"
      ],
      "metadata": {
        "id": "K7zMccVZ0ybK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d29f1a-056a-4633-d398-7c64478e22cb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "100%|██████████| 106/106 [00:04<00:00, 25.61it/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch_geometric.loader import DataLoader\n",
        "# #training\n",
        "# embedding_size = 128\n",
        "# dec_units = 128\n",
        "# encoder_hidden_size = 128\n",
        "# vocab_size = len(tokenizer)\n",
        "# lr = 5e-4\n",
        "# num_sample = 10\n",
        "# epochs = 3000\n",
        "\n",
        "# graph_encoder = torch.load('/content/gdrive/MyDrive/single_graph_encoder_epoch3400.pt',map_location=device)\n",
        "# GRU_decoder = torch.load('/content/gdrive/MyDrive/single_GRU_decoder_epoch3400.pt',map_location=device)\n",
        "\n",
        "# encoder_optimizer = optim.Adam(graph_encoder.parameters(), lr=lr)\n",
        "# decoder_optimizer = optim.Adam(GRU_decoder.parameters(), lr=lr)\n",
        "\n",
        "# encoder_optimizer.load_state_dict(torch.load('/content/gdrive/MyDrive/single_encoder_optimizer_epoch3400.pth',map_location=device))\n",
        "# decoder_optimizer.load_state_dict(torch.load('/content/gdrive/MyDrive/single_decoder_optimizer_epoch3400.pth',map_location=device))"
      ],
      "metadata": {
        "id": "ObIk9XuusWv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "!wandb login"
      ],
      "metadata": {
        "id": "np0w5quhll8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"NLP-project\", entity=\"congliu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729,
          "referenced_widgets": [
            "a74f74583f2b401588efda3afe136fff",
            "43aa8112cfbd4a0eb63fb00d58a37681",
            "5021b7fd4b4a411695c1eca906580e11",
            "60d7a01baabd4930bad5c3649f445bc7",
            "2d209dd9084b4bf6a528dbfe185d46ca",
            "b1ac1e8688af43d4986d412275070581",
            "494729b01bd442d2b517b77bf986023e",
            "5dc3c320636b48bbb6dbfb184a6263ce"
          ]
        },
        "id": "eGEerzUoCJtZ",
        "outputId": "c6d1df58-575d-4b8a-dcc0-25d7f44cce25"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:1dy36owi) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a74f74583f2b401588efda3afe136fff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>5.54592</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">prime-sicko-1</strong>: <a href=\"https://wandb.ai/congliu/NLP-project/runs/1dy36owi\" target=\"_blank\">https://wandb.ai/congliu/NLP-project/runs/1dy36owi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220406_132044-1dy36owi/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:1dy36owi). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220406_141322-2pqy40la</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/congliu/NLP-project/runs/2pqy40la\" target=\"_blank\">jem-hadar-tuvix-2</a></strong> to <a href=\"https://wandb.ai/congliu/NLP-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/congliu/NLP-project/runs/2pqy40la?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f313401c690>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.config = {\n",
        "  \"learning_rate\": 1e-4,\n",
        "  \"epochs\": 2000,\n",
        "  \"batch_size\": 8,\n",
        "  \"encoder_hidden_size\": 128,\n",
        "  \"decoder_hidden_size\": 128,\n",
        "  \"embedding_size\": 128,\n",
        "  \"num_sample\": 10,\n",
        "  \"vocab_size\": len(tokenizer)\n",
        "}"
      ],
      "metadata": {
        "id": "BgBTvllZCOZQ"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "#training\n",
        "embedding_size = 128\n",
        "dec_units = 128\n",
        "encoder_hidden_size = 128\n",
        "vocab_size = len(tokenizer)\n",
        "lr = 1e-4\n",
        "num_sample = 10\n",
        "epochs = 2000\n",
        "\n",
        "model_weight = model_weight.T.to(device)\n",
        "# # ##model\n",
        "graph_encoder = GraphEncoder(768).to(device)\n",
        "GRU_decoder = GRUDecoder(vocab_size, embedding_size, model_weight.T.to(device), dec_units, encoder_hidden_size).to(device)\n",
        "\n",
        "# #loss definition\n",
        "weight = torch.ones(vocab_size).to(device)\n",
        "weight[0] = 0\n",
        "weight[100] = 0\n",
        "criterion = nn.CrossEntropyLoss(weight=weight)\n",
        "\n",
        "# #optimizer\n",
        "encoder_optimizer = optim.Adam(graph_encoder.parameters(), lr=lr)\n",
        "decoder_optimizer = optim.Adam(GRU_decoder.parameters(), lr=lr)\n",
        "\n",
        "loader = DataLoader(dataset_list[0], batch_size=8, shuffle=True, pin_memory=True, num_workers=2, prefetch_factor=2)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    progress_bar = tqdm(loader)\n",
        "    for j, (data, y, scalar_y) in enumerate(progress_bar):\n",
        "        progress_bar.set_description('Epoch ' + str(epoch))\n",
        "        batchsize = y.shape[0]\n",
        "        loss = 0\n",
        "\n",
        "        data = data.to(device)\n",
        "        y = y.to(device).transpose(0, 1) #200, bs, 768\n",
        "        scalar_y = torch.squeeze(scalar_y.to(device)).transpose(0, 1)\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        \n",
        "        #encoder\n",
        "        x_encode = graph_encoder(data) # bs*num_nodes, encoder_hidden_size\n",
        "\n",
        "        #grasp corresponding x and generate decoder hidden\n",
        "        encoder_outputs = torch.zeros(batchsize, max_num_nodes, graph_encoder.hidden_size).to(device)\n",
        "        decoder_hidden = torch.zeros(batchsize, 1, graph_encoder.hidden_size).to(device)\n",
        "        idx = data.batch.cpu().numpy()\n",
        "        start_idx = 0\n",
        "        for batch_num in range(batchsize):\n",
        "            idx_list = np.where(idx==batch_num)[0]\n",
        "            graph_data = x_encode[idx_list]\n",
        "            encoder_outputs[batch_num, :len(idx_list)] = graph_data\n",
        "            #find headline vertex \n",
        "            decoder_hidden[batch_num] = graph_data[-2].view(1, -1)\n",
        "        encoder_outputs.transpose(0, 1) #max_num_nodes, bs, encoder_hidden_size\n",
        "        decoder_hidden.transpose(0, 1) # 1, bs, encoder_hidden_size\n",
        "\n",
        "        dec_input = torch.squeeze(model(torch.tensor([101]).to(device).view(1, -1))[0])\n",
        "        dec_input = dec_input.repeat(batchsize).view(batchsize, -1)\n",
        "        #teacher forcing\n",
        "        correct = 0\n",
        "        for t in range(y.shape[0]-1):\n",
        "            # dec_input = y[t] #\n",
        "            predictions, decoder_hidden = GRU_decoder(batchsize, dec_input, decoder_hidden, encoder_outputs)\n",
        "            pred_token = torch.argmax(predictions, 1)\n",
        "            correct += sum(pred_token == scalar_y[t+1]).item()\n",
        "            loss += criterion(predictions, scalar_y[t+1])\n",
        "            dec_input = y[t+1]\n",
        "        \n",
        "        acc = correct/batchsize/y.shape[0]\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()/y.shape[0]\n",
        "\n",
        "        progress_bar.set_postfix(loss='%.3f' % (running_loss /(j+1)),\n",
        "                                    acc='%.3f' % (acc))\n",
        "            \n",
        "    wandb.log({\"loss\": running_loss /(j+1)})\n",
        "    # Optional\n",
        "    wandb.watch(model)\n",
        "\n",
        "    if epoch % 100 == 99:\n",
        "        torch.save(graph_encoder, '/content/gdrive/MyDrive/single_graph_encoder_epoch{0:}.pt'.format(epoch+1))\n",
        "        torch.save(GRU_decoder, '/content/gdrive/MyDrive/single_GRU_decoder_epoch{0:}.pt'.format(epoch+1))\n",
        "        torch.save(encoder_optimizer.state_dict(),  '/content/gdrive/MyDrive/single_encoder_optimizer_epoch{0:}.pth'.format(epoch+1))\n",
        "        torch.save(decoder_optimizer.state_dict(),  '/content/gdrive/MyDrive/single_decoder_optimizer_epoch{0:}.pth'.format(epoch+1))\n",
        "\n",
        "\n",
        "        "
      ],
      "metadata": {
        "id": "n_GSP8NQFvfj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b85884-5d28-4f9a-c59c-bb865f4c933f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 14/14 [00:04<00:00,  2.94it/s, acc=0.030, loss=10.002]\n",
            "Epoch 1: 100%|██████████| 14/14 [00:04<00:00,  3.16it/s, acc=0.000, loss=9.388]\n",
            "Epoch 2: 100%|██████████| 14/14 [00:04<00:00,  3.15it/s, acc=0.010, loss=8.188]\n",
            "Epoch 3: 100%|██████████| 14/14 [00:04<00:00,  3.13it/s, acc=0.030, loss=7.582]\n",
            "Epoch 4: 100%|██████████| 14/14 [00:04<00:00,  3.13it/s, acc=0.090, loss=7.011]\n",
            "Epoch 5: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s, acc=0.020, loss=6.835]\n",
            "Epoch 6: 100%|██████████| 14/14 [00:04<00:00,  3.08it/s, acc=0.040, loss=6.582]\n",
            "Epoch 7: 100%|██████████| 14/14 [00:04<00:00,  3.12it/s, acc=0.040, loss=6.478]\n",
            "Epoch 8: 100%|██████████| 14/14 [00:04<00:00,  3.13it/s, acc=0.040, loss=6.507]\n",
            "Epoch 9: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s, acc=0.060, loss=6.450]\n",
            "Epoch 10: 100%|██████████| 14/14 [00:04<00:00,  3.09it/s, acc=0.030, loss=6.399]\n",
            "Epoch 11: 100%|██████████| 14/14 [00:04<00:00,  3.10it/s, acc=0.070, loss=6.318]\n",
            "Epoch 12: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s, acc=0.050, loss=6.237]\n",
            "Epoch 13: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s, acc=0.030, loss=6.292]\n",
            "Epoch 14: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s, acc=0.060, loss=6.314]\n",
            "Epoch 15: 100%|██████████| 14/14 [00:04<00:00,  2.80it/s, acc=0.020, loss=6.225]\n",
            "Epoch 16: 100%|██████████| 14/14 [00:05<00:00,  2.78it/s, acc=0.030, loss=6.274]\n",
            "Epoch 17: 100%|██████████| 14/14 [00:05<00:00,  2.76it/s, acc=0.080, loss=6.196]\n",
            "Epoch 18: 100%|██████████| 14/14 [00:05<00:00,  2.77it/s, acc=0.030, loss=6.156]\n",
            "Epoch 19: 100%|██████████| 14/14 [00:05<00:00,  2.79it/s, acc=0.020, loss=5.909]\n",
            "Epoch 20: 100%|██████████| 14/14 [00:05<00:00,  2.77it/s, acc=0.070, loss=6.121]\n",
            "Epoch 21: 100%|██████████| 14/14 [00:05<00:00,  2.74it/s, acc=0.070, loss=6.076]\n",
            "Epoch 22: 100%|██████████| 14/14 [00:05<00:00,  2.77it/s, acc=0.010, loss=6.112]\n",
            "Epoch 23: 100%|██████████| 14/14 [00:05<00:00,  2.77it/s, acc=0.040, loss=5.988]\n",
            "Epoch 24: 100%|██████████| 14/14 [00:05<00:00,  2.76it/s, acc=0.020, loss=6.094]\n",
            "Epoch 25: 100%|██████████| 14/14 [00:05<00:00,  2.75it/s, acc=0.060, loss=6.089]\n",
            "Epoch 26: 100%|██████████| 14/14 [00:05<00:00,  2.74it/s, acc=0.050, loss=6.117]\n",
            "Epoch 27: 100%|██████████| 14/14 [00:05<00:00,  2.74it/s, acc=0.070, loss=6.100]\n",
            "Epoch 28: 100%|██████████| 14/14 [00:05<00:00,  2.71it/s, acc=0.000, loss=5.846]\n",
            "Epoch 29: 100%|██████████| 14/14 [00:05<00:00,  2.75it/s, acc=0.030, loss=6.074]\n",
            "Epoch 30: 100%|██████████| 14/14 [00:05<00:00,  2.75it/s, acc=0.040, loss=6.032]\n",
            "Epoch 31: 100%|██████████| 14/14 [00:05<00:00,  2.77it/s, acc=0.020, loss=6.060]\n",
            "Epoch 32: 100%|██████████| 14/14 [00:05<00:00,  2.75it/s, acc=0.080, loss=6.019]\n",
            "Epoch 33: 100%|██████████| 14/14 [00:05<00:00,  2.73it/s, acc=0.010, loss=5.928]\n",
            "Epoch 34: 100%|██████████| 14/14 [00:05<00:00,  2.72it/s, acc=0.020, loss=6.045]\n",
            "Epoch 35: 100%|██████████| 14/14 [00:05<00:00,  2.73it/s, acc=0.060, loss=6.016]\n",
            "Epoch 36: 100%|██████████| 14/14 [00:05<00:00,  2.72it/s, acc=0.050, loss=6.009]\n",
            "Epoch 37: 100%|██████████| 14/14 [00:05<00:00,  2.71it/s, acc=0.060, loss=5.989]\n",
            "Epoch 38: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s, acc=0.020, loss=5.974]\n",
            "Epoch 39: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s, acc=0.060, loss=5.986]\n",
            "Epoch 40: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s, acc=0.010, loss=5.987]\n",
            "Epoch 41: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s, acc=0.050, loss=5.970]\n",
            "Epoch 42: 100%|██████████| 14/14 [00:05<00:00,  2.72it/s, acc=0.020, loss=5.822]\n",
            "Epoch 43: 100%|██████████| 14/14 [00:05<00:00,  2.70it/s, acc=0.060, loss=5.960]\n",
            "Epoch 44: 100%|██████████| 14/14 [00:05<00:00,  2.71it/s, acc=0.050, loss=5.962]\n",
            "Epoch 45: 100%|██████████| 14/14 [00:05<00:00,  2.71it/s, acc=0.030, loss=5.955]\n",
            "Epoch 46: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s, acc=0.030, loss=5.938]\n",
            "Epoch 47: 100%|██████████| 14/14 [00:05<00:00,  2.71it/s, acc=0.070, loss=5.963]\n",
            "Epoch 48: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s, acc=0.040, loss=5.924]\n",
            "Epoch 49: 100%|██████████| 14/14 [00:05<00:00,  2.70it/s, acc=0.060, loss=5.919]\n",
            "Epoch 50: 100%|██████████| 14/14 [00:05<00:00,  2.67it/s, acc=0.030, loss=5.933]\n",
            "Epoch 51: 100%|██████████| 14/14 [00:05<00:00,  2.73it/s, acc=0.050, loss=5.932]\n",
            "Epoch 52: 100%|██████████| 14/14 [00:05<00:00,  2.67it/s, acc=0.020, loss=5.936]\n",
            "Epoch 53: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s, acc=0.060, loss=5.902]\n",
            "Epoch 54: 100%|██████████| 14/14 [00:05<00:00,  2.67it/s, acc=0.050, loss=5.925]\n",
            "Epoch 55: 100%|██████████| 14/14 [00:05<00:00,  2.68it/s, acc=0.030, loss=5.934]\n",
            "Epoch 56: 100%|██████████| 14/14 [00:05<00:00,  2.67it/s, acc=0.050, loss=5.924]\n",
            "Epoch 57: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s, acc=0.020, loss=5.908]\n",
            "Epoch 58: 100%|██████████| 14/14 [00:05<00:00,  2.47it/s, acc=0.040, loss=5.889]\n",
            "Epoch 59: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s, acc=0.030, loss=5.916]\n",
            "Epoch 60: 100%|██████████| 14/14 [00:05<00:00,  2.67it/s, acc=0.040, loss=5.882]\n",
            "Epoch 61: 100%|██████████| 14/14 [00:05<00:00,  2.67it/s, acc=0.040, loss=5.887]\n",
            "Epoch 62: 100%|██████████| 14/14 [00:05<00:00,  2.66it/s, acc=0.020, loss=5.615]\n",
            "Epoch 63: 100%|██████████| 14/14 [00:05<00:00,  2.65it/s, acc=0.040, loss=5.827]\n",
            "Epoch 64: 100%|██████████| 14/14 [00:05<00:00,  2.65it/s, acc=0.020, loss=5.587]\n",
            "Epoch 65: 100%|██████████| 14/14 [00:05<00:00,  2.65it/s, acc=0.040, loss=5.879]\n",
            "Epoch 66: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s, acc=0.050, loss=5.823]\n",
            "Epoch 67: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s, acc=0.040, loss=5.877]\n",
            "Epoch 68: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s, acc=0.060, loss=5.872]\n",
            "Epoch 69: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s, acc=0.070, loss=5.878]\n",
            "Epoch 70: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s, acc=0.010, loss=5.847]\n",
            "Epoch 71: 100%|██████████| 14/14 [00:05<00:00,  2.65it/s, acc=0.020, loss=5.880]\n",
            "Epoch 72: 100%|██████████| 14/14 [00:05<00:00,  2.67it/s, acc=0.050, loss=5.844]\n",
            "Epoch 73: 100%|██████████| 14/14 [00:05<00:00,  2.66it/s, acc=0.070, loss=5.864]\n",
            "Epoch 74: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s, acc=0.030, loss=5.880]\n",
            "Epoch 75: 100%|██████████| 14/14 [00:05<00:00,  2.62it/s, acc=0.030, loss=5.859]\n",
            "Epoch 76: 100%|██████████| 14/14 [00:05<00:00,  2.66it/s, acc=0.080, loss=5.852]\n",
            "Epoch 77: 100%|██████████| 14/14 [00:05<00:00,  2.65it/s, acc=0.010, loss=5.853]\n",
            "Epoch 78: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s, acc=0.040, loss=5.855]\n",
            "Epoch 79: 100%|██████████| 14/14 [00:05<00:00,  2.62it/s, acc=0.020, loss=5.849]\n",
            "Epoch 80: 100%|██████████| 14/14 [00:05<00:00,  2.64it/s, acc=0.040, loss=5.828]\n",
            "Epoch 81: 100%|██████████| 14/14 [00:05<00:00,  2.63it/s, acc=0.040, loss=5.820]\n",
            "Epoch 82: 100%|██████████| 14/14 [00:05<00:00,  2.59it/s, acc=0.060, loss=5.837]\n",
            "Epoch 83: 100%|██████████| 14/14 [00:05<00:00,  2.60it/s, acc=0.060, loss=5.826]\n",
            "Epoch 84: 100%|██████████| 14/14 [00:05<00:00,  2.61it/s, acc=0.050, loss=5.690]\n",
            "Epoch 85: 100%|██████████| 14/14 [00:05<00:00,  2.59it/s, acc=0.040, loss=5.787]\n",
            "Epoch 86: 100%|██████████| 14/14 [00:05<00:00,  2.39it/s, acc=0.020, loss=5.825]\n",
            "Epoch 87: 100%|██████████| 14/14 [00:05<00:00,  2.37it/s, acc=0.020, loss=5.776]\n",
            "Epoch 88: 100%|██████████| 14/14 [00:05<00:00,  2.39it/s, acc=0.010, loss=5.800]\n",
            "Epoch 89: 100%|██████████| 14/14 [00:05<00:00,  2.38it/s, acc=0.020, loss=5.800]\n",
            "Epoch 90: 100%|██████████| 14/14 [00:05<00:00,  2.40it/s, acc=0.050, loss=5.801]\n",
            "Epoch 91: 100%|██████████| 14/14 [00:05<00:00,  2.39it/s, acc=0.100, loss=5.773]\n",
            "Epoch 92: 100%|██████████| 14/14 [00:05<00:00,  2.39it/s, acc=0.020, loss=5.771]\n",
            "Epoch 93: 100%|██████████| 14/14 [00:05<00:00,  2.38it/s, acc=0.030, loss=5.814]\n",
            "Epoch 94: 100%|██████████| 14/14 [00:05<00:00,  2.38it/s, acc=0.050, loss=5.790]\n",
            "Epoch 95: 100%|██████████| 14/14 [00:05<00:00,  2.38it/s, acc=0.030, loss=5.769]\n",
            "Epoch 96: 100%|██████████| 14/14 [00:05<00:00,  2.36it/s, acc=0.020, loss=5.686]\n",
            "Epoch 97: 100%|██████████| 14/14 [00:05<00:00,  2.37it/s, acc=0.030, loss=5.759]\n",
            "Epoch 98: 100%|██████████| 14/14 [00:05<00:00,  2.37it/s, acc=0.000, loss=5.746]\n",
            "Epoch 99: 100%|██████████| 14/14 [00:05<00:00,  2.39it/s, acc=0.030, loss=5.689]\n",
            "Epoch 100: 100%|██████████| 14/14 [00:06<00:00,  2.16it/s, acc=0.030, loss=5.741]\n",
            "Epoch 101: 100%|██████████| 14/14 [00:05<00:00,  2.34it/s, acc=0.050, loss=5.753]\n",
            "Epoch 102: 100%|██████████| 14/14 [00:06<00:00,  2.32it/s, acc=0.040, loss=5.738]\n",
            "Epoch 103: 100%|██████████| 14/14 [00:05<00:00,  2.36it/s, acc=0.060, loss=5.730]\n",
            "Epoch 104: 100%|██████████| 14/14 [00:05<00:00,  2.36it/s, acc=0.020, loss=5.542]\n",
            "Epoch 105: 100%|██████████| 14/14 [00:05<00:00,  2.35it/s, acc=0.040, loss=5.700]\n",
            "Epoch 106: 100%|██████████| 14/14 [00:05<00:00,  2.37it/s, acc=0.060, loss=5.725]\n",
            "Epoch 107: 100%|██████████| 14/14 [00:05<00:00,  2.37it/s, acc=0.050, loss=5.708]\n",
            "Epoch 108: 100%|██████████| 14/14 [00:05<00:00,  2.35it/s, acc=0.020, loss=5.732]\n",
            "Epoch 109: 100%|██████████| 14/14 [00:05<00:00,  2.37it/s, acc=0.060, loss=5.703]\n",
            "Epoch 110: 100%|██████████| 14/14 [00:05<00:00,  2.36it/s, acc=0.050, loss=5.708]\n",
            "Epoch 111: 100%|██████████| 14/14 [00:05<00:00,  2.35it/s, acc=0.040, loss=5.694]\n",
            "Epoch 112: 100%|██████████| 14/14 [00:06<00:00,  2.33it/s, acc=0.020, loss=5.611]\n",
            "Epoch 113: 100%|██████████| 14/14 [00:06<00:00,  2.33it/s, acc=0.040, loss=5.718]\n",
            "Epoch 114: 100%|██████████| 14/14 [00:05<00:00,  2.35it/s, acc=0.050, loss=5.697]\n",
            "Epoch 115: 100%|██████████| 14/14 [00:05<00:00,  2.33it/s, acc=0.030, loss=5.713]\n",
            "Epoch 116: 100%|██████████| 14/14 [00:05<00:00,  2.35it/s, acc=0.020, loss=5.684]\n",
            "Epoch 117: 100%|██████████| 14/14 [00:05<00:00,  2.35it/s, acc=0.040, loss=5.674]\n",
            "Epoch 118: 100%|██████████| 14/14 [00:05<00:00,  2.36it/s, acc=0.030, loss=5.684]\n",
            "Epoch 119: 100%|██████████| 14/14 [00:05<00:00,  2.34it/s, acc=0.040, loss=5.708]\n",
            "Epoch 120: 100%|██████████| 14/14 [00:06<00:00,  2.32it/s, acc=0.030, loss=5.688]\n",
            "Epoch 121: 100%|██████████| 14/14 [00:05<00:00,  2.34it/s, acc=0.050, loss=5.681]\n",
            "Epoch 122: 100%|██████████| 14/14 [00:06<00:00,  2.32it/s, acc=0.040, loss=5.674]\n",
            "Epoch 123: 100%|██████████| 14/14 [00:06<00:00,  2.33it/s, acc=0.050, loss=5.582]\n",
            "Epoch 124: 100%|██████████| 14/14 [00:06<00:00,  2.33it/s, acc=0.030, loss=5.696]\n",
            "Epoch 125: 100%|██████████| 14/14 [00:06<00:00,  2.18it/s, acc=0.020, loss=5.709]\n",
            "Epoch 126: 100%|██████████| 14/14 [00:06<00:00,  2.33it/s, acc=0.080, loss=5.684]\n",
            "Epoch 127: 100%|██████████| 14/14 [00:05<00:00,  2.35it/s, acc=0.020, loss=5.656]\n",
            "Epoch 128: 100%|██████████| 14/14 [00:06<00:00,  2.31it/s, acc=0.060, loss=5.648]\n",
            "Epoch 129: 100%|██████████| 14/14 [00:06<00:00,  2.32it/s, acc=0.050, loss=5.673]\n",
            "Epoch 130: 100%|██████████| 14/14 [00:06<00:00,  2.32it/s, acc=0.050, loss=5.640]\n",
            "Epoch 131: 100%|██████████| 14/14 [00:06<00:00,  2.29it/s, acc=0.040, loss=5.690]\n",
            "Epoch 132: 100%|██████████| 14/14 [00:05<00:00,  2.34it/s, acc=0.060, loss=5.664]\n",
            "Epoch 133: 100%|██████████| 14/14 [00:06<00:00,  2.28it/s, acc=0.050, loss=5.658]\n",
            "Epoch 134: 100%|██████████| 14/14 [00:06<00:00,  2.31it/s, acc=0.030, loss=5.676]\n",
            "Epoch 135: 100%|██████████| 14/14 [00:06<00:00,  2.30it/s, acc=0.050, loss=5.650]\n",
            "Epoch 136: 100%|██████████| 14/14 [00:06<00:00,  2.30it/s, acc=0.030, loss=5.676]\n",
            "Epoch 137: 100%|██████████| 14/14 [00:06<00:00,  2.30it/s, acc=0.060, loss=5.473]\n",
            "Epoch 138: 100%|██████████| 14/14 [00:06<00:00,  2.30it/s, acc=0.020, loss=5.671]\n",
            "Epoch 139: 100%|██████████| 14/14 [00:06<00:00,  2.30it/s, acc=0.030, loss=5.661]\n",
            "Epoch 140: 100%|██████████| 14/14 [00:06<00:00,  2.29it/s, acc=0.030, loss=5.654]\n",
            "Epoch 141: 100%|██████████| 14/14 [00:06<00:00,  2.28it/s, acc=0.040, loss=5.615]\n",
            "Epoch 142: 100%|██████████| 14/14 [00:06<00:00,  2.32it/s, acc=0.040, loss=5.642]\n",
            "Epoch 143: 100%|██████████| 14/14 [00:06<00:00,  2.28it/s, acc=0.030, loss=5.620]\n",
            "Epoch 144: 100%|██████████| 14/14 [00:06<00:00,  2.29it/s, acc=0.020, loss=5.623]\n",
            "Epoch 145: 100%|██████████| 14/14 [00:06<00:00,  2.31it/s, acc=0.050, loss=5.626]\n",
            "Epoch 146: 100%|██████████| 14/14 [00:06<00:00,  2.32it/s, acc=0.030, loss=5.638]\n",
            "Epoch 147: 100%|██████████| 14/14 [00:06<00:00,  2.30it/s, acc=0.050, loss=5.615]\n",
            "Epoch 148: 100%|██████████| 14/14 [00:06<00:00,  2.27it/s, acc=0.000, loss=5.470]\n",
            "Epoch 149: 100%|██████████| 14/14 [00:06<00:00,  2.29it/s, acc=0.060, loss=5.636]\n",
            "Epoch 150: 100%|██████████| 14/14 [00:06<00:00,  2.31it/s, acc=0.030, loss=5.652]\n",
            "Epoch 151: 100%|██████████| 14/14 [00:06<00:00,  2.28it/s, acc=0.030, loss=5.616]\n",
            "Epoch 152: 100%|██████████| 14/14 [00:06<00:00,  2.28it/s, acc=0.040, loss=5.592]\n",
            "Epoch 153: 100%|██████████| 14/14 [00:06<00:00,  2.25it/s, acc=0.020, loss=5.616]\n",
            "Epoch 154: 100%|██████████| 14/14 [00:06<00:00,  2.26it/s, acc=0.070, loss=5.614]\n",
            "Epoch 155: 100%|██████████| 14/14 [00:06<00:00,  2.28it/s, acc=0.070, loss=5.604]\n",
            "Epoch 156: 100%|██████████| 14/14 [00:06<00:00,  2.27it/s, acc=0.040, loss=5.611]\n",
            "Epoch 157: 100%|██████████| 14/14 [00:06<00:00,  2.26it/s, acc=0.040, loss=5.456]\n",
            "Epoch 158: 100%|██████████| 14/14 [00:06<00:00,  2.11it/s, acc=0.040, loss=5.610]\n",
            "Epoch 159: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.020, loss=5.602]\n",
            "Epoch 160: 100%|██████████| 14/14 [00:06<00:00,  2.07it/s, acc=0.050, loss=5.575]\n",
            "Epoch 161: 100%|██████████| 14/14 [00:06<00:00,  2.12it/s, acc=0.070, loss=5.586]\n",
            "Epoch 162: 100%|██████████| 14/14 [00:06<00:00,  2.10it/s, acc=0.040, loss=5.578]\n",
            "Epoch 163: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.020, loss=5.504]\n",
            "Epoch 164: 100%|██████████| 14/14 [00:06<00:00,  2.11it/s, acc=0.010, loss=5.300]\n",
            "Epoch 165: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.030, loss=5.616]\n",
            "Epoch 166: 100%|██████████| 14/14 [00:06<00:00,  2.10it/s, acc=0.020, loss=5.582]\n",
            "Epoch 167: 100%|██████████| 14/14 [00:06<00:00,  2.10it/s, acc=0.050, loss=5.618]\n",
            "Epoch 168: 100%|██████████| 14/14 [00:06<00:00,  2.08it/s, acc=0.030, loss=5.592]\n",
            "Epoch 169: 100%|██████████| 14/14 [00:06<00:00,  2.07it/s, acc=0.030, loss=5.592]\n",
            "Epoch 170: 100%|██████████| 14/14 [00:06<00:00,  2.10it/s, acc=0.020, loss=5.605]\n",
            "Epoch 171: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.070, loss=5.601]\n",
            "Epoch 172: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.020, loss=5.580]\n",
            "Epoch 173: 100%|██████████| 14/14 [00:06<00:00,  2.07it/s, acc=0.040, loss=5.564]\n",
            "Epoch 174: 100%|██████████| 14/14 [00:06<00:00,  2.10it/s, acc=0.040, loss=5.575]\n",
            "Epoch 175: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.040, loss=5.561]\n",
            "Epoch 176: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.030, loss=5.572]\n",
            "Epoch 177: 100%|██████████| 14/14 [00:06<00:00,  2.07it/s, acc=0.030, loss=5.588]\n",
            "Epoch 178: 100%|██████████| 14/14 [00:06<00:00,  2.07it/s, acc=0.000, loss=5.548]\n",
            "Epoch 179: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.020, loss=5.550]\n",
            "Epoch 180: 100%|██████████| 14/14 [00:06<00:00,  2.08it/s, acc=0.070, loss=5.555]\n",
            "Epoch 181: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.050, loss=5.599]\n",
            "Epoch 182: 100%|██████████| 14/14 [00:06<00:00,  2.09it/s, acc=0.110, loss=5.579]\n",
            "Epoch 183: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.060, loss=5.566]\n",
            "Epoch 184: 100%|██████████| 14/14 [00:06<00:00,  2.04it/s, acc=0.010, loss=5.566]\n",
            "Epoch 185: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.040, loss=5.403]\n",
            "Epoch 186: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.030, loss=5.573]\n",
            "Epoch 187: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.040, loss=5.529]\n",
            "Epoch 188: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.050, loss=5.592]\n",
            "Epoch 189: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.030, loss=5.600]\n",
            "Epoch 190: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.030, loss=5.545]\n",
            "Epoch 191: 100%|██████████| 14/14 [00:07<00:00,  1.96it/s, acc=0.030, loss=5.553]\n",
            "Epoch 192: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.020, loss=5.550]\n",
            "Epoch 193: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.050, loss=5.537]\n",
            "Epoch 194: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.040, loss=5.540]\n",
            "Epoch 195: 100%|██████████| 14/14 [00:06<00:00,  2.04it/s, acc=0.070, loss=5.572]\n",
            "Epoch 196: 100%|██████████| 14/14 [00:06<00:00,  2.02it/s, acc=0.050, loss=5.547]\n",
            "Epoch 197: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.050, loss=5.541]\n",
            "Epoch 198: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.050, loss=5.547]\n",
            "Epoch 199: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.050, loss=5.559]\n",
            "Epoch 200: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.030, loss=5.546]\n",
            "Epoch 201: 100%|██████████| 14/14 [00:07<00:00,  2.00it/s, acc=0.020, loss=5.554]\n",
            "Epoch 202: 100%|██████████| 14/14 [00:07<00:00,  1.89it/s, acc=0.060, loss=5.535]\n",
            "Epoch 203: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.050, loss=5.558]\n",
            "Epoch 204: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.070, loss=5.571]\n",
            "Epoch 205: 100%|██████████| 14/14 [00:07<00:00,  2.00it/s, acc=0.050, loss=5.541]\n",
            "Epoch 206: 100%|██████████| 14/14 [00:06<00:00,  2.06it/s, acc=0.040, loss=5.554]\n",
            "Epoch 207: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.070, loss=5.533]\n",
            "Epoch 208: 100%|██████████| 14/14 [00:06<00:00,  2.05it/s, acc=0.050, loss=5.475]\n",
            "Epoch 209: 100%|██████████| 14/14 [00:06<00:00,  2.00it/s, acc=0.050, loss=5.537]\n",
            "Epoch 210: 100%|██████████| 14/14 [00:06<00:00,  2.04it/s, acc=0.030, loss=5.415]\n",
            "Epoch 211: 100%|██████████| 14/14 [00:06<00:00,  2.04it/s, acc=0.040, loss=5.507]\n",
            "Epoch 212: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.060, loss=5.529]\n",
            "Epoch 213: 100%|██████████| 14/14 [00:06<00:00,  2.03it/s, acc=0.020, loss=5.402]\n",
            "Epoch 214: 100%|██████████| 14/14 [00:06<00:00,  2.03it/s, acc=0.070, loss=5.537]\n",
            "Epoch 215: 100%|██████████| 14/14 [00:06<00:00,  2.02it/s, acc=0.050, loss=5.542]\n",
            "Epoch 216: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.010, loss=5.521]\n",
            "Epoch 217: 100%|██████████| 14/14 [00:06<00:00,  2.02it/s, acc=0.070, loss=5.458]\n",
            "Epoch 218: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.000, loss=5.305]\n",
            "Epoch 219: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.020, loss=5.503]\n",
            "Epoch 220: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.020, loss=5.506]\n",
            "Epoch 221: 100%|██████████| 14/14 [00:07<00:00,  2.00it/s, acc=0.010, loss=5.366]\n",
            "Epoch 222: 100%|██████████| 14/14 [00:07<00:00,  1.99it/s, acc=0.040, loss=5.514]\n",
            "Epoch 223: 100%|██████████| 14/14 [00:06<00:00,  2.02it/s, acc=0.050, loss=5.457]\n",
            "Epoch 224: 100%|██████████| 14/14 [00:06<00:00,  2.02it/s, acc=0.020, loss=5.505]\n",
            "Epoch 225: 100%|██████████| 14/14 [00:06<00:00,  2.00it/s, acc=0.030, loss=5.496]\n",
            "Epoch 226: 100%|██████████| 14/14 [00:06<00:00,  2.04it/s, acc=0.060, loss=5.519]\n",
            "Epoch 227: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.010, loss=5.504]\n",
            "Epoch 228: 100%|██████████| 14/14 [00:06<00:00,  2.01it/s, acc=0.020, loss=5.539]\n",
            "Epoch 229: 100%|██████████| 14/14 [00:07<00:00,  1.89it/s, acc=0.030, loss=5.513]\n",
            "Epoch 230: 100%|██████████| 14/14 [00:07<00:00,  1.87it/s, acc=0.030, loss=5.495]\n",
            "Epoch 231: 100%|██████████| 14/14 [00:07<00:00,  1.87it/s, acc=0.040, loss=5.504]\n",
            "Epoch 232: 100%|██████████| 14/14 [00:07<00:00,  1.87it/s, acc=0.070, loss=5.498]\n",
            "Epoch 233: 100%|██████████| 14/14 [00:07<00:00,  1.88it/s, acc=0.010, loss=5.514]\n",
            "Epoch 234: 100%|██████████| 14/14 [00:07<00:00,  1.88it/s, acc=0.050, loss=5.508]\n",
            "Epoch 235: 100%|██████████| 14/14 [00:07<00:00,  1.87it/s, acc=0.060, loss=5.479]\n",
            "Epoch 236: 100%|██████████| 14/14 [00:07<00:00,  1.87it/s, acc=0.050, loss=5.514]\n",
            "Epoch 237: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.050, loss=5.464]\n",
            "Epoch 238: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.030, loss=5.513]\n",
            "Epoch 239: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.040, loss=5.480]\n",
            "Epoch 240: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.070, loss=5.460]\n",
            "Epoch 241: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.080, loss=5.487]\n",
            "Epoch 242: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.080, loss=5.478]\n",
            "Epoch 243: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.040, loss=5.510]\n",
            "Epoch 244: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.030, loss=5.512]\n",
            "Epoch 245: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.070, loss=5.501]\n",
            "Epoch 246: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.060, loss=5.472]\n",
            "Epoch 247: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.050, loss=5.503]\n",
            "Epoch 248: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.030, loss=5.523]\n",
            "Epoch 249: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.050, loss=5.494]\n",
            "Epoch 250: 100%|██████████| 14/14 [00:07<00:00,  1.87it/s, acc=0.050, loss=5.483]\n",
            "Epoch 251: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.030, loss=5.318]\n",
            "Epoch 252: 100%|██████████| 14/14 [00:07<00:00,  1.83it/s, acc=0.040, loss=5.486]\n",
            "Epoch 253: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.040, loss=5.464]\n",
            "Epoch 254: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.090, loss=5.468]\n",
            "Epoch 255: 100%|██████████| 14/14 [00:07<00:00,  1.83it/s, acc=0.020, loss=5.473]\n",
            "Epoch 256: 100%|██████████| 14/14 [00:07<00:00,  1.83it/s, acc=0.040, loss=5.367]\n",
            "Epoch 257: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.030, loss=5.539]\n",
            "Epoch 258: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.060, loss=5.485]\n",
            "Epoch 259: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.040, loss=5.464]\n",
            "Epoch 260: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.070, loss=5.537]\n",
            "Epoch 261: 100%|██████████| 14/14 [00:07<00:00,  1.85it/s, acc=0.070, loss=5.458]\n",
            "Epoch 262: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.040, loss=5.501]\n",
            "Epoch 263: 100%|██████████| 14/14 [00:07<00:00,  1.86it/s, acc=0.080, loss=5.466]\n",
            "Epoch 264: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.080, loss=5.497]\n",
            "Epoch 265: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.040, loss=5.362]\n",
            "Epoch 266: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.030, loss=5.325]\n",
            "Epoch 267: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.030, loss=5.460]\n",
            "Epoch 268: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.060, loss=5.446]\n",
            "Epoch 269: 100%|██████████| 14/14 [00:07<00:00,  1.84it/s, acc=0.050, loss=5.434]\n",
            "Epoch 270: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.020, loss=5.484]\n",
            "Epoch 271: 100%|██████████| 14/14 [00:07<00:00,  1.83it/s, acc=0.040, loss=5.453]\n",
            "Epoch 272: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.020, loss=5.384]\n",
            "Epoch 273: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.040, loss=5.398]\n",
            "Epoch 274: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.050, loss=5.471]\n",
            "Epoch 275: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.050, loss=5.498]\n",
            "Epoch 276: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.050, loss=5.455]\n",
            "Epoch 277: 100%|██████████| 14/14 [00:07<00:00,  1.83it/s, acc=0.090, loss=5.357]\n",
            "Epoch 278: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.050, loss=5.460]\n",
            "Epoch 279: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.080, loss=5.454]\n",
            "Epoch 280: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.040, loss=5.446]\n",
            "Epoch 281: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.060, loss=5.474]\n",
            "Epoch 282: 100%|██████████| 14/14 [00:07<00:00,  1.83it/s, acc=0.010, loss=5.455]\n",
            "Epoch 283: 100%|██████████| 14/14 [00:07<00:00,  1.83it/s, acc=0.040, loss=5.470]\n",
            "Epoch 284: 100%|██████████| 14/14 [00:07<00:00,  1.79it/s, acc=0.020, loss=5.490]\n",
            "Epoch 285: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.070, loss=5.457]\n",
            "Epoch 286: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.020, loss=5.505]\n",
            "Epoch 287: 100%|██████████| 14/14 [00:07<00:00,  1.80it/s, acc=0.080, loss=5.460]\n",
            "Epoch 288: 100%|██████████| 14/14 [00:07<00:00,  1.79it/s, acc=0.060, loss=5.502]\n",
            "Epoch 289: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.040, loss=5.458]\n",
            "Epoch 290: 100%|██████████| 14/14 [00:08<00:00,  1.70it/s, acc=0.060, loss=5.451]\n",
            "Epoch 291: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.080, loss=5.461]\n",
            "Epoch 292: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.030, loss=5.478]\n",
            "Epoch 293: 100%|██████████| 14/14 [00:07<00:00,  1.80it/s, acc=0.040, loss=5.452]\n",
            "Epoch 294: 100%|██████████| 14/14 [00:07<00:00,  1.80it/s, acc=0.050, loss=5.448]\n",
            "Epoch 295: 100%|██████████| 14/14 [00:07<00:00,  1.80it/s, acc=0.040, loss=5.478]\n",
            "Epoch 296: 100%|██████████| 14/14 [00:07<00:00,  1.79it/s, acc=0.050, loss=5.451]\n",
            "Epoch 297: 100%|██████████| 14/14 [00:07<00:00,  1.81it/s, acc=0.070, loss=5.449]\n",
            "Epoch 298: 100%|██████████| 14/14 [00:07<00:00,  1.82it/s, acc=0.080, loss=5.420]\n",
            "Epoch 299: 100%|██████████| 14/14 [00:07<00:00,  1.79it/s, acc=0.020, loss=5.316]\n",
            "Epoch 300: 100%|██████████| 14/14 [00:08<00:00,  1.68it/s, acc=0.080, loss=5.465]\n",
            "Epoch 301: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.070, loss=5.401]\n",
            "Epoch 302: 100%|██████████| 14/14 [00:08<00:00,  1.70it/s, acc=0.060, loss=5.453]\n",
            "Epoch 303: 100%|██████████| 14/14 [00:08<00:00,  1.68it/s, acc=0.040, loss=5.415]\n",
            "Epoch 304: 100%|██████████| 14/14 [00:08<00:00,  1.68it/s, acc=0.100, loss=5.465]\n",
            "Epoch 305: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.060, loss=5.435]\n",
            "Epoch 306: 100%|██████████| 14/14 [00:08<00:00,  1.69it/s, acc=0.100, loss=5.412]\n",
            "Epoch 307: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.050, loss=5.439]\n",
            "Epoch 308: 100%|██████████| 14/14 [00:08<00:00,  1.67it/s, acc=0.090, loss=5.435]\n",
            "Epoch 309: 100%|██████████| 14/14 [00:08<00:00,  1.69it/s, acc=0.050, loss=5.454]\n",
            "Epoch 310: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.020, loss=5.393]\n",
            "Epoch 311: 100%|██████████| 14/14 [02:52<00:00, 12.29s/it, acc=0.070, loss=5.285]\n",
            "Epoch 312: 100%|██████████| 14/14 [00:08<00:00,  1.68it/s, acc=0.040, loss=5.431]\n",
            "Epoch 313: 100%|██████████| 14/14 [00:08<00:00,  1.68it/s, acc=0.010, loss=5.397]\n",
            "Epoch 314: 100%|██████████| 14/14 [00:08<00:00,  1.69it/s, acc=0.100, loss=5.386]\n",
            "Epoch 315: 100%|██████████| 14/14 [00:08<00:00,  1.67it/s, acc=0.040, loss=5.439]\n",
            "Epoch 316: 100%|██████████| 14/14 [00:08<00:00,  1.67it/s, acc=0.040, loss=5.424]\n",
            "Epoch 317: 100%|██████████| 14/14 [00:08<00:00,  1.70it/s, acc=0.030, loss=5.429]\n",
            "Epoch 318: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.050, loss=5.388]\n",
            "Epoch 319: 100%|██████████| 14/14 [00:08<00:00,  1.67it/s, acc=0.070, loss=5.445]\n",
            "Epoch 320: 100%|██████████| 14/14 [00:08<00:00,  1.67it/s, acc=0.060, loss=5.407]\n",
            "Epoch 321: 100%|██████████| 14/14 [00:08<00:00,  1.67it/s, acc=0.040, loss=5.403]\n",
            "Epoch 322: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.020, loss=5.405]\n",
            "Epoch 323: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.090, loss=5.405]\n",
            "Epoch 324: 100%|██████████| 14/14 [00:08<00:00,  1.67it/s, acc=0.120, loss=5.415]\n",
            "Epoch 325: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.050, loss=5.399]\n",
            "Epoch 326: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.060, loss=5.410]\n",
            "Epoch 327: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.040, loss=5.429]\n",
            "Epoch 328: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.030, loss=5.297]\n",
            "Epoch 329: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.060, loss=5.414]\n",
            "Epoch 330: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.080, loss=5.405]\n",
            "Epoch 331: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.070, loss=5.331]\n",
            "Epoch 332: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.030, loss=5.437]\n",
            "Epoch 333: 100%|██████████| 14/14 [00:08<00:00,  1.65it/s, acc=0.060, loss=5.368]\n",
            "Epoch 334: 100%|██████████| 14/14 [00:08<00:00,  1.66it/s, acc=0.060, loss=5.401]\n",
            "Epoch 335: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.050, loss=5.412]\n",
            "Epoch 336: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.050, loss=5.433]\n",
            "Epoch 337: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.050, loss=5.416]\n",
            "Epoch 338: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.090, loss=5.407]\n",
            "Epoch 339: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.060, loss=5.403]\n",
            "Epoch 340: 100%|██████████| 14/14 [00:08<00:00,  1.65it/s, acc=0.040, loss=5.392]\n",
            "Epoch 341: 100%|██████████| 14/14 [00:08<00:00,  1.65it/s, acc=0.070, loss=5.442]\n",
            "Epoch 342: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.030, loss=5.409]\n",
            "Epoch 343: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.010, loss=5.402]\n",
            "Epoch 344: 100%|██████████| 14/14 [00:08<00:00,  1.65it/s, acc=0.030, loss=5.386]\n",
            "Epoch 345: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.060, loss=5.420]\n",
            "Epoch 346: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.040, loss=5.391]\n",
            "Epoch 347: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.030, loss=5.421]\n",
            "Epoch 348: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.030, loss=5.245]\n",
            "Epoch 349: 100%|██████████| 14/14 [00:08<00:00,  1.62it/s, acc=0.060, loss=5.365]\n",
            "Epoch 350: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.090, loss=5.445]\n",
            "Epoch 351: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.060, loss=5.409]\n",
            "Epoch 352: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.100, loss=5.382]\n",
            "Epoch 353: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.070, loss=5.404]\n",
            "Epoch 354: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.030, loss=5.400]\n",
            "Epoch 355: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.040, loss=5.382]\n",
            "Epoch 356: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.060, loss=5.438]\n",
            "Epoch 357: 100%|██████████| 14/14 [00:08<00:00,  1.60it/s, acc=0.040, loss=5.373]\n",
            "Epoch 358: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.030, loss=5.410]\n",
            "Epoch 359: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.050, loss=5.379]\n",
            "Epoch 360: 100%|██████████| 14/14 [00:08<00:00,  1.63it/s, acc=0.020, loss=5.415]\n",
            "Epoch 361: 100%|██████████| 14/14 [00:08<00:00,  1.62it/s, acc=0.040, loss=5.344]\n",
            "Epoch 362: 100%|██████████| 14/14 [00:08<00:00,  1.62it/s, acc=0.040, loss=5.405]\n",
            "Epoch 363: 100%|██████████| 14/14 [00:08<00:00,  1.62it/s, acc=0.020, loss=5.399]\n",
            "Epoch 364: 100%|██████████| 14/14 [00:08<00:00,  1.62it/s, acc=0.020, loss=5.274]\n",
            "Epoch 365: 100%|██████████| 14/14 [00:08<00:00,  1.61it/s, acc=0.050, loss=5.381]\n",
            "Epoch 366: 100%|██████████| 14/14 [00:08<00:00,  1.61it/s, acc=0.040, loss=5.403]\n",
            "Epoch 367: 100%|██████████| 14/14 [00:08<00:00,  1.62it/s, acc=0.080, loss=5.386]\n",
            "Epoch 368: 100%|██████████| 14/14 [00:08<00:00,  1.64it/s, acc=0.090, loss=5.387]\n",
            "Epoch 369: 100%|██████████| 14/14 [00:08<00:00,  1.62it/s, acc=0.070, loss=5.403]\n",
            "Epoch 370: 100%|██████████| 14/14 [00:08<00:00,  1.59it/s, acc=0.040, loss=5.416]\n",
            "Epoch 371: 100%|██████████| 14/14 [00:08<00:00,  1.61it/s, acc=0.040, loss=5.416]\n",
            "Epoch 372: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.030, loss=5.415]\n",
            "Epoch 373: 100%|██████████| 14/14 [00:09<00:00,  1.54it/s, acc=0.070, loss=5.372]\n",
            "Epoch 374: 100%|██████████| 14/14 [00:09<00:00,  1.55it/s, acc=0.040, loss=5.241]\n",
            "Epoch 375: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.030, loss=5.424]\n",
            "Epoch 376: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.090, loss=5.365]\n",
            "Epoch 377: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.030, loss=5.365]\n",
            "Epoch 378: 100%|██████████| 14/14 [00:09<00:00,  1.54it/s, acc=0.070, loss=5.378]\n",
            "Epoch 379: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.000, loss=5.356]\n",
            "Epoch 380: 100%|██████████| 14/14 [00:09<00:00,  1.54it/s, acc=0.030, loss=5.392]\n",
            "Epoch 381: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.060, loss=5.404]\n",
            "Epoch 382: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.040, loss=5.417]\n",
            "Epoch 383: 100%|██████████| 14/14 [00:09<00:00,  1.54it/s, acc=0.020, loss=5.395]\n",
            "Epoch 384: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.030, loss=5.381]\n",
            "Epoch 385: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.040, loss=5.394]\n",
            "Epoch 386: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.000, loss=5.408]\n",
            "Epoch 387: 100%|██████████| 14/14 [00:09<00:00,  1.54it/s, acc=0.040, loss=5.313]\n",
            "Epoch 388: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.090, loss=5.368]\n",
            "Epoch 389: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.030, loss=5.352]\n",
            "Epoch 390: 100%|██████████| 14/14 [00:09<00:00,  1.43it/s, acc=0.040, loss=5.410]\n",
            "Epoch 391: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.040, loss=5.180]\n",
            "Epoch 392: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.040, loss=5.227]\n",
            "Epoch 393: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.050, loss=5.235]\n",
            "Epoch 394: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.020, loss=5.389]\n",
            "Epoch 395: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.060, loss=5.399]\n",
            "Epoch 396: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.020, loss=5.260]\n",
            "Epoch 397: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.070, loss=5.372]\n",
            "Epoch 398: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.030, loss=5.137]\n",
            "Epoch 399: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.050, loss=5.399]\n",
            "Epoch 400: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.070, loss=5.409]\n",
            "Epoch 401: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.050, loss=5.411]\n",
            "Epoch 402: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.010, loss=5.405]\n",
            "Epoch 403: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.100, loss=5.323]\n",
            "Epoch 404: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.070, loss=5.406]\n",
            "Epoch 405: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.060, loss=5.378]\n",
            "Epoch 406: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.040, loss=5.390]\n",
            "Epoch 407: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.080, loss=5.310]\n",
            "Epoch 408: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.050, loss=5.419]\n",
            "Epoch 409: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.060, loss=5.366]\n",
            "Epoch 410: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.070, loss=5.399]\n",
            "Epoch 411: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.090, loss=5.368]\n",
            "Epoch 412: 100%|██████████| 14/14 [00:09<00:00,  1.52it/s, acc=0.040, loss=5.355]\n",
            "Epoch 413: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.030, loss=5.384]\n",
            "Epoch 414: 100%|██████████| 14/14 [00:09<00:00,  1.53it/s, acc=0.040, loss=5.400]\n",
            "Epoch 415: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.090, loss=5.331]\n",
            "Epoch 416: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.070, loss=5.308]\n",
            "Epoch 417: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.040, loss=5.310]\n",
            "Epoch 418: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.070, loss=5.382]\n",
            "Epoch 419: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.040, loss=5.379]\n",
            "Epoch 420: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.080, loss=5.262]\n",
            "Epoch 421: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.030, loss=5.388]\n",
            "Epoch 422: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, acc=0.070, loss=5.380]\n",
            "Epoch 423: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.110, loss=5.377]\n",
            "Epoch 424: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.020, loss=5.194]\n",
            "Epoch 425: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.070, loss=5.412]\n",
            "Epoch 426: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.020, loss=5.366]\n",
            "Epoch 427: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, acc=0.120, loss=5.353]\n",
            "Epoch 428: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.070, loss=5.382]\n",
            "Epoch 429: 100%|██████████| 14/14 [00:09<00:00,  1.47it/s, acc=0.050, loss=5.351]\n",
            "Epoch 430: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.060, loss=5.319]\n",
            "Epoch 431: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.070, loss=5.270]\n",
            "Epoch 432: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.070, loss=5.351]\n",
            "Epoch 433: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, acc=0.040, loss=5.341]\n",
            "Epoch 434: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, acc=0.080, loss=5.344]\n",
            "Epoch 435: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, acc=0.060, loss=5.350]\n",
            "Epoch 436: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.070, loss=5.348]\n",
            "Epoch 437: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.040, loss=5.342]\n",
            "Epoch 438: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.010, loss=5.353]\n",
            "Epoch 439: 100%|██████████| 14/14 [00:09<00:00,  1.50it/s, acc=0.020, loss=5.416]\n",
            "Epoch 440: 100%|██████████| 14/14 [00:09<00:00,  1.51it/s, acc=0.050, loss=5.344]\n",
            "Epoch 441: 100%|██████████| 14/14 [00:09<00:00,  1.49it/s, acc=0.060, loss=5.337]\n",
            "Epoch 442: 100%|██████████| 14/14 [00:09<00:00,  1.48it/s, acc=0.070, loss=5.382]\n",
            "Epoch 443: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.030, loss=5.182]\n",
            "Epoch 444: 100%|██████████| 14/14 [00:09<00:00,  1.43it/s, acc=0.040, loss=5.365]\n",
            "Epoch 445: 100%|██████████| 14/14 [00:09<00:00,  1.42it/s, acc=0.100, loss=5.273]\n",
            "Epoch 446: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.050, loss=5.366]\n",
            "Epoch 447: 100%|██████████| 14/14 [00:09<00:00,  1.42it/s, acc=0.000, loss=5.372]\n",
            "Epoch 448: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.070, loss=5.338]\n",
            "Epoch 449: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.030, loss=5.300]\n",
            "Epoch 450: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.100, loss=5.318]\n",
            "Epoch 451: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.040, loss=5.386]\n",
            "Epoch 452: 100%|██████████| 14/14 [00:09<00:00,  1.42it/s, acc=0.060, loss=5.309]\n",
            "Epoch 453: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.030, loss=5.376]\n",
            "Epoch 454: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.050, loss=5.323]\n",
            "Epoch 455: 100%|██████████| 14/14 [00:09<00:00,  1.42it/s, acc=0.080, loss=5.396]\n",
            "Epoch 456: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.080, loss=5.355]\n",
            "Epoch 457: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.030, loss=5.271]\n",
            "Epoch 458: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.070, loss=5.375]\n",
            "Epoch 459: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.060, loss=5.355]\n",
            "Epoch 460: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.070, loss=5.385]\n",
            "Epoch 461: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.070, loss=5.309]\n",
            "Epoch 462: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.100, loss=5.357]\n",
            "Epoch 463: 100%|██████████| 14/14 [00:09<00:00,  1.42it/s, acc=0.030, loss=5.301]\n",
            "Epoch 464: 100%|██████████| 14/14 [00:10<00:00,  1.40it/s, acc=0.070, loss=5.374]\n",
            "Epoch 465: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.060, loss=5.339]\n",
            "Epoch 466: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.020, loss=5.301]\n",
            "Epoch 467: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.040, loss=5.343]\n",
            "Epoch 468: 100%|██████████| 14/14 [00:10<00:00,  1.40it/s, acc=0.060, loss=5.408]\n",
            "Epoch 469: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.060, loss=5.341]\n",
            "Epoch 470: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.020, loss=5.219]\n",
            "Epoch 471: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.100, loss=5.386]\n",
            "Epoch 472: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.060, loss=5.211]\n",
            "Epoch 473: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.010, loss=5.394]\n",
            "Epoch 474: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.050, loss=5.229]\n",
            "Epoch 475: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.060, loss=5.336]\n",
            "Epoch 476: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.020, loss=5.364]\n",
            "Epoch 477: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.050, loss=5.343]\n",
            "Epoch 478: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.070, loss=5.317]\n",
            "Epoch 479: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.090, loss=5.336]\n",
            "Epoch 480: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.060, loss=5.335]\n",
            "Epoch 481: 100%|██████████| 14/14 [00:09<00:00,  1.41it/s, acc=0.080, loss=5.365]\n",
            "Epoch 482: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.100, loss=5.349]\n",
            "Epoch 483: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.040, loss=5.120]\n",
            "Epoch 484: 100%|██████████| 14/14 [00:10<00:00,  1.40it/s, acc=0.070, loss=5.387]\n",
            "Epoch 485: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.030, loss=5.207]\n",
            "Epoch 486: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.000, loss=5.353]\n",
            "Epoch 487: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.050, loss=5.076]\n",
            "Epoch 488: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.040, loss=5.331]\n",
            "Epoch 489: 100%|██████████| 14/14 [00:09<00:00,  1.40it/s, acc=0.070, loss=5.355]\n",
            "Epoch 490: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.070, loss=5.335]\n",
            "Epoch 491: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.050, loss=5.354]\n",
            "Epoch 492: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.040, loss=5.371]\n",
            "Epoch 493: 100%|██████████| 14/14 [00:10<00:00,  1.39it/s, acc=0.040, loss=5.309]\n",
            "Epoch 494: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.060, loss=5.387]\n",
            "Epoch 495: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.090, loss=5.288]\n",
            "Epoch 496: 100%|██████████| 14/14 [00:10<00:00,  1.36it/s, acc=0.050, loss=5.327]\n",
            "Epoch 497: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.070, loss=5.331]\n",
            "Epoch 498: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.070, loss=5.315]\n",
            "Epoch 499: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.020, loss=5.374]\n",
            "Epoch 500: 100%|██████████| 14/14 [00:10<00:00,  1.35it/s, acc=0.030, loss=5.318]\n",
            "Epoch 501: 100%|██████████| 14/14 [00:10<00:00,  1.36it/s, acc=0.050, loss=5.315]\n",
            "Epoch 502: 100%|██████████| 14/14 [00:10<00:00,  1.38it/s, acc=0.020, loss=5.230]\n",
            "Epoch 503: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.080, loss=5.373]\n",
            "Epoch 504: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.060, loss=5.357]\n",
            "Epoch 505: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s, acc=0.020, loss=5.294]\n",
            "Epoch 506: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.040, loss=5.353]\n",
            "Epoch 507: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.070, loss=5.290]\n",
            "Epoch 508: 100%|██████████| 14/14 [00:10<00:00,  1.36it/s, acc=0.090, loss=5.291]\n",
            "Epoch 509: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.030, loss=5.319]\n",
            "Epoch 510: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.080, loss=5.259]\n",
            "Epoch 511: 100%|██████████| 14/14 [00:10<00:00,  1.37it/s, acc=0.070, loss=5.318]\n",
            "Epoch 512: 100%|██████████| 14/14 [00:10<00:00,  1.36it/s, acc=0.030, loss=5.337]\n",
            "Epoch 513: 100%|██████████| 14/14 [00:10<00:00,  1.35it/s, acc=0.070, loss=5.322]\n",
            "Epoch 514: 100%|██████████| 14/14 [00:10<00:00,  1.32it/s, acc=0.040, loss=5.333]\n",
            "Epoch 515: 100%|██████████| 14/14 [00:10<00:00,  1.30it/s, acc=0.060, loss=5.395]\n",
            "Epoch 516: 100%|██████████| 14/14 [00:10<00:00,  1.31it/s, acc=0.080, loss=5.303]\n",
            "Epoch 517: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s, acc=0.060, loss=5.340]\n",
            "Epoch 518: 100%|██████████| 14/14 [00:10<00:00,  1.29it/s, acc=0.050, loss=5.338]\n",
            "Epoch 519: 100%|██████████| 14/14 [00:10<00:00,  1.30it/s, acc=0.070, loss=5.340]\n",
            "Epoch 520: 100%|██████████| 14/14 [00:10<00:00,  1.32it/s, acc=0.060, loss=5.312]\n",
            "Epoch 521:  21%|██▏       | 3/14 [00:02<00:07,  1.53it/s, acc=0.070, loss=5.360]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wvit9sxLUQuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#beam search"
      ],
      "metadata": {
        "id": "AO9oryTTODCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "def beam_search_decoder(predictions, k):\n",
        "    # create the list of [seq, score]\n",
        "    # score is log_prob\n",
        "    sequences = [[list(), 1.0]]\n",
        "    # walk over each step in sequence\n",
        "    for row in predictions:\n",
        "        all_candidates = list()\n",
        "        # expand each current candidate\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                # add the embedding into the list and calculate the log_prob\n",
        "                # 这里可以加if语句去判断是否遇到了end 直接跳过。（如果这样可以迫使模型生成1句话或者2句话，或者你前面如果\n",
        "                # 加了对于pad的惩罚 这里就不用在多搞了，如果没有可以判断，如果一个pad后面加的还是pad那么说明句子到头了\n",
        "                candidate = [seq + [j], score * -log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        # order all candidates by score\n",
        "        ordered = sorted(all_candidates, key=lambda tup :tup[1])\n",
        "        # select k best\n",
        "        sequences = ordered[:k]\n",
        "    return sequences"
      ],
      "metadata": {
        "id": "2rKekQpROEjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TopK"
      ],
      "metadata": {
        "id": "0eGeCOK8EKfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_encode, weight = graph_encoder(data, mask)\n",
        "dec_input = torch.tensor([101], device=device)\n",
        "dec_hidden = x_encode[-1]\n",
        "decode = []\n",
        "idx_list = []\n",
        "for _ in range(200):\n",
        "    predictions, dec_hidden = GRU_decoder(dec_input, dec_hidden, x_encode, weight)\n",
        "    a, idx = predictions.topk(2)\n",
        "    idx_list.append(idx.cpu().numpy()[0,1])\n",
        "    dec_input = idx[0, 1]\n",
        "decode = tokenizer.decode(np.array(idx_list))\n"
      ],
      "metadata": {
        "id": "d982nISooC7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GbLhfHFz15VJ",
        "outputId": "29cb893d-a96d-44f2-9289-8c985fa0462c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"- said i was also a packers put fan - was root qb to the vikings their brett. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for num in sample:\n",
        "    res = tokenizer.decode(num)\n",
        "    print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-5ZQykO2UAc",
        "outputId": "54a059ac-d953-491f-f068-ada55b6987b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] i was shocked that the vikings held on. i was even more shocked that new england was not only a wild card contender but ac tua lly lost in the end. i guess the only that that could surprise me more would be if my beloved packers ac tua lly beat seattle and if minn esota made it to the super bowl. what a wild and crazy nfl season thus far. while the 49ers and seahawks are tough and consistent, i stopped assuming any one team will be in the super bowl this year. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ marge keller i thought seattle looked awful. it was a close game even with the eagle's 40 year old qb. i am surprised they play so well against sf. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ jsailor really? i thought their defense was pretty sharp. i was almost embarrassed by how the eagles played. funny how folks can have such differing recollections when viewing the same game. t hanks much for your comment. much appreciated. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ doon i really like your assessment! the biggest thrill for me will be if / when the vikings ac tua lly become the bride rather than bridesmaids. but they have to get to the super bowl first. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
            "[CLS] @ doon - well said. i'm a packers fan and i was rooting for the vikings in this game. as i recall sean payton was also suspended for a year for allowing his players to put a \" bounty \" on the viking players when brett was their qb. i have no sympathy for sean payton. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM example"
      ],
      "metadata": {
        "id": "8j6XLsKOxudP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample LSTM text generator\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self, text_df\n",
        "    ):\n",
        "        self.text_df = text_df\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.sequence_length = 4\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    # here I load all the words in all nodes for one graph, it should be fixed...\n",
        "    def load_words(self):\n",
        "        text_arr = np.array(self.text_df)\n",
        "        text = \"\"\n",
        "        for i in range(len(text_arr)):\n",
        "            text += text_arr[i][0] + \" \"\n",
        "        return text.split(' ')\n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# LSTM\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
        "        \n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(dataset, model):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=256\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        state_h, state_c = model.init_state(4)\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "\n",
        "def predict(dataset, model, text, next_words=100):\n",
        "    words = text.split(' ')\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "dataset = Dataset(df)\n",
        "model = Model(dataset)\n",
        "\n",
        "train(dataset, model)"
      ],
      "metadata": {
        "id": "k23VjARD7GHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transformer encoder example"
      ],
      "metadata": {
        "id": "QLu5qU6_xyG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = transformer_encoder(src)"
      ],
      "metadata": {
        "id": "nqkdnu3aHgoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8OVWHGDiiPD",
        "outputId": "3bcba31f-921b-4543-abf0-7617733c9dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 32, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "text = \"The capital of France contains the Eiffel Tower.\"\n",
        "input = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
        "output = model(**input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dysWTlnqa1eB",
        "outputId": "61c4f7ff-9856-4bf1-c5a6-3bb99c46f854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59HGZyYYfDSm",
        "outputId": "3d640297-f016-4005-a1f0-42c99e502a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"The capital of France contains the Eiffel Tower.\"]\n",
        "input = tokenizer.encode_plus(text, return_tensors = \"pt\")"
      ],
      "metadata": {
        "id": "-xD9fnCidlaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode_plus(text, add_special_tokens = True,  truncation = True, padding = \"max_length\", return_attention_mask = True, return_tensors = \"pt\")"
      ],
      "metadata": {
        "id": "wmYENNtydo4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
