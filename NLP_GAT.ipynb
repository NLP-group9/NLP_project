{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-GAT",
      "provenance": [],
      "collapsed_sections": [
        "XQh-352-Vy4w",
        "r4sjXW5pyxFU",
        "AO9oryTTODCQ",
        "0eGeCOK8EKfX",
        "8j6XLsKOxudP"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load file"
      ],
      "metadata": {
        "id": "XQh-352-Vy4w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "h4B7dYGPORcr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e224bb3b-d834-413a-d97f-06be8944aabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import os # accessing directory structure\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "dir = '/content/gdrive/MyDrive/archive'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "article"
      ],
      "metadata": {
        "id": "NGYRTZhCrxL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-articles-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df1 = pd.read_csv('/content/gdrive/MyDrive/archive/nyt-articles-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df1.dataframeName = 'nyt-articles-2020.csv'\n",
        "nRow, nCol = df1.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "metadata": {
        "id": "I1G8ci8frTne",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf949381-c471-41ea-e21d-3641e2d3f32b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 16787 rows and 11 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "comment"
      ],
      "metadata": {
        "id": "4Ul50KM2rzeM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nRowsRead = None # specify 'None' if want to read whole file\n",
        "# nyt-comments-2020.csv may have more rows in reality, but we are only loading/previewing the first 1000 rows\n",
        "df2 = pd.read_csv( dir+'/nyt-comments-2020.csv', delimiter=',', nrows = nRowsRead)\n",
        "df2.dataframeName = 'nyt-comments-2020.csv'\n",
        "nRow, nCol = df2.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')\n",
        "article = np.array(df1)\n",
        "comments = np.array(df2)"
      ],
      "metadata": {
        "id": "lARaxsdtrmiG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "415f1b13-7808-4b7a-b61f-eb764676a0b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4986461 rows and 23 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data cleaning"
      ],
      "metadata": {
        "id": "r4sjXW5pyxFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Article cleaning \\\\\n",
        "列数从0开始 \\\\\n",
        "第1列 第2列不出现 politics \\\\\n",
        "第6列不出现 [] \\\\\n",
        "第7列筛选文章词数大于50 \\\\\n",
        "第9列筛选comments个数大于50 \\\\\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "akvF2EghyytA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#只保留sports和movies\n",
        "# df1_1 = df1.drop(df1[df1['section'] != 'Sports'].index)\n",
        "# df1_2 = df1.drop(df1[df1['section'] != 'Movies'].index)\n",
        "# cleaned_arti = pd.concat([df1_1, df1_2])\n",
        "cleaned_arti = df1\n",
        "#第六列不出现空\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['keywords'] == '[]'].index)\n",
        "#第七列筛选次数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['word_count'] < 50].index)\n",
        "#第九列comments个数大于50\n",
        "cleaned_arti = cleaned_arti.drop(cleaned_arti[cleaned_arti['n_comments'] < 50].index)\n",
        "#取出对应的article id\n",
        "#article只保留四列\n",
        "cleaned_arti = cleaned_arti[['headline','abstract','keywords', 'uniqueID']]"
      ],
      "metadata": {
        "id": "KY9i-F7t1F51"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_arti.dropna(axis=0,how='any')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "sGb_wf15eK--",
        "outputId": "131c9945-1a53-4f50-e610-ea099460743f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                headline  \\\n",
              "0                            Protect Veterans From Fraud   \n",
              "1                                 ‘It’s Green and Slimy’   \n",
              "5      Pro-Iranian Protesters End Siege of U.S. Embas...   \n",
              "7      She Felt Fine, but Her M.R.I. Showed Several S...   \n",
              "10     Eat Better, Feel Better? Food Advice From the ...   \n",
              "...                                                  ...   \n",
              "16781  Here’s Why Distribution of the Vaccine Is Taki...   \n",
              "16782                What It Takes to Heal From Covid-19   \n",
              "16784  Their Finances Ravaged, Customers Fear Banks W...   \n",
              "16785      Should Wine Be Among Your Health Resolutions?   \n",
              "16786  Microsoft Says Russian Hackers Viewed Some of ...   \n",
              "\n",
              "                                                abstract  \\\n",
              "0      Congress could do much more to protect America...   \n",
              "1      Christina Iverson and Jeff Chen ring in the Ne...   \n",
              "5      Iran’s ability to deploy militias to attack th...   \n",
              "7      After the 67-year-old woman fell at the airpor...   \n",
              "10     Intermittent fasting, drinking less alcohol an...   \n",
              "...                                                  ...   \n",
              "16781  Health officials and hospitals are struggling ...   \n",
              "16782      Survivors can get better, but they need help.   \n",
              "16784  Banks have the power to decide whether to let ...   \n",
              "16785  The new category of ‘clean wines’ is an effort...   \n",
              "16786  The hackers gained more access than the compan...   \n",
              "\n",
              "                                                keywords  \\\n",
              "0      ['Veterans', 'For-Profit Schools', 'Financial ...   \n",
              "1                                  ['Crossword Puzzles']   \n",
              "5      ['Iraq', 'Iran', 'United States', 'Demonstrati...   \n",
              "7      ['Stroke', 'Brain', 'Heart', 'Medicine and Hea...   \n",
              "10           ['Weight', 'Fasting', 'Diet and Nutrition']   \n",
              "...                                                  ...   \n",
              "16781  ['Vaccination and Immunization', 'Coronavirus ...   \n",
              "16782  ['Chronic Condition (Health)', 'Coronavirus (2...   \n",
              "16784  ['Banking and Financial Institutions', 'Corona...   \n",
              "16785  ['Wines', 'Grapes', 'Diet and Nutrition', 'Dia...   \n",
              "16786  ['Microsoft Corp', 'US Federal Government Data...   \n",
              "\n",
              "                                                uniqueID  \n",
              "0      nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...  \n",
              "1      nyt://article/9edddb54-0aa3-5835-a833-d311a76f...  \n",
              "5      nyt://article/ac742403-9ccd-522f-9a1e-a90feb6c...  \n",
              "7      nyt://article/dfd5bb59-f330-5c01-ae02-221e6f9c...  \n",
              "10     nyt://article/da74e3b3-f027-5b03-9052-0bc2e69a...  \n",
              "...                                                  ...  \n",
              "16781  nyt://article/5320a2e9-d739-542a-a397-443c4323...  \n",
              "16782  nyt://article/e8adbb75-a8b3-5a8c-886b-b9c1195f...  \n",
              "16784  nyt://article/c4b9edab-bdde-5d81-b496-06fedb52...  \n",
              "16785  nyt://article/efcaf652-ffad-5b4e-9f17-4fd9aff5...  \n",
              "16786  nyt://article/12048b2b-62e3-5bed-8c77-483a4299...  \n",
              "\n",
              "[9403 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b2420e5-d28b-40a0-a4af-034d2be87803\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>abstract</th>\n",
              "      <th>keywords</th>\n",
              "      <th>uniqueID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Protect Veterans From Fraud</td>\n",
              "      <td>Congress could do much more to protect America...</td>\n",
              "      <td>['Veterans', 'For-Profit Schools', 'Financial ...</td>\n",
              "      <td>nyt://article/69a7090b-9f36-569e-b5ab-b0ba5bb3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‘It’s Green and Slimy’</td>\n",
              "      <td>Christina Iverson and Jeff Chen ring in the Ne...</td>\n",
              "      <td>['Crossword Puzzles']</td>\n",
              "      <td>nyt://article/9edddb54-0aa3-5835-a833-d311a76f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pro-Iranian Protesters End Siege of U.S. Embas...</td>\n",
              "      <td>Iran’s ability to deploy militias to attack th...</td>\n",
              "      <td>['Iraq', 'Iran', 'United States', 'Demonstrati...</td>\n",
              "      <td>nyt://article/ac742403-9ccd-522f-9a1e-a90feb6c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>She Felt Fine, but Her M.R.I. Showed Several S...</td>\n",
              "      <td>After the 67-year-old woman fell at the airpor...</td>\n",
              "      <td>['Stroke', 'Brain', 'Heart', 'Medicine and Hea...</td>\n",
              "      <td>nyt://article/dfd5bb59-f330-5c01-ae02-221e6f9c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Eat Better, Feel Better? Food Advice From the ...</td>\n",
              "      <td>Intermittent fasting, drinking less alcohol an...</td>\n",
              "      <td>['Weight', 'Fasting', 'Diet and Nutrition']</td>\n",
              "      <td>nyt://article/da74e3b3-f027-5b03-9052-0bc2e69a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16781</th>\n",
              "      <td>Here’s Why Distribution of the Vaccine Is Taki...</td>\n",
              "      <td>Health officials and hospitals are struggling ...</td>\n",
              "      <td>['Vaccination and Immunization', 'Coronavirus ...</td>\n",
              "      <td>nyt://article/5320a2e9-d739-542a-a397-443c4323...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16782</th>\n",
              "      <td>What It Takes to Heal From Covid-19</td>\n",
              "      <td>Survivors can get better, but they need help.</td>\n",
              "      <td>['Chronic Condition (Health)', 'Coronavirus (2...</td>\n",
              "      <td>nyt://article/e8adbb75-a8b3-5a8c-886b-b9c1195f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16784</th>\n",
              "      <td>Their Finances Ravaged, Customers Fear Banks W...</td>\n",
              "      <td>Banks have the power to decide whether to let ...</td>\n",
              "      <td>['Banking and Financial Institutions', 'Corona...</td>\n",
              "      <td>nyt://article/c4b9edab-bdde-5d81-b496-06fedb52...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16785</th>\n",
              "      <td>Should Wine Be Among Your Health Resolutions?</td>\n",
              "      <td>The new category of ‘clean wines’ is an effort...</td>\n",
              "      <td>['Wines', 'Grapes', 'Diet and Nutrition', 'Dia...</td>\n",
              "      <td>nyt://article/efcaf652-ffad-5b4e-9f17-4fd9aff5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16786</th>\n",
              "      <td>Microsoft Says Russian Hackers Viewed Some of ...</td>\n",
              "      <td>The hackers gained more access than the compan...</td>\n",
              "      <td>['Microsoft Corp', 'US Federal Government Data...</td>\n",
              "      <td>nyt://article/12048b2b-62e3-5bed-8c77-483a4299...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9403 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b2420e5-d28b-40a0-a4af-034d2be87803')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b2420e5-d28b-40a0-a4af-034d2be87803 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b2420e5-d28b-40a0-a4af-034d2be87803');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kw_set = np.array(cleaned_arti['keywords'])"
      ],
      "metadata": {
        "id": "ttCY1njXczIQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keep_idx = []\n",
        "for i, kw in enumerate(kw_set):\n",
        "    if str(kw)=='nan' or ',' not in kw or len(kw.split(',')) < 10:\n",
        "        pass\n",
        "    else:\n",
        "        keep_idx.append(i)"
      ],
      "metadata": {
        "id": "fXUUVAOgc1T-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_arti = cleaned_arti.iloc[keep_idx, :]"
      ],
      "metadata": {
        "id": "GJ2Qby02dmmk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_arti)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpDWr5a8iyzr",
        "outputId": "bcca9a43-44d3-4937-9ef5-eba3f80331d1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4084"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comments cleaning \\\\\n",
        "根据cleaned article筛选comments \\\\\n"
      ],
      "metadata": {
        "id": "lG4K6bjD0BE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uni_id = cleaned_arti['uniqueID'].to_numpy()\n",
        "cleaned_comm = df2[df2['articleID'].isin(uni_id)]\n",
        "cleaned_comm = cleaned_comm[['commentBody','articleID']]"
      ],
      "metadata": {
        "id": "CJfNgUgi65t3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "comment_len_list = []\n",
        "a = np.array(cleaned_comm['commentBody'])\n",
        "for comm in tqdm(a):\n",
        "    comment_len_list.append(len(comm.split(' ')))\n",
        "comment_len_list = np.array(comment_len_list)"
      ],
      "metadata": {
        "id": "0zRoMUuLJzpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a23dd37-0185-4162-f0ab-e88bc5818802"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2375148/2375148 [00:10<00:00, 233712.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.sort(comment_len_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "8AFRZcQHZtpG",
        "outputId": "cf999ff0-548e-4882-fb0e-6b92ee4c7379"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fccabdbbb50>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(comment_len_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c2AJnK1aCJA",
        "outputId": "3de1e836-5e5c-4864-9ee9-36a5c30c1292"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.62632518057822"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reconstruct keywords"
      ],
      "metadata": {
        "id": "QPzAYx7UI3rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords \n",
        "\n",
        "\n",
        "# new version\n",
        "def extract_kw(cleaned_arti):\n",
        "    # stop words in English\n",
        "    stop = set(stopwords.words('english')) \n",
        "    #extract keywords from cleaned article\n",
        "    kw_set = np.array(cleaned_arti['keywords'])\n",
        "    new_kw_set = []\n",
        "    for i, kw in enumerate(kw_set):\n",
        "        kw = kw.split(',') if ',' in kw else kw\n",
        "        for j in range(len(kw)):\n",
        "            kw[j] = re.sub(u\"([^\\u0041-\\u005a\\u0061-\\u007a\\u0020])\", \"\", kw[j])\n",
        "            kw[j] = kw[j].strip()\n",
        "        kw = np.array([i for i in kw if i != \"\" and i not in stop])\n",
        "        kw_set[i] = np.unique(kw)\n",
        "        new_kw_set.append(np.unique(kw))\n",
        "    new_kw_set = np.concatenate(new_kw_set[:])\n",
        "    return new_kw_set, kw_set\n"
      ],
      "metadata": {
        "id": "awoyXGsss6Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc4966b-8867-4134-b2bb-e1af65c956af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kw_list, kw = extract_kw(cleaned_arti)"
      ],
      "metadata": {
        "id": "wPBG9dv1TIA4"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train new tokenizer"
      ],
      "metadata": {
        "id": "LbDHUVd_S59T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import BertTokenizerFast\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "# all_tokens = list(np.concatenate((np.array(cleaned_arti['headline']), kw_list, np.array(cleaned_comm['commentBody']), np.array(cleaned_arti['abstract']))))\n",
        "\n",
        "# batch_size = 1000\n",
        "# all_texts = [all_tokens[i : i + batch_size] for i in range(0, len(all_tokens), batch_size)]\n",
        "\n",
        "# def batch_iterator(dataset):\n",
        "#     for i in range(0, len(dataset), batch_size):\n",
        "#         yield dataset[i : i + batch_size]\n",
        "\n",
        "# tokenizer = tokenizer.train_new_from_iterator(all_texts, vocab_size=60000)\n",
        "# save_directory_tokenizer = '/content/gdrive/MyDrive/withoutBERT_tokenizer'\n",
        "# tokenizer.save_pretrained(save_directory_tokenizer)"
      ],
      "metadata": {
        "id": "j4lgrRSagGis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import decoders, models, normalizers, pre_tokenizers, processors, trainers, Tokenizer\n",
        "all_tokens = list(np.concatenate((np.array(cleaned_arti['headline']), kw_list, np.array(cleaned_comm['commentBody']), np.array(cleaned_arti['abstract']))))\n",
        "batch_size = 1000\n",
        "all_texts = [all_tokens[i : i + batch_size] for i in range(0, len(all_tokens), batch_size)]\n",
        "\n",
        "tokenizer = Tokenizer(models.WordPiece(unl_token=\"[UNK]\"))\n",
        "tokenizer.normalizer = normalizers.BertNormalizer(lowercase=True)\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.BertPreTokenizer()\n",
        "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "trainer = trainers.WordPieceTrainer(vocab_size=60000, special_tokens=special_tokens)\n",
        "tokenizer.train_from_iterator(all_texts, trainer=trainer)"
      ],
      "metadata": {
        "id": "_TLuKiOSDzD_"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls_token_id = tokenizer.token_to_id(\"[CLS]\")\n",
        "sep_token_id = tokenizer.token_to_id(\"[SEP]\")\n",
        "\n",
        "tokenizer.post_processor = processors.TemplateProcessing(\n",
        "    single=f\"[CLS]:0 $A:0 [SEP]:0\",\n",
        "    pair=f\"[CLS]:0 $A:0 [SEP]:0 $B:1 [SEP]:1\",\n",
        "    special_tokens=[\n",
        "        (\"[CLS]\", cls_token_id),\n",
        "        (\"[SEP]\", sep_token_id),\n",
        "    ],\n",
        ")\n",
        "tokenizer.decoder = decoders.WordPiece(prefix=\"##\")\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast(tokenizer_object=tokenizer)\n",
        "save_directory_tokenizer = '/content/gdrive/MyDrive/withoutBERT_tokenizer'\n",
        "tokenizer.save_pretrained(save_directory_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJm8Iyj6EjcQ",
        "outputId": "c3d1eeb5-11e3-4a43-f37e-bed05c6925fe"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gdrive/MyDrive/withoutBERT_tokenizer/tokenizer_config.json',\n",
              " '/content/gdrive/MyDrive/withoutBERT_tokenizer/special_tokens_map.json',\n",
              " '/content/gdrive/MyDrive/withoutBERT_tokenizer/vocab.txt',\n",
              " '/content/gdrive/MyDrive/withoutBERT_tokenizer/added_tokens.json',\n",
              " '/content/gdrive/MyDrive/withoutBERT_tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Node extraction"
      ],
      "metadata": {
        "id": "Hh91t0fMahwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 略加修改\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "class DataSeq(Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.sequences[index]\n",
        "        return sequence\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "import string \n",
        "\n",
        "def not_break(sen):\n",
        "    return (sen != '\\n' and sen != '\\u3000' and  sen != '' and not sen.isspace())\n",
        "def filter_data(ini_data):\n",
        "    new_data = list(filter(not_break, [data.strip() for data in ini_data]))\n",
        "    return new_data\n",
        "\n",
        "import gc\n",
        "for i in range(len(kw)):\n",
        "    kw[i] = kw[i].astype('<U5000')\n",
        "\n",
        "headline = np.array(cleaned_arti['headline'])\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "def recon_kw(kw, headline, cleaned_arti, cleaned_comm):\n",
        "    data_list = []\n",
        "    sample_num = 10\n",
        "    sample_comment_set = []\n",
        "    sample_comment_set_atten_mask = []\n",
        "    edge_connection_box, edge_feat_box = [], []\n",
        "\n",
        "    #divider\n",
        "    english_punctuation = string.punctuation\n",
        "    eng_punc = '|'.join([c for c in english_punctuation])\n",
        "    eng_punc  = eng_punc[:-5] + eng_punc[-3:]\n",
        "\n",
        "    uni_id = np.array(cleaned_arti['uniqueID'])\n",
        "\n",
        "    #construct abstract set\n",
        "    abstract_set = np.array(cleaned_arti['abstract'])\n",
        "\n",
        "    #iterate through each article\n",
        "    for i, id in enumerate(tqdm(uni_id)):\n",
        "        #find corresponding comments set\n",
        "        idx = np.where(np.array(cleaned_comm['articleID']) == id)\n",
        "        comment_set = np.array(cleaned_comm['commentBody'])[idx]\n",
        "\n",
        "        #constract abstract in sentence for one id\n",
        "        abstract = abstract_set[i]\n",
        "        abstract_kw = filter_data(re.split(r''+(\"[\"+eng_punc+\"]\"), abstract))\n",
        "        abstract_kw = [abstract.strip('\\n') for abstract in abstract_kw]\n",
        "        \n",
        "        #iterate through each comment, construct comment set\n",
        "        comm_list = []\n",
        "        comm_kw = []\n",
        "        for comm in comment_set:\n",
        "            comm_k = re.sub(u\"([^\\u0061-\\u007a\\u0030-\\u0039\\u0020\\u0041-\\u005a])\", \"\", comm.strip('\\n'))\n",
        "            comm1 = comm_k.split(' ')\n",
        "            comm_list.extend(comm1)\n",
        "            comm_k = comm.strip('\\n')\n",
        "            comm_kw.append(comm_k)\n",
        "        \n",
        "        #construct dict\n",
        "        comm_dict = {}\n",
        "        for comm in comm_list:\n",
        "            if comm in comm_dict:\n",
        "                comm_dict[comm] += 1\n",
        "            else:\n",
        "                comm_dict[comm] = 1\n",
        "        \n",
        "        # take out the top10\n",
        "        top = 10\n",
        "        freq_threshold = 10\n",
        "        stop_words = 50\n",
        "\n",
        "        # rank comm_dict\n",
        "        comm_dict = np.array(sorted(comm_dict.items(), key=lambda item:item[1], reverse=True))[stop_words:]\n",
        "        comm_kw_list = np.array(comm_dict[:, 0])\n",
        "        freq_list = np.array(np.array(comm_dict[:, 1], dtype=np.int64))\n",
        "\n",
        "        # append keywords\n",
        "        #************************************************************************************\n",
        "        # delete stop words\n",
        "        idx = np.where(freq_list >= freq_threshold)[0]\n",
        "        kw[i] = np.concatenate((kw[i], comm_kw_list[idx])) if len(idx) <= top else np.concatenate((kw[i], comm_kw_list[:top]))\n",
        "        kw[i] = np.unique(kw[i])\n",
        "\n",
        "        # append headline at the end of each graph\n",
        "        headline[i] = headline[i].strip('\\n')\n",
        "        headline[i] =  np.delete(headline[i], np.where(headline[i] == ''))\n",
        "        kw[i] = np.concatenate((kw[i], headline[i]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # copy kw, without the first empty node\n",
        "        kw_copy = kw[i].copy()\n",
        "\n",
        "\n",
        "        #sample several comments as target\n",
        "        random_idx = np.arange(len(comm_kw))\n",
        "        np.random.shuffle(random_idx)\n",
        "        sample_idx = random_idx[:sample_num]\n",
        "        sample_max_length = 50\n",
        "        sample_comment = np.zeros((sample_num, sample_max_length))\n",
        "        sample_comment_mask = np.zeros((sample_num, sample_max_length))\n",
        "        for idx in range(len(sample_idx)):\n",
        "            selected_comm = comm_kw[idx]\n",
        "            sample_encoding = tokenizer.encode_plus(selected_comm, padding='max_length', add_special_tokens=True, max_length=sample_max_length, truncation=True, return_attention_mask=True)\n",
        "            sample_comment[idx] = sample_encoding['input_ids']\n",
        "            sample_comment_mask[idx] = sample_encoding['attention_mask']\n",
        "            del comm_kw[idx]\n",
        "            gc.collect()\n",
        "        sample_comment_set.append(sample_comment)\n",
        "        sample_comment_set_atten_mask.append(sample_comment_mask)\n",
        "\n",
        "        # add comment and abstract to node\n",
        "        comm_kw.extend(abstract_kw)\n",
        "        docs = comm_kw\n",
        "\n",
        "        counter = np.zeros(len(docs))\n",
        "        counter_edge = np.zeros((len(kw_copy[:-1]), len(docs)))\n",
        "        \n",
        "        # add corresponding sentences to keywords\n",
        "        #************************************************************************************\n",
        "        for j, single_kw in enumerate(kw_copy[:-1]):\n",
        "            # convert to word\n",
        "            single_kw_set = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", single_kw.strip('\\n').lower()).split(' ')\n",
        "            for k, doc in enumerate(docs):  \n",
        "                doc_copy = re.sub(u\"([^\\u0061-\\u007a\\u0020])\", \"\", doc.strip('\\n').lower())\n",
        "                exist = 0\n",
        "                for s_kw in single_kw_set:\n",
        "                    if s_kw in doc_copy.split(' ') and exist == 0:\n",
        "                        exist = 1\n",
        "                        kw[i][j] += ' '\n",
        "                        kw[i][j] = np.char.add(kw[i][j], doc)\n",
        "                        counter[k] += 1\n",
        "                        counter_edge[j, k] += 1\n",
        "                    else:\n",
        "                        pass\n",
        "        #************************************************************************************\n",
        "\n",
        "\n",
        "\n",
        "        # construct empty node \n",
        "        empty_node = np.array([''], dtype='<U10000')\n",
        "        kw[i] = np.concatenate((empty_node, kw[i]))\n",
        "        \n",
        "        # add doc to empty node\n",
        "        if len(np.where(counter == 0)[0]) != 0:\n",
        "            empty_doc = np.array(docs)[np.where(counter == 0)[0]]\n",
        "            kw[i][0] = np.char.add(kw[i][0], ' '.join(empty_doc))\n",
        "\n",
        "        #encode and generate graph.x data file\n",
        "        path = '/content/gdrive/MyDrive/withoutBERT_graph'\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "\n",
        "        path_mask = '/content/gdrive/MyDrive/withoutBERT_mask'\n",
        "        if not os.path.exists(path_mask):\n",
        "            os.makedirs(path_mask)\n",
        "\n",
        "        # for ith, row in enumerate(kw[i]):\n",
        "        #     input = tokenizer.encode_plus(row, padding='max_length',add_special_tokens=True, max_length=200, truncation=True, return_attention_mask=True, return_tensors = \"pt\").to(device)\n",
        "        #     torch.save(model(**input)[0][0][1], path + \"/node{0:}.pt\".format(ith))\n",
        "\n",
        "        text_list = [row for row in kw[i]]\n",
        "        dataset_i = DataSeq(text_list)\n",
        "        data_loader = DataLoader(dataset_i, batch_size=32, shuffle=False, num_workers=0)\n",
        "        embedding_repre = []\n",
        "        embedding_mask = []\n",
        "        with torch.no_grad():\n",
        "            for sequence in data_loader:           \n",
        "                input = tokenizer.batch_encode_plus(sequence, padding='max_length', add_special_tokens=True, max_length=100, return_attention_mask=True, truncation=True, return_tensors = \"pt\").to(device)         \n",
        "                embedding_repre.append(input['input_ids'].cpu().numpy())\n",
        "                embedding_mask.append(input['attention_mask'].cpu().numpy())\n",
        "        embedding_repre = np.concatenate(embedding_repre[:])\n",
        "        embedding_mask = np.concatenate(embedding_mask[:])\n",
        "        torch.save(torch.tensor(embedding_repre), path+\"/graph{0:}.pt\".format(i))\n",
        "        torch.save(torch.tensor(embedding_mask), path_mask+\"/graph{0:}.pt\".format(i))\n",
        "\n",
        "            \n",
        "\n",
        "        # calculate edge\n",
        "        store_edge = []\n",
        "        value_edge = []\n",
        "\n",
        "        for j in range(len(counter_edge)-1):\n",
        "            interaction = np.sum(counter_edge[j] * counter_edge[j+1:], axis=1)\n",
        "            if len(np.where(interaction != 0)[0]) != 0:\n",
        "                if len(value_edge) != 0:\n",
        "                    value_edge.append(np.hstack((value_edge[-1], interaction[np.nonzero(interaction)])))\n",
        "                else:\n",
        "                    value_edge.append(interaction[np.nonzero(interaction)])\n",
        "                \n",
        "                edge = np.vstack((np.array([j for _ in range(len(np.where(interaction != 0)[0]))]), np.where(interaction != 0)[0]+j+1))\n",
        "                \n",
        "                if len(store_edge) != 0:\n",
        "                    store_edge.append(np.hstack((store_edge[-1], edge))) \n",
        "                else:\n",
        "                    store_edge.append(edge)\n",
        "\n",
        "        # edge connection\n",
        "        if len(store_edge) == 0:\n",
        "            pass\n",
        "        else:\n",
        "            edge_for_id = store_edge[-1]\n",
        "        \n",
        "            # copy edge connection\n",
        "            edge_for_id2 = np.zeros_like(edge_for_id)\n",
        "            edge_for_id2[0], edge_for_id2[1] = edge_for_id[1], edge_for_id[0]\n",
        "            edge_connection_box.append(np.hstack((edge_for_id, edge_for_id2)))\n",
        "\n",
        "            # edge feature\n",
        "            edge_feat_for_id = value_edge[-1]\n",
        "\n",
        "            # copy edge feature\n",
        "            edge_feat_box.append(np.hstack((edge_feat_for_id, edge_feat_for_id)))\n",
        "    return sample_comment_set, sample_comment_set_atten_mask, edge_connection_box, edge_feat_box\n"
      ],
      "metadata": {
        "id": "XichWjhuszfJ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_comment_set, sample_comment_set_atten_mask, edge_connection, edge_feat = recon_kw(kw, np.array(cleaned_arti['headline']), cleaned_arti, cleaned_comm)"
      ],
      "metadata": {
        "id": "6umU6S33tbN_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d080cf-c7d4-4607-d500-51bccc9aceac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 576/4084 [43:50<4:27:27,  4.57s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generate the other edge related data file \n",
        "import os\n",
        "\n",
        "path = '/content/gdrive/MyDrive/withoutBERT_edge_connection'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/withoutBERT_edge_feat'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/withoutBERT_sample_comment'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "path = '/content/gdrive/MyDrive/withoutBERT_sample_comment_set_atten_mask'\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "\n",
        "for i in range(len(uni_id)):\n",
        "    np.save('/content/gdrive/MyDrive/withoutBERT_edge_connection/egde_connection{0:}.npy'.format(i), edge_connection[i])\n",
        "    np.save('/content/gdrive/MyDrive/withoutBERT_edge_feat/edge_feat{0:}.npy'.format(i), edge_feat[i])\n",
        "    np.save('/content/gdrive/MyDrive/withoutBERT_sample_comment/sample_comment{0:}.npy'.format(i), sample_comment_set[i])\n",
        "    np.save('/content/gdrive/MyDrive/withoutBERT_sample_comment_set_atten_mask/sample_comment_set_atten_mask{0:}.npy'.format(i), sample_comment_set_atten_mask[i])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A-XvhsWrtSDB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JxVBV_uQ9kTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph construction"
      ],
      "metadata": {
        "id": "tkuo2EXMyd9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export CPATH=/usr/local/cuda/include:$CPATH\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from google.colab import drive\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "!pip install transformers\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zirS4mt3G1l_",
        "outputId": "64510b8a-8736-469c-c164-da1e2768ed87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.13)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_directory_tokenizer='/content/gdrive/MyDrive/withoutBERT_tokenizer'\n",
        "tokenizer = BertTokenizer.from_pretrained(save_directory_tokenizer)"
      ],
      "metadata": {
        "id": "ywltX1UEgLWS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_y(sample_comment, sample_comment_atten_mask):\n",
        "    #generate y data file \n",
        "    sample_comment = np.array(sample_comment)\n",
        "    num_label_set = sample_comment.shape[1]\n",
        "    for i in tqdm(range(num_label_set)):\n",
        "        label_set = sample_comment[:, i, :]\n",
        "        num_label = label_set.shape[0]\n",
        "        #scalar y path\n",
        "        path_scalar = '/content/gdrive/MyDrive/withoutBERT_scalar_label_set{0:}'.format(i)\n",
        "        if not os.path.exists(path_scalar):\n",
        "            os.makedirs(path_scalar)\n",
        "\n",
        "        for j in range(num_label):\n",
        "            label_tensor = torch.tensor(label_set[j], dtype=torch.long).view(1,-1).to(device)\n",
        "            label_tensor = label_tensor.cpu()\n",
        "            torch.save(label_tensor, path_scalar+\"/label{0:}.pt\".format(j))\n"
      ],
      "metadata": {
        "id": "BdqjMFzxeb6X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, path, num_set):\n",
        "        super(YDataset, self).__init__()\n",
        "        self.path = path \n",
        "        self.num_set = num_set\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.path + str(self.num_set) + '/label' + str(index) + '.pt'\n",
        "        data = torch.load(path).cpu()\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(os.listdir(self.path+str(self.num_set)))"
      ],
      "metadata": {
        "id": "VnubtwZ10TdC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, datasetA, datasetB):\n",
        "        self.datasetA = datasetA\n",
        "        self.datasetB = datasetB\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        xA = self.datasetA[index]\n",
        "        xB = self.datasetB[index]\n",
        "        return xA, xB\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.datasetA)\n",
        "    "
      ],
      "metadata": {
        "id": "yGqWc6n-uAFa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate y data file\n",
        "path = '/content/gdrive/MyDrive/withoutBERT_scalar_label_set0'\n",
        "if not os.path.exists(path):\n",
        "    path = '/content/gdrive/MyDrive/withoutBERT_graph/' \n",
        "    files = os.listdir(path)   \n",
        "    num_file = len(files)       \n",
        "\n",
        "    #graph.x file has been generated by recon_kw\n",
        "    #generate sample\n",
        "    sample_comment = []\n",
        "    sample_comment_atten_mask = []\n",
        "\n",
        "    for i in tqdm(range(num_file)):\n",
        "        sample_comment.append(np.load('/content/gdrive/MyDrive/withoutBERT_sample_comment/sample_comment{0:}.npy'.format(i)))\n",
        "        sample_comment_atten_mask.append(np.load('/content/gdrive/MyDrive/withoutBERT_sample_comment_set_atten_mask/sample_comment_set_atten_mask{0:}.npy'.format(i)))\n",
        "    gen_y(sample_comment, sample_comment_atten_mask)"
      ],
      "metadata": {
        "id": "fxBD4qnTgDHv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GCN with fixed pretrained embedding"
      ],
      "metadata": {
        "id": "ucPROchYOghj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. lower batchsize\n",
        "# 2. shuffle # 4. lower hidden size\n",
        "# 3. lr\n",
        "# 5. align two dataset\n",
        "# 6. stop when comments aren't continuing, [padding] 2\n",
        "# 7. better decoding\n",
        "# 8. take the avg length of comments 1"
      ],
      "metadata": {
        "id": "KP550idV6Yfi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--encoder_hidden_size', type=int, default=128,\n",
        "                    choices=[64, 128, 256])\n",
        "parser.add_argument('--decoder_hidden_size', type=int, default=128,\n",
        "                    choices=[64, 128, 256])\n",
        "parser.add_argument('--embedding_size', type=int, default=128,\n",
        "                    choices=[64, 128, 256])\n",
        "parser.add_argument('--vocab_size', type=int, default=len(tokenizer))\n",
        "parser.add_argument('--teacher_forcing_prob', type=float, default=0.5)\n",
        "parser.add_argument('--max_num_nodes', type=int, default=50)\n",
        "parser.add_argument('--device', default=torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "parser.add_argument('--encoder_lr', type=float, default=1e-3)\n",
        "parser.add_argument('--decoder_lr', type=float, default=1e-3)\n",
        "parser.add_argument('--batch_size', type=int, default=32,\n",
        "                    choices=[64, 128, 256])\n",
        "parser.add_argument('--num_sample', type=int, default=10)\n",
        "parser.add_argument('--epochs', type=int, default=2000)\n",
        "args = parser.parse_args(args=[])"
      ],
      "metadata": {
        "id": "MlpOP5UNzvGE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "!pip install wandb\n",
        "!wandb login\n",
        "wandb.init(project=\"NLP-project_withoutBERT\", entity=\"congliu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "nrYxrcVu1Qh-",
        "outputId": "a4c06e64-27c4-474a-9214-3d86a7757d33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.13)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcongliu\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcongliu\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.13"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220408_163713-1ydp0ne5</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/congliu/NLP-project_withoutBERT/runs/1ydp0ne5\" target=\"_blank\">rich-plasma-14</a></strong> to <a href=\"https://wandb.ai/congliu/NLP-project_withoutBERT\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/congliu/NLP-project_withoutBERT/runs/1ydp0ne5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fd07ade6b90>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, GraphNorm, global_max_pool\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "wandb.config = {\n",
        "  \"encoder_learning_rate\": args.encoder_lr,\n",
        "  \"decoder_learning_rate\": args.decoder_lr,\n",
        "  \"epochs\": args.epochs,\n",
        "  \"batch_size\": args.batch_size,\n",
        "  \"encoder_hidden_size\": args.encoder_hidden_size,\n",
        "  \"decoder_hidden_size\": args.decoder_hidden_size,\n",
        "  \"embedding_size\": args.embedding_size,\n",
        "  \"num_sample\": args.num_sample,\n",
        "  \"vocab_size\": args.vocab_size\n",
        "}\n",
        "\n",
        "class GraphEncoder(torch.nn.Module):\n",
        "    def __init__(self, args, embedding):\n",
        "        super(GraphEncoder, self).__init__()\n",
        "        self.embedding_size = args.embedding_size        \n",
        "        self.encoder_hidden_size = args.encoder_hidden_size\n",
        "        \n",
        "        self.embedding = embedding\n",
        "        #Multi-atten\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=self.embedding_size, nhead=4)\n",
        "        self.multi_atten = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "        \n",
        "        #GAT encoder\n",
        "        self.conv1 = GATConv(self.embedding_size, self.encoder_hidden_size, edge_dim=1)\n",
        "        self.norm = GraphNorm(self.encoder_hidden_size)\n",
        "        self.conv2 = GATConv(self.encoder_hidden_size, self.encoder_hidden_size, edge_dim=1)\n",
        "        self.fc = nn.Linear(self.encoder_hidden_size, self.encoder_hidden_size) ########big fc!!\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_attr, mask, batch = data.x, data.edge_index, data.edge_attr, data.mask, data.batch\n",
        "\n",
        "        #embedding layer\n",
        "        x = self.embedding(x)\n",
        "        #multi-atten\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        x = self.multi_atten(x, src_key_padding_mask=mask)\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        x = x[:, 1] #keyword\n",
        "        ##GCN\n",
        "        x_ = self.conv1(x, edge_index, edge_attr.to(torch.float))\n",
        "        x_ = self.norm(x_)\n",
        "        x_ = F.relu(x_)\n",
        "        # x_ += x\n",
        "        x = x_.to(torch.float32)\n",
        "        x_ = self.conv2(x_, edge_index, edge_attr.to(torch.float))\n",
        "        x_ = self.norm(x_)\n",
        "        # x_ += x\n",
        "        x_ = x_.to(torch.float32)\n",
        "        x_ = F.relu(self.fc(x_))\n",
        "        #pooling\n",
        "        pool_x = global_max_pool(x_, batch)\n",
        "\n",
        "\n",
        "        return x_, pool_x\n",
        "\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, units, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = nn.Linear(hidden_size, units)\n",
        "        self.W2 = nn.Linear(hidden_size, units)\n",
        "        self.V = nn.Linear(units, 1)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, batch_size, query, values):\n",
        "        #query: init_hidden_state: headline embedding: bs, embedding_size\n",
        "        #values: encoder_output_embeeding: num_nodes, bs, embedding_size\n",
        "        query = query.transpose(0, 1) # bs, 1, embedding_size\n",
        "        score = self.V(self.tanh(self.W1(values) + self.W2(query))) #bs, num_nodes, attention_hidden_size -> bs, num_nodes, 1\n",
        "        attention_weights = self.softmax(score) #bs, num_nodes, 1\n",
        "        context_vector = torch.sum(attention_weights * values, 1) #bs, embedding_size == bs, encoder_hidden_size\n",
        "\n",
        "        return context_vector, attention_weights\n",
        "    \n",
        "class GRUDecoder(nn.Module):\n",
        "    def __init__(self, args, criterion, embedding):\n",
        "        super(GRUDecoder, self).__init__()\n",
        "        #GRU Decoder\n",
        "        self.args = args\n",
        "        self.embedding = embedding\n",
        "        self.vocab_size = args.vocab_size\n",
        "        self.decoder_hidden_size = args.decoder_hidden_size\n",
        "        self.encoder_hidden_size = args.encoder_hidden_size\n",
        "        self.embedding_size = args.embedding_size\n",
        "        self.out = nn.Linear(self.embedding_size, self.vocab_size)\n",
        "        self.out.weight = self.embedding.weight\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=self.encoder_hidden_size,\n",
        "            hidden_size=self.decoder_hidden_size\n",
        "        )\n",
        "        self.attention = BahdanauAttention(self.decoder_hidden_size, self.encoder_hidden_size)\n",
        "        self.attn_combine = nn.Linear(self.embedding_size + self.encoder_hidden_size, self.decoder_hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.device = self.args.device\n",
        "        self.criterion = criterion\n",
        "\n",
        "    def forward(self, data, inputs, hidden, enc_output):\n",
        "        #inputs, y: scalar\n",
        "        #hidden: bs, encoder_hidden_size #pooled encoder output \n",
        "        #enc_output: num_nodes, bs, encoder_hidden_size\n",
        "        #output: embedding\n",
        "        \n",
        "        inputs = torch.squeeze(inputs)\n",
        "        batch_size, num_steps = inputs.shape\n",
        "        use_teacher_forcing = random.random() < args.teacher_forcing_prob\n",
        "        loss = 0\n",
        "\n",
        "        encoder_outputs = torch.zeros(batch_size, self.args.max_num_nodes, self.args.encoder_hidden_size).to(self.device)\n",
        "        idx = data.batch.cpu().numpy()\n",
        "        start_idx = 0\n",
        "        for batch_num in range(batch_size):\n",
        "            idx_list = np.where(idx==batch_num)[0]\n",
        "            graph_data = enc_output[idx_list]\n",
        "            encoder_outputs[batch_num, :len(idx_list)] = graph_data[:args.max_num_nodes]\n",
        "\n",
        "        input = torch.LongTensor([[2]]*batch_size).to(self.device)\n",
        "        outputs = torch.zeros((batch_size, num_steps), dtype=torch.long).to(self.device)\n",
        "        hidden = hidden.view(1, batch_size, -1) # 1, bs, encoder_hidden_size\n",
        "\n",
        "        if use_teacher_forcing:\n",
        "            for i in range(num_steps-1):\n",
        "                context_vector, attention_weights = self.attention(batch_size, hidden, encoder_outputs) #1, encoder_hidden_size\n",
        "                context_vector = context_vector.unsqueeze(0) # 1, bs, encoder_hidden_size\n",
        "                #concatenate x and context_vector\n",
        "                input = self.embedding(input)\n",
        "                input = input.transpose(0, 1)\n",
        "                x = torch.cat((context_vector, input), -1) #1, bs, embedding_size + encoder_hidden_size\n",
        "                x = self.relu(self.attn_combine(x)) #1, bs, dec_units\n",
        "\n",
        "                output, hidden = self._step(x, hidden)\n",
        "                topv, topi = output.topk(1)\n",
        "                outputs[:, i] = topi.detach().squeeze()\n",
        "                loss += self.criterion(output, inputs[:, i+1])\n",
        "\n",
        "                input = torch.unsqueeze(inputs[:, i+1], 1)\n",
        "        else:\n",
        "            for i in range(num_steps-1):\n",
        "                context_vector, attention_weights = self.attention(batch_size, hidden, encoder_outputs) #1, encoder_hidden_size\n",
        "                context_vector = context_vector.unsqueeze(0) # 1, bs, encoder_hidden_size\n",
        "                #concatenate x and context_vector\n",
        "                input = self.embedding(input)\n",
        "                input = input.transpose(0, 1)\n",
        "                x = torch.cat((context_vector, input), -1) #1, bs, embedding_size + encoder_hidden_size\n",
        "                x = self.relu(self.attn_combine(x)) #1, bs, dec_units\n",
        "\n",
        "                output, hidden = self._step(x, hidden)\n",
        "                topv, topi = output.topk(1)\n",
        "\n",
        "                input = topi.detach()\n",
        "                outputs[:, i+1] = topi.detach().squeeze()\n",
        "                loss += self.criterion(output, inputs[:, i+1])\n",
        "                if input[0].item() == 3:\n",
        "                    break\n",
        "        return loss\n",
        "\n",
        "    def _step(self, input, hidden):\n",
        "        output, hidden = self.gru(input, hidden)\n",
        "        output = F.log_softmax(self.out(torch.squeeze(output)), dim=1)\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "class Graph2Seq:\n",
        "\n",
        "    def __init__(self, args, criterion, train_dataloader, test_dataloader, val_dataloader):\n",
        "        self.args = args\n",
        "        self.embedding_layer = nn.Embedding(args.vocab_size, args.embedding_size)\n",
        "\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.test_dataloader = test_dataloader\n",
        "        self.val_dataloader = val_dataloader\n",
        "\n",
        "\n",
        "        self.encoder = GraphEncoder(args, self.embedding_layer)\n",
        "        self.decoder = GRUDecoder(args, criterion, self.embedding_layer)\n",
        "\n",
        "        self.encoder.to(args.device)\n",
        "        self.decoder.to(args.device)\n",
        "\n",
        "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=args.encoder_lr)\n",
        "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=args.decoder_lr)\n",
        "\n",
        "    def train(self):\n",
        "        self.encoder.train()\n",
        "        self.decoder.train()\n",
        "\n",
        "    def eval(self):\n",
        "        self.encoder.eval()\n",
        "        self.decoder.eval()\n",
        "\n",
        "    def train_batch(self, data, y): \n",
        "        num_steps = y.shape[1]\n",
        "        self.encoder_optimizer.zero_grad()\n",
        "        self.decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_output, pooled_encoder_output = self.encoder(data)\n",
        "        loss = self.decoder(data, y, pooled_encoder_output, encoder_output)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        self.encoder_optimizer.step()\n",
        "        self.decoder_optimizer.step()\n",
        "\n",
        "        wandb.watch(self.encoder)\n",
        "        wandb.watch(self.decoder)\n",
        "\n",
        "        return loss.item() / (num_steps)\n",
        "\n",
        "    def train_epoch(self, epochs):\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0.\n",
        "            progress_bar = tqdm(self.train_dataloader)\n",
        "            for idx, (data, scalar_y) in enumerate(progress_bar):\n",
        "                progress_bar.set_description('Epoch ' + str(epoch))\n",
        "                data = data.to(args.device)\n",
        "                scalar_y = scalar_y.to(args.device)\n",
        "\n",
        "                # Train batch and get batch loss\n",
        "                batch_loss = self.train_batch(data, scalar_y)\n",
        "                # Update epoch loss given als batch loss\n",
        "                epoch_loss += batch_loss\n",
        "                progress_bar.set_postfix(epoch_loss='%.3f' % (epoch_loss /(idx+1)))\n",
        "\n",
        "            wandb.log({\"loss\": epoch_loss /(idx+1)})\n",
        "        \n",
        "        return epoch_loss\n",
        "\n",
        "    def save_models(self, encoder_file_name, decoder_file_name):\n",
        "        torch.save(self.encoder.state_dict(), encoder_file_name)\n",
        "        torch.save(self.decoder.state_dict(), decoder_file_name)\n",
        "\n",
        "    def load_models(self, encoder_file_name, decoder_file_name):\n",
        "        self.encoder.load_state_dict(torch.load(encoder_file_name))\n",
        "        self.decoder.load_state_dict(torch.load(decoder_file_name))\n",
        "\n"
      ],
      "metadata": {
        "id": "7qR_BIoyOi7E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_sample = args.num_sample\n",
        "max_num_nodes = args.max_num_nodes\n",
        "batchsize = args.batch_size\n",
        "\n",
        "#y data and graph data\n",
        "idx = 0\n",
        "path_y_scalar = '/content/gdrive/MyDrive/withoutBERT_scalar_label_set'+str(idx)\n",
        "num_file = len(os.listdir(path_y_scalar))\n",
        "y_scalar_list = []\n",
        "for i in tqdm(range(num_file)):\n",
        "    y_scalar_list.append(torch.load(path_y_scalar+'/label'+str(i)+'.pt').cpu())\n",
        "\n",
        "\n",
        "path_mask = '/content/gdrive/MyDrive/withoutBERT_mask'\n",
        "path_graph = '/content/gdrive/MyDrive/withoutBERT_graph'\n",
        "path_connect = '/content/gdrive/MyDrive/withoutBERT_edge_connection'\n",
        "path_feat = '/content/gdrive/MyDrive/withoutBERT_edge_feat'\n",
        "num_file = len(os.listdir(path_graph))\n",
        "data_list = []\n",
        "for i in tqdm(range(num_file)):\n",
        "    data_list.append(Data(x=torch.load(path_graph + '/graph'+str(i)+'.pt'), edge_index=torch.tensor(np.load(path_connect+'/egde_connection'+str(i)+'.npy'), dtype=torch.long), edge_attr=torch.tensor(np.load(path_feat+'/edge_feat'+str(i)+'.npy')), mask=torch.load(path_mask+'/graph'+str(i)+'.pt').cpu()))\n",
        "\n",
        "#graph data\n",
        "path_whole_graph = '/content/gdrive/MyDrive/withoutBERT_whole_graph'\n",
        "if not os.path.exists(path_whole_graph):\n",
        "    os.makedirs(path_whole_graph)\n",
        "    for i, data in enumerate(tqdm(data_list)):\n",
        "        torch.save(data, path_whole_graph+'/graph'+str(i)+'.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "K7zMccVZ0ybK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883db656-b00e-41a0-b912-7772dfb7f5f2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4084/4084 [00:04<00:00, 991.60it/s] \n",
            "100%|██████████| 4084/4084 [00:17<00:00, 227.19it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(data_list[:3000], y_scalar_list[:3000])\n",
        "val_dataset = MyDataset(data_list[3500:], y_scalar_list[3500:])\n",
        "test_dataset = MyDataset(data_list[3000:3500], y_scalar_list[3000:3500])"
      ],
      "metadata": {
        "id": "bYfeFnfec5JH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import DataLoader\n",
        "trainloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=1, prefetch_factor=1)\n",
        "testloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=1, prefetch_factor=1)\n",
        "valloader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False, pin_memory=True, num_workers=1, prefetch_factor=1)"
      ],
      "metadata": {
        "id": "48ulIvuqqDFV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = torch.ones(args.vocab_size).to(args.device)\n",
        "weight[0] = 0\n",
        "weight[1] = 0\n",
        "##pay attention!!!\n",
        "criterion = nn.CrossEntropyLoss(weight=weight)\n",
        "graph2seq = Graph2Seq(args, criterion, trainloader, testloader, valloader)"
      ],
      "metadata": {
        "id": "Gi2Bg__8zQ_y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph2seq.train_epoch(args.epochs)"
      ],
      "metadata": {
        "id": "VJB0dpYT1U0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#beam search"
      ],
      "metadata": {
        "id": "AO9oryTTODCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "def beam_search_decoder(predictions, k):\n",
        "    # create the list of [seq, score]\n",
        "    # score is log_prob\n",
        "    sequences = [[list(), 1.0]]\n",
        "    # walk over each step in sequence\n",
        "    for row in tqdm(predictions):\n",
        "        all_candidates = list()\n",
        "        # expand each current candidate\n",
        "        for i in range(len(sequences)):\n",
        "            seq, score = sequences[i]\n",
        "            for j in range(len(row)):\n",
        "                # add the embedding into the list and calculate the log_prob\n",
        "                # 这里可以加if语句去判断是否遇到了end 直接跳过。（如果这样可以迫使模型生成1句话或者2句话，或者你前面如果\n",
        "                # 加了对于pad的惩罚 这里就不用在多搞了，如果没有可以判断，如果一个pad后面加的还是pad那么说明句子到头了\n",
        "                candidate = [seq + [j], score * -np.log(row[j])]\n",
        "                all_candidates.append(candidate)\n",
        "        # order all candidates by score\n",
        "        ordered = sorted(all_candidates, key=lambda tup :tup[1])\n",
        "        # select k best\n",
        "        sequences = ordered[:k]\n",
        "    return sequences"
      ],
      "metadata": {
        "id": "nloSKM77iTyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp8pqUashnej",
        "outputId": "8625f473-c773-434d-ccef-e9d4611b8583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 32027])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = graph_dataset[0]"
      ],
      "metadata": {
        "id": "u84T2LNQhGrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = graph_dataset[32]\n",
        "dec_input = model(torch.tensor([101]).to(device).view(1, -1))[0]\n",
        "x_encode = graph_encoder(data.to(device))\n",
        "\n",
        "dec_hidden = x_encode[-1]\n",
        "decode = []\n",
        "idx_list = []\n",
        "output = torch.zeros(10, 32027)\n",
        "for i in range(10):\n",
        "    predictions, dec_hidden = GRU_decoder(1, dec_input, dec_hidden, x_encode)\n",
        "    output[i] = predictions.detach().cpu()\n",
        "    idx = torch.argmax(predictions, 1)\n",
        "    idx_list.append(idx.data.cpu().numpy()[0])\n",
        "    dec_input = model(idx.cpu().view(1, -1).to(device))[0]\n",
        "decode = tokenizer.decode(np.array(idx_list))\n"
      ],
      "metadata": {
        "id": "nL6dnh9ohVm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beam_search_decoder(output, 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8BjjnBrh_Lu",
        "outputId": "eef9f908-b377-4a69-f1d1-60c87134e845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in log\n",
            "  app.launch_new_instance()\n",
            "100%|██████████| 10/10 [00:14<00:00,  1.47s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], tensor(nan)],\n",
              " [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1], tensor(nan)]]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TopK"
      ],
      "metadata": {
        "id": "0eGeCOK8EKfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = graph_dataset[32]\n",
        "dec_input = model(torch.tensor([101]).to(device).view(1, -1))[0]\n",
        "x_encode = graph_encoder(data.to(device))\n",
        "\n",
        "dec_hidden = x_encode[-1]\n",
        "decode = []\n",
        "idx_list = []\n",
        "for _ in range(100):\n",
        "    predictions, dec_hidden = GRU_decoder(1, dec_input, dec_hidden, x_encode)\n",
        "    _, idx = torch.topk(predictions, 5)\n",
        "    idx = idx[0][torch.randint(5, (1,)).to(device)]\n",
        "    idx_list.append(idx.data.cpu().numpy()[0])\n",
        "    dec_input = model(idx.cpu().view(1, -1).to(device))[0]\n",
        "decode = tokenizer.decode(np.array(idx_list))\n"
      ],
      "metadata": {
        "id": "d982nISooC7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GbLhfHFz15VJ",
        "outputId": "29cb893d-a96d-44f2-9289-8c985fa0462c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"- said i was also a packers put fan - was root qb to the vikings their brett. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as [PAD] i was also a packers. i'sean a packers payton was theiring qb to. as\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM example"
      ],
      "metadata": {
        "id": "8j6XLsKOxudP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A sample LSTM text generator\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(\n",
        "        self, text_df\n",
        "    ):\n",
        "        self.text_df = text_df\n",
        "        self.words = self.load_words()\n",
        "        self.uniq_words = self.get_uniq_words()\n",
        "        self.sequence_length = 4\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.uniq_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.uniq_words)}\n",
        "\n",
        "        self.words_indexes = [self.word_to_index[w] for w in self.words]\n",
        "\n",
        "    # here I load all the words in all nodes for one graph, it should be fixed...\n",
        "    def load_words(self):\n",
        "        text_arr = np.array(self.text_df)\n",
        "        text = \"\"\n",
        "        for i in range(len(text_arr)):\n",
        "            text += text_arr[i][0] + \" \"\n",
        "        return text.split(' ')\n",
        "\n",
        "    def get_uniq_words(self):\n",
        "        word_counts = Counter(self.words)\n",
        "        return sorted(word_counts, key=word_counts.get, reverse=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words_indexes) - self.sequence_length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (\n",
        "            torch.tensor(self.words_indexes[index:index+self.sequence_length]),\n",
        "            torch.tensor(self.words_indexes[index+1:index+self.sequence_length+1]),\n",
        "        )\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# LSTM\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, dataset):\n",
        "        super(Model, self).__init__()\n",
        "        self.lstm_size = 128\n",
        "        self.embedding_dim = 128\n",
        "        self.num_layers = 3\n",
        "\n",
        "        n_vocab = len(dataset.uniq_words)\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=self.embedding_dim,\n",
        "        )\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.lstm_size,\n",
        "            hidden_size=self.lstm_size,\n",
        "            num_layers=self.num_layers,\n",
        "            dropout=0.2,\n",
        "        )\n",
        "        self.fc = nn.Linear(self.lstm_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, prev_state):\n",
        "        embed = self.embedding(x)\n",
        "        output, state = self.lstm(embed, prev_state)\n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "    def init_state(self, sequence_length):\n",
        "        return (torch.zeros(self.num_layers, sequence_length, self.lstm_size),\n",
        "                torch.zeros(self.num_layers, sequence_length, self.lstm_size))\n",
        "        \n",
        "import argparse\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train(dataset, model):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=256\n",
        "    )\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        state_h, state_c = model.init_state(4)\n",
        "\n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "\n",
        "            state_h = state_h.detach()\n",
        "            state_c = state_c.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "\n",
        "def predict(dataset, model, text, next_words=100):\n",
        "    words = text.split(' ')\n",
        "    model.eval()\n",
        "\n",
        "    state_h, state_c = model.init_state(len(words))\n",
        "\n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words[i:]]])\n",
        "        y_pred, (state_h, state_c) = model(x, (state_h, state_c))\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "dataset = Dataset(df)\n",
        "model = Model(dataset)\n",
        "\n",
        "train(dataset, model)"
      ],
      "metadata": {
        "id": "k23VjARD7GHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# transformer encoder example"
      ],
      "metadata": {
        "id": "QLu5qU6_xyG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
        "transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
        "src = torch.rand(10, 32, 512)\n",
        "out = transformer_encoder(src)"
      ],
      "metadata": {
        "id": "nqkdnu3aHgoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8OVWHGDiiPD",
        "outputId": "3bcba31f-921b-4543-abf0-7617733c9dc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 32, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "text = \"The capital of France contains the Eiffel Tower.\"\n",
        "input = tokenizer.encode_plus(text, return_tensors = \"pt\")\n",
        "output = model(**input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dysWTlnqa1eB",
        "outputId": "61c4f7ff-9856-4bf1-c5a6-3bb99c46f854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59HGZyYYfDSm",
        "outputId": "3d640297-f016-4005-a1f0-42c99e502a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"The capital of France contains the Eiffel Tower.\"]\n",
        "input = tokenizer.encode_plus(text, return_tensors = \"pt\")"
      ],
      "metadata": {
        "id": "-xD9fnCidlaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode_plus(text, add_special_tokens = True,  truncation = True, padding = \"max_length\", return_attention_mask = True, return_tensors = \"pt\")"
      ],
      "metadata": {
        "id": "wmYENNtydo4g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
